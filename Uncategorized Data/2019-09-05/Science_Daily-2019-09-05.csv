Source,Heading,Category,Date,Time,URL,Text
Science Daily,New Insight Into Motor Neuron Death Mechanisms Could Be a Step Toward ALS Treatment,Mind & Brain,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904125327.htm,"   The study into the role a protein known as heat shock protein 90 plays in intracellular signaling is a key step on the way to figuring out the reason some motor neurons in the spinal cord die and some do not. Findings, which could eventually lead to therapies to counter motor neuron death, were published in Experimental Biology and Medicine. Neurons are cells in the nervous system that carry information to muscles, glands and other nerves. Motor neurons are large neurons in the spine and brain stem, with long axons extending outside the nervous system to contact muscles and control their movements via contraction. Researchers led by Alvaro Estevez and Maria Clara Franco of the OSU College of Science have shown that a ubiquitous ""protein chaperone,"" heat shock protein 90, is particularly sensitive to inhibition in motor neurons that depend for survival on ""trophic factors"" -- small proteins that serve as helper molecules. Trophic factors attach to docking sites on the surface of nerve cells, setting in motion processes that help keep a cell alive. Research in animal models has shown trophic factors may have the ability to salvage dying neurons. ""It is well known that there are some motor neuron subpopulations resistant to degeneration in ALS, and other subpopulations that are highly susceptible to degeneration,"" said Estevez, associate professor of biochemistry and biophysics and the corresponding author on this research. ""Understanding the mechanisms involved in these different predispositions could provide new insight into how ALS progresses and open new alternatives for the development of novel treatments for the disease."" In this study, a motor-neuron-specific pool of heat shock protein 90, also known as Hsp90, repressed activation of a key cellular receptor and thus was shown to be critical to neuron survival; when Hsp90 was inhibited, motor neuron death was triggered. The Hsp90 inhibitor used in this research was geldanamycin, an antitumor antibiotic used in chemotherapy. Findings suggest the drug may have the unintended consequence of decreasing motor neurons' trophic pathways and thus putting those nerve cells at risk. ""The inhibition of Hsp90 as a therapeutic approach may require the development of inhibitors that are more selective so the cancer cells are targeted and healthy motor neurons are not,"" said Franco, assistant professor of biochemistry and biophysics. ALS, short for amyotrophic lateral sclerosis and also known as Lou Gehrig's disease, is caused by the deterioration and death of motor neurons in the spinal cord. It is progressive, debilitating and fatal. ALS was first identified in the late 1800s and gained international recognition in 1939 when it was diagnosed in a mysteriously declining Gehrig, ending the Hall of Fame baseball career of the New York Yankees first baseman. Known as the Iron Horse for his durability -- he hadn't missed a game in 15 seasons -- Gehrig died two years later at age 37. "
Science Daily,Emotion-Reading Algorithms Cannot Predict Intentions Via Facial Expressions,Mind & Brain,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904165231.htm,"   Computers aren't very good at discerning misrepresentation, and that's a problem as the technologies are increasingly deployed in society to render decisions that shape public policy, business and people's lives. Turns out that algorithms fail basic tests as truth detectors, according to researchers who study theoretical factors of expression and the complexities of reading emotions at the USC Institute for Creative Technologies. The research team completed a pair of studies using science that undermines popular psychology and AI expression understanding techniques, both of which assume facial expressions reveal what people are thinking. ""Both people and so-called 'emotion reading' algorithms rely on a folk wisdom that our emotions are written on our face,"" said Jonathan Gratch, director for virtual human research at ICT and a professor of computer science at the USC Viterbi School of Engineering. ""This is far from the truth. People smile when they are angry or upset, they mask their true feelings, and many expressions have nothing to do with inner feelings, but reflect conversational or cultural conventions."" Gratch and colleagues presented the findings today at the 8th International Conference on Affective Computing and Intelligent Interaction in Cambridge, England. Of course, people know that people can lie with a straight face. Poker players bluff. Job applicants fake interviews. Unfaithful spouses cheat. And politicians can cheerfully utter false statements. Yet, algorithms aren't so good at catching duplicity, even as machines are increasingly deployed to read human emotions and inform life-changing decisions. For example, the Department of Homeland Security invests in such algorithms to predict potential threats. Some nations use mass surveillance to monitor communications data. Algorithms are used in focus groups, marketing campaigns, to screen loan applicants or hire people for jobs. ""We're trying to undermine the folk psychology view that people have that if we could recognize people's facial expressions, we could tell what they're thinking,"" said Gratch, who is also a professor of psychology. ""Think about how people used polygraphs back in the day to see if people were lying. There were misuses of the technology then, just like misuses of facial expression technology today. We're using na√Øve assumptions about these techniques because there's no association between expressions and what people are really feeling based on these tests."" To prove it, Gratch and fellow researchers Su Lei and Rens Hoegen at ICT, along with Brian Parkinson and Danielle Shore at the University of Oxford, examined spontaneous facial expressions in social situations. In one study, they developed a game that 700 people played for money and then captured how people's expressions impacted their decisions and how much they earned. Next, they allowed subjects to review their behavior and provide insights into how they were using expressions to gain advantage and if their expressions matched their feelings. Using several novel approaches, the team examined the relationships between spontaneous facial expressions and key events during the game. They adopted a technique from psychophysiology called ""event-related potentials"" to address the extreme variability in facial expressions and used computer vision techniques to analyze those expressions. To represent facial movements, they used a recently proposed method called facial factors, which captures many nuances of facial expressions without the difficulties modern analysis techniques provide. The scientists found that smiles were the only expressions consistently provoked, regardless of the reward or fairness of outcomes. Additionally, participants were fairly inaccurate in perceiving facial emotion and particularly poor at recognizing when expressions were regulated. The findings show people smile for lots of reasons, not just happiness, a context important in the evaluation of facial expressions. ""These discoveries emphasize the limits of technology use to predict feelings and intentions,"" Gratch said. ""When companies and governments claim these capabilities, the buyer should beware because often these techniques have simplistic assumptions built into them that have not been tested scientifically."" Prior research shows that people will make conclusions about other's intentions and likely actions simply based off of the other's expressions. While past studies exist using automatic expression analysis to make inferences, such as boredom, depression and rapport, less is known about the extent to which perceptions of expression are accurate. These recent findings highlight the importance of contextual information when reading other's emotions and support the view that facial expressions communicate more than we might believe. "
Science Daily,Review: Biofeedback Could Help Treat a Number of Conditions,Mind & Brain,2019-08-27,-,https://www.sciencedaily.com/releases/2019/08/190827101624.htm,"   Dr. Karli Kondo of the VA Evidence Synthesis Program and OHSU, first author on the study, explained how the research could advance the use of biofeedback: ""We are encouraged by the positive findings and the additional findings of potential benefits for a wide range of conditions. Biofeedback is a low-risk, cost-effective intervention. We hope that this report will help to make biofeedback more widely available to veterans across the U.S., and that it will serve as a roadmap for future research in the field."" The results appeared online Aug. 14, 2019, in the Journal of General Internal Medicine. Biofeedback refers to using instruments to measure and provide real-time feedback on patients' physiological responses. It can help patients learn to control and change those responses. Since biofeedback does not involve medication and is relatively noninvasive compared to other treatments, it could benefit patients with a low risk of any adverse effects, say the researchers. Biofeedback measures include muscle activity, heart rate, blood pressure, and brainwaves. It is often paired with treatments to change behavior, thoughts, or emotions. For example, using electromyography (EMG) to measure how muscles tighten in response to a medical condition may help patients consciously control those muscles. Biofeedback increasingly is being used as a complementary or alternative treatment for a wide range of conditions. In 2017, about 70 VA facilities reported offering some form of biofeedback. However, the evidence on how biofeedback is used and its effectiveness is scattered across studies on the individual conditions. Because of this, the practice is not well-integrated with usual care. Kondo and colleagues created an ""evidence map"" to get a high-level overview of the research available on biofeedback. They searched for previously conducted systematic reviews and studies on biofeedback to summarize what has been found so far. In total, the researchers used 16 systematic reviews on the topic. The review showed clear evidence that biofeedback is effective at reducing headache pain. A variety of biofeedback measures have been used for headache, including EMG, skin temperature, and blood pressure monitoring. These techniques appear to help decrease the frequency, duration, and intensity of both migraine and tension headaches. The largest improvements were in decreasing frequency of headaches. Moderate-confidence evidence shows that biofeedback can also improve secondary outcomes of headache, such as medication use, muscle tension, anxiety, and depression. Strong evidence also exists showing that biofeedback can help with urinary incontinence for men who have had their prostate removed. In this case, EMG is used to assist with pelvic floor muscle training. Adding biofeedback provides both immediate and long-term improvements beyond those seen with muscle training alone. The evidence map shows consistent evidence that biofeedback helps with several other conditions, although with fewer trials than were found for headaches or incontinence. EMG biofeedback can help with fecal incontinence in both older people of both sexes and in young women who recently gave birth. Adding biofeedback to therapy for lower-limb activity after stroke also appears to help patients. Stroke therapy can include several different types of biofeedback, such as platforms that measure weight distribution to help with balance, sensors to measure the angle of the joints during walking, and EMG to record muscle activity. The researchers found studies on biofeedback use for several other conditions, but no compelling evidence that it was effective in those cases. Reviews showed no benefits from biofeedback for urinary incontinence in women or for high blood pressure management. However, the studies covering these conditions were limited. Likewise, the review turned up insufficient evidence for the use of biofeedback for other conditions, such as bruxism (grinding or clenching the teeth, often while sleeping), labor pain, and Reynaud's disease (a condition involving reduced blood flow to the extremities). The researchers point out that their evidence map, in addition to showing several conditions for which biofeedback has been proven useful, also shows areas of uncertainty where more research is needed. They identified several targets for further research: balance and gait training, fibromyalgia, and intradialytic hypotension (a decrease in blood pressure that can cause a number of symptoms, including nausea, dizziness, and anxiety). Overall, the evidence map gives a ""lay of the land"" that shows what evidence exists for using biofeedback to treat medical conditions or symptoms and what research is still needed. The study was funded by the VA Office of Research and Development Quality Enhancement Research Initiative. "
Science Daily,Concussions Linked to Erectile Dysfunction in Former Pro Football Players,Mind & Brain,2019-08-26,-,https://www.sciencedaily.com/releases/2019/08/190826121940.htm,"   The research -- based on a survey of more than 3,400 former NFL players representing the largest study cohort of former professional football players to date -- was conducted by investigators at the Harvard T.H. Chan School of Public Health and Harvard Medical School as part of the ongoing Football Players Health Study at Harvard University, a research program that encompasses a constellation of studies designed to evaluate various aspects of players' health across their lifespans. The researchers caution that their findings are observational -- based on self-reported concussion symptoms and indirect measures of ED and low testosterone. The results do not prove a cause-effect link between concussion and ED, nor do they explain exactly how head trauma might precipitate the onset of ED, the investigators noted. However, the findings do reveal an intriguing and powerful link between history of concussions and hormonal and sexual dysfunction, regardless of player age. Notably, the ED risk persisted even when researchers accounted for other possible causes such as diabetes, heart disease or sleep apnea, for example. Taken together, these findings warrant further study to tease out the precise mechanism behind it. One possible explanation, the research team said, could be injury to the brain's pituitary gland that sparks a cascade of hormonal changes culminating in diminished testosterone and ED. This biological mechanism has emerged as a plausible explanation in earlier studies that echo the current findings, such as reports of higher ED prevalence and neurohormonal dysfunction among people with head trauma and traumatic brain injury, including military veterans and civilians with head injuries. The new findings also suggest that sleep apnea and use of prescription pain medication contribute to low testosterone and ED. It remains unclear whether they do so independently, as consequences of head injury or both, the researchers said. Sexual function is not only a critical marker of overall health but also central to overall well-being, the researchers note. Understanding the mechanisms behind the possible downstream effects of head injury, they said, can inform treatments and preventive strategies. ""Former players with ED may be relieved to know that concussions sustained during their NFL careers may be contributing to a condition that is both common and treatable,"" said study lead author Rachel Grashow, a researcher at the Harvard T.H. Chan School of Public Health. The results are based on a survey of 3,409 former NFL players, average age 52 years (age range 24 to 89), conducted between 2015 and 2017. Participants were asked to report how often blows to the head or neck caused them to feel dizzy, nauseated or disoriented, or to experience headaches, loss of consciousness or vision disturbances -- all markers of concussion. Responders were grouped in four categories by number of concussive symptoms. Next, the former players were asked whether a clinician had recommended medication for either low testosterone or ED, and whether they were currently taking such medications. Men who reported the highest number of concussion symptoms were two and a half times more likely to report receiving either a recommendation for medication or to be currently taking medication for low testosterone, compared to men who reported the fewest concussion symptoms. Men with the most concussion symptoms were nearly two times more likely to report receiving a recommendation to take ED medication or to be currently taking ED medication than those reporting the fewest symptoms. Players who reported losing consciousness following head injury had an elevated risk for ED even in the absence of other concussion-related symptoms. Notably, even former players with relatively few concussion symptoms had an elevated risk for low testosterone, a finding that suggests there may be no safe threshold for head trauma, the team said. Of all participants, 18 percent reported low testosterone and nearly 23 percent reported ED. Slightly less than 10 percent of participants reported both. As expected, individuals with cardiovascular disease, diabetes, sleep apnea and depression, as well as those taking prescription pain medication -- all of which are known to affect sexual health -- were more likely to report low testosterone levels and ED. Yet, the link between concussion history and low testosterone levels and ED persisted even after researchers accounted for these other conditions. The link between history of concussion and ED was present among both the older and the younger players -- those under age 50 in this case -- the analysis showed, and it persisted over time. ""We found the same association of concussions with ED among both younger and older men in the study, and we found the same risk of ED among men who had last played twenty years ago,"" said study senior author Andrea Roberts, a researcher at the Harvard T.H. Chan School of Public Health. ""These findings suggest that increased risk of ED following head injury may occur at relatively young ages and may linger for decades thereafter."" Given that ED is both fairly common and easily treatable, those who experience symptoms are encouraged to report them to their physicians, the researchers said. Importantly, prompt evaluation of ED is critical because it can signal the presence of other conditions, including heart disease and diabetes. The findings also suggest that it may be important for clinicians to assess all patients with concussion history for the presence of neurohormonal changes. ""ED is a fact of life for many men,"" said Herman Taylor, director of player engagement and education and director of the Cardiovascular Research Institute at Morehouse School of Medicine. ""Anyone with symptoms should seek clinical attention and thorough evaluation, particularly since ED can be fueled by cardiovascular and metabolic disorders. The good news is that this is a treatable condition."" Co-investigators included Marc Weisskopf, Karen Miller, David M. Nathan, Ross Zafonte, Frank Speizer, Theodore Courtney, Aaron Baggish, Alvaro Pascual-Leone and Lee Nadler. The research was supported by the National Football League Players Association (NFLPA). "
Science Daily,Benefits of Cognitive Behavioral Therapy for IBS Continue 2 Years After Treatment,Mind & Brain,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904102629.htm,"   Previous research (the ACTIB trial) led by Professor Hazel Everitt at the University of Southampton in collaboration with researchers at King's College London, showed that that Cognitive Behavioural Therapy (CBT) tailored specifically for IBS and delivered over the telephone or through an interactive website is more effective in relieving the symptoms of IBS than current standard care one year after treatment. This 24 month follow up research published in Lancet Gastroenterology and Hepatology this week has shown that benefits continue two years after treatment despite patients having no further therapy after the initial CBT course. These results are important as previously there was uncertainty whether the initial benefits could be sustained in the long term. Currently there is limited availability of CBT for IBS in a resource constrained NHS but this research indicates that easily accessible treatment could be provided to a large number of patients and provide them with effective, long-term relief. Professor Everitt added: ""the fact that both telephone and web based CBT sessions were shown to be effective treatments is a really important and exciting discovery. Patients are able to undertake these treatments at a time convenient to them, without having to travel to clinics and we now know that the benefits can last long term.'' "
Science Daily,"Similarities in Human, Chimpanzee, and Bonobo Eye Color Patterns Revealed",Mind & Brain,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904100801.htm,"   In contrast, as the sclerae of apes' eyes is often darker than human eyes, researchers have long argued that their gaze is 'cryptic', or hidden. This means that nonhuman apes would not be able to see where other members of their species are looking. Now, researchers from the National University of Singapore (NUS), together with collaborators from the University of St Andrews and Leiden University, have discovered that ape eyes possess the same pattern of colour differences as human beings. Doctoral student Mr Juan O. Perea-Garc√≠a and Associate Professor Ant√≥nia Monteiro from the Department of Biological Sciences at the NUS Faculty of Science suggest that this discovery may mean apes also follow each other's gaze. Their findings were published in Proceedings of the National Academy of Sciences (PNAS) on 3 September 2019. Eye-opening results The research team compared the darkness of the sclerae contrasted with irises of over 150 humans, bonobos and chimpanzees. The researchers found that bonobos, like humans, have paler sclerae and darker irises. Chimpanzees were found to have a different pattern -- with very dark sclerae, and paler irises. Both of these colour patterns show the same type of contrast seen in human eyes, and could help other apes find out where they are looking. ""Humans are unique in many ways, as no other animal can communicate with similar intricate language or build tools of such complexity. Gaze following is an important component of many behaviours that are thought to be characteristically human, so our findings suggest that apes might also engage in these behaviours,"" said Mr Perea-Garc√≠a. Furthering our ancestral understanding Before humans had language, our ancestors might have used the gaze of those around them to help communicate dangers or other useful information. They might not have been able to say, ""Look over there!."" However, a look in the direction of the predator might be sufficient, as long as it was possible to follow the direction of their gaze. Apart from helping us understand how our ancestors communicated, this study suggests some interesting new research directions. These include questions pertaining to why human beings and bonobos evolve in a similar way, despite bonobos being more closely related to chimpanzees. ""We know that some gorillas and orangutans have eye colouration like our own, and some members of these species have eye colouration similar to the chimpanzees, but why is there this variation within a species? We are working with several zoos to find out more,"" shared Mr Perea-Garc√≠a. "
Science Daily,Receptor Protein in Brain Promotes Resilience to Stress,Mind & Brain,2019-09-03,-,https://www.sciencedaily.com/releases/2019/09/190903160619.htm,"   ""We have found that a specific cell receptor promotes resilience to the adverse effects of stress in animals,"" said study leader Seema Bhatnagar, PhD, a neuroscientist in the Department of Anesthesiology and Critical Care at Children's Hospital of Philadelphia (CHOP). ""Because we found links to the same receptor in patients with PTSD, we may have insights into developing more effective treatments for human psychiatric disorders."" The research appeared online July 17, 2019 in Nature Communications. Bhatnagar leads CHOP's Stress Neurobiology Program, which includes first author Brian F. Corbett, PhD, of CHOP, who performed much of the laboratory analysis. Other key collaborators were psychiatrists Philip Gerhman, MD, and Richard Ross, MD, of the Perelman School of Medicine at the University of Pennsylvania, who are attending physicians at the Corporal Michael J. Crescenz Veterans Affairs Medical Center in Philadelphia. The researchers focused on the sphingosine-1-phosphate receptor 3 (S1PR3), a lipid molecule found on cell membranes that is active in many cellular processes, including inflammation, cell migration and proliferation. It is one of a broader set of molecules called sphingolipid receptors. Scientists previously knew little about S1PR3's function in the brain. Bhatnagar said the current study points to this receptor as important in neural signaling, and added, ""We found that manipulating SIRPR3 levels affected how well animals cope with stress."" Because current psychiatric treatments succeed in only a subset of patients with stress-related psychiatric disorders, neurobiologists often model stress in laboratory animals, such as rats, to understand what makes some animals vulnerable to stress and others more resilient. Social hierarchies and territoriality are sources of stress in rats. Bhatnagar's team used validated behavioral tools, such as a forced swim test or a social defeat test, to investigate how rats use coping strategies to deal with stress. Rats that cope more passively, showing anxiety- and depressive-type behaviors, are classified as vulnerable; those that cope more actively are classified as resilient. In the current study, the researchers detected higher levels of the S1PR3 protein in resilient rats and lower levels in the vulnerable group. The study team then adjusted the expression of the S1PR3 gene to raise or reduce the gene's product -- the S1PR3 protein. Their results confirmed that increasing the protein levels increased stress-resilient behaviors, while ""knocking down"" or reducing protein levels raised vulnerable behaviors. The scientists also measured S1PR3 levels in the blood of patients at the Veterans Affairs hospital, all of whom had experienced combat. The veterans with PTSD had lower levels of S1PR3 than those without PTSD. Furthermore, those with more severe PTSD symptoms had lower levels of S1PR3. ""Our findings in both laboratory models and patients suggest that this protein is a potential blood-based biomarker for PTSD,"" said Bhatnagar. She added that follow-up studies in larger patient samples will be necessary to validate these initial findings. ""If we can establish that SIPR3 or related sphingolipid receptors are valid biomarkers for PTSD and other stress-related disorders, we may have a new tool to predict a person's risk for PTSD, or to predict the severity of a patient's symptoms. It may help us to better evaluate potential treatments, and perhaps to design better treatments,"" she added. "
Science Daily,Promising New Target to Combat Alzheimer's Disease,Mind & Brain,2019-09-03,-,https://www.sciencedaily.com/releases/2019/09/190903153827.htm,"   The new research, published online in the journal Nature Communications, is the first to link maladaptive changes in calcium transport by mitochondria -- the energy-generating powerhouses of cells -- to the progression of Alzheimer's disease. ""Amyloid-beta deposition and tau pathology are considered the major contributors to Alzheimer's disease and, as a result, they have been the main focus of therapeutic development,"" explained John W. Elrod, PhD, Associate Professor in the Center for Translational Medicine at LKSOM and senior investigator on the new study. ""Large clinical trials targeting these pathways have universally failed, however."" Altered calcium regulation and metabolic dysfunction have been suspected of contributing to neuronal dysfunction and Alzheimer's development. ""But up to now, no one has investigated the impact of altered calcium transport into and out of the mitochondria on the progression of Alzheimer's disease,"" Dr. Elrod noted. ""Our current study provides a missing link between these two hypotheses of Alzheimer's pathogenesis."" Calcium transport into mitochondria plays an important part in many cellular functions and requires the involvement of multiple proteins to be carried out effectively. Among the key regulators of this process is a protein known as NCLX, which previously was discovered by Dr. Elrod's laboratory to mediate calcium efflux from heart cells. NCLX expression is also important in mitochondrial calcium efflux in neurons. In their new study, Dr. Elrod and colleagues examined the role of mitochondrial calcium uptake by neurons in Alzheimer's disease. To do so, the team used a mouse model of familial Alzheimer's disease in which animals harbored three gene mutations that give rise to age-progressive pathology comparable to Alzheimer's progression in human patients. As mice carrying the three mutations aged, the researchers observed a steady reduction in NCLX expression. This reduction was accompanied by decreases in the expression of proteins that limit mitochondrial calcium uptake, resulting in damaging calcium overload. NCLX loss was further linked to increases in the production of cell-damaging oxidants. To better understand the physiological relevance of NCLX loss, Dr. Elrod's team next completely eliminated NCLX expression in the forebrain of Alzheimer's disease mice. In tests for memory and cognitive function, the animals exhibited significant impairments. Analyses of brain tissue from these mice showed that NCLX reduction and the consequent loss of calcium efflux from mitochondria accelerated the development of amyloid beta and tau pathology. When NCLX expression was restored, levels of harmful protein aggregates declined, neuronal mitochondrial calcium homeostasis was reestablished, and mice were rescued from cognitive decline. ""Our findings indicate that maladaptive remodeling of pathways to compensate for abnormalities in calcium regulation, which perhaps are meant to maintain energy production in cells, lead to neuronal dysfunction and Alzheimer's pathology,"" Dr. Elrod said. ""Moreover, our data suggest that amyloid beta and tau pathology actually lie downstream of mitochondrial dysfunction in the progression of Alzheimer's disease, which opens up a new therapeutic angle."" Dr. Elrod and colleagues plan next to carry out a more detailed investigation of metabolic dysfunction that arises before Alzheimer's disease pathology emerges. "
Science Daily,New Way to Reduce Food Waste,Mind & Brain,2019-09-03,-,https://www.sciencedaily.com/releases/2019/09/190903153825.htm,"   That, in turn, raises the cost and environmental impact of feeding the world's population. Researchers are suggesting a potential solution -- they found that 'humanizing' produce can change consumer attitudes toward fresh fruits and vegetables that are showing signs of age. The work, published in the Journal of the Association for Consumer Research, found that depicting imperfect-looking but still nutritious produce with human characteristics enhanced the food's appeal. ""We suggest that when old produce is humanized, it is evaluated more favorably, since it leads consumers to evaluate the old produce with a more compassionate lens,"" the researchers wrote. Vanessa Patrick, Bauer Professor of Marketing at the University of Houston and a coauthor on the paper, said the researchers examined how attitudes toward human aging -- ""old is gold,"" vs. ""young is good"" -- translated to attitudes toward so-called ""mature"" produce. The project involved anthropomorphizing bananas, cucumbers and zucchini, or depicting the produce in ways that suggest human-like traits. Bananas, for example, were depicted sunbathing while reclining in a chaise. Cucumber slices were used to create a picture of a human face. ""With fresh produce, aging promotes visible changes, much as it does in humans,"" Patrick said. ""That can create a connection with human qualities of aging when the food is anthropomorphized."" In the study, participants were shown depictions of both fresh and slightly-past-its-prime produce in both anthropomorphized and unadorned states. Those who saw the anthropomorphized aging produce rated it as more desirable than participants who saw the same produce without the anthropomorphic effects. Anthropomorphism didn't affect perceptions of fresh produce. The researchers said the results suggest grocery store managers and other marketers should consider using similar strategies to promote produce that has begun to show signs of aging but remains nutritious and tasty. ""Making food that would otherwise go to waste more appealing to consumers may allow store managers to avoid having to reduce the price for that older produce, which would improve the bottom line,"" Patrick said. "
Science Daily,Diet's Effect on Gut Bacteria Could Play Role in Reducing Alzheimer's Risk,Mind & Brain,2019-09-03,-,https://www.sciencedaily.com/releases/2019/09/190903120514.htm,"   According to researchers at Wake Forest School of Medicine, that is a fair possibility. In a small pilot study, the researchers identified several distinct gut microbiome signatures -- the chemicals produced by bacteria -- in study participants with mild cognitive impairment (MCI) but not in their counterparts with normal cognition, and found that these bacterial signatures correlated with higher levels of markers of Alzheimer's disease in the cerebrospinal fluid of the participants with MCI. Through cross-group dietary intervention, the study also showed that a modified Mediterranean-ketogenic diet produced changes in the gut microbiome and its metabolites that correlated with reduced levels of Alzheimer's markers in the members of both study groups. The study appears in the current issue of EBioMedicine, a journal published by The Lancet. ""The relationship of the gut microbiome and diet to neurodegenerative diseases has recently received considerable attention, and this study suggests that Alzheimer's disease is associated with specific changes in gut bacteria and that a type of ketogenic Mediterranean diet can affect the microbiome in ways that could impact the development od dementia,"" said Hariom Yadav, Ph.D., assistant professor of molecular medicine at Wake Forest School of Medicine, who co-authored the study with Suzanne Craft, Ph.D., professor gerontology and geriatric medicine at the medical school and director of Wake Forest Baptist Health's Alzheimer's Disease Research Center. The randomized, double-blind, single-site study involved 17 older adults, 11 with diagnosed MCI and six with normal cognition. These participants were randomly assigned to follow either the low-carbohydrate modified Mediterranean-ketogenic diet or a low-fat, higher carbohydrate diet for six weeks then, after a six-week ""washout"" period, to switch to the other diet. Gut microbiome, fecal short-chain fatty acids and markers of Alzheimer's, including amyloid and tau proteins, in cerebrospinal fluid were measured before and after each dieting period. The study's limitations include the subject group's size, which also accounts for the lack of diversity in terms of gender, ethnicity and age. ""Our findings provide important information that future interventional and clinical studies can be based on,"" Yadav said. ""Determining the specific role these gut microbiome signatures have in the progression of Alzheimer's disease could lead to novel nutritional and therapeutic approaches that would be effective against the disease."" The research was supported by grant P30 AG049638 and award R01 AG055122 from the National Institute on Aging, Department of Defense grant W81XWH-18-1-0118, National Center for Advancing Translational Sciences grant UL1 TR001420 and a grant from the Hartman Family Foundation. "
Science Daily,Natural Ways of Cooling Cities,Matter & Energy,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904165242.htm,"   Urban heat islands are a phenomenon where the temperature in a city is noticeably higher than in the surrounding rural area. When combined with the sort of heatwave that hit many parts of Europe at the beginning of July, urban heat can pose a real threat to the elderly, sick or other vulnerable people. Scientists at ETH Zurich have researched urban heat islands across the globe and have found that the effectiveness of heat-reduction strategies in cities varies depending on the regional climate. ""We already know that plants create a more pleasant environment in a city, but we wanted to quantify how many green spaces are actually needed to produce a significant cooling effect,"" says Gabriele Manoli, former postdoc with the Chair of Hydrology and Water Resources Management at ETH Zurich and lead author of the recently published article in the journal Nature. More green spaces: not always the most efficient solution Manoli and his colleagues from ETH Zurich, Princeton University and Duke University studied data from some 30,000 cities worldwide and their surrounding environment, taking into consideration the average summer temperature, the population size and the annual rainfall. The urban heat island phenomenon is more pronounced the bigger the city and the more rainfall in that region. As a general rule, more rain encourages plant growth in the surrounding area, making this cooler than the city. This effect is the strongest when annual rainfall averages around 1500 millimetres as in Tokyo, but does not increase further with more rain. Two climate extremes illustrate well the role of vegetation on the urban heat island phenomenon: very dry regions on the one hand, and tropical areas on the other. Through carefully targeted planting, a city like Phoenix in the USA could achieve cooler temperatures than the surrounding countryside, where conditions are almost desert-like. By comparison, a city surrounded by tropical forests, such as Singapore, would need far more green spaces to reduce temperatures, but this would also create more humidity. In cities located in tropical zones, other cooling methods are therefore expected to be more effective, such as increased wind circulation, more use of shade and new heat-dispersing materials. ""There is no single solution,"" Manoli says. ""It all depends on the surrounding environment and regional climate characteristics."" Useful information for city planners Manoli explains that the main benefit of the study is a preliminary classification of cities, in the form of a clear visualisation guiding planners on possible approaches to mitigate the urban heat island effect. ""Even so, searching for solutions to reduce temperatures in specific cities will require additional analysis and in-depth understanding of the microclimate,"" he stresses. ""Such information, however, is based on data and models available to city planners and decision-makers only in a handful of cities, such as Zurich, Singapore or London."" Manoli is currently analysing data from other periods of the year and is studying which types of plant are most suitable for reducing temperatures. The support provided by the Branco Weiss Fellowship allowed the environmental engineer to work with scientists from the areas of physics, urban studies and social sciences with a specific focus on interdisciplinary research topics. "
Science Daily,New Material State: Quantum Disordered Liquid-Like Magnetic Moments,Matter & Energy,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904165240.htm,"   In the paper ""Field-tunable quantum disordered ground state in the triangular-lattice antiferromagnet NaYbO2,"" published in the journal Nature Physics, Wilson and colleagues Leon Balents, of the campus's Kavli Institute for Theoretical Physics, and Mark Sherwin, a professor in the Department of Physics, describe their discovery of a long-sought ""quantum spin liquid state"" in the material NaYbO2 (sodium ytterbium oxide). The study was led by materials student Mitchell Bordelon and also involved physics students Chunxiao Liu, Marzieh Kavand and Yuanqi Lyu, and undergraduate chemistry student Lorenzo Posthuma, as well as collaborators at Boston College and at the U.S. National Institute of Standards and Technology. At the atomic level, electrons in one material's lattice structure behave differently, both individually and collectively, from those in another material. Specifically, the ""spin,"" or the electron's intrinsic magnetic moment (akin to an innate bar magnet) and its tendency to communicate and coordinate with the magnetic moments of nearby electrons differs by material. Various types of spin systems and collective patterns of ordering of these moments are known to occur, and materials scientists are ever seeking new ones, including those that have been hypothesized but not yet shown to exist. ""There are certain, more classical moments that let you know to a very high degree of certainty that the spin is pointing in a particular direction,"" Wilson explained. ""In those, the quantum effects are small. But there are certain moments where the quantum effects are large, and you can't precisely orient the spin, so there is uncertainty, which we call 'quantum fluctuation.'"" Quantum magnetic states are those in which the magnetism of a material is primarily driven by such quantum fluctuations, generally derived from the uncertainty principle, intrinsic to magnetic moments. ""So, you envision a magnetic moment, but the uncertainty principle says that I can't perfectly orient that in any one direction,"" Wilson noted. Explaining the quantum spin liquid state, which was proposed long ago and is the subject of this paper, Wilson said, ""In conventional materials, the magnetic moments talk to one another and want to orient relative to one another to form some pattern of order."" In classical materials, this order is disrupted by thermal fluctuations, what Wilson describes as ""just heat from the environment."" ""If the material is warm enough, it is nonmagnetic, meaning the moments are all sort of jumbled relative to one another,"" he explained. ""Once the material is cooled, the moments start to communicate, such that their connection to one another outcompetes the thermal fluctuations and they form an ordered state. That's classical magnetism."" But things are different in the quantum world, and magnetic moments that fluctuate can actually be the inherent ""ground state"" of a material. ""So, you can ask if there is a magnetic state in which the moments are precluded from freezing or forming some pattern of long-range order relative to one another, not by thermal fluctuations, but instead, by quantum fluctuations,"" Wilson said. ""Quantum fluctuations become more relevant as a material cools, while thermal fluctuations increase as it heats up, so you want to find a magnet that doesn't order until you can get it cool enough such that the quantum fluctuations preclude it from ever ordering."" That quantum disorder is desirable because it is associated with entanglement, the quantum mechanical quality that makes it possible to encode quantum information. To determine whether NaYbO2 might exhibit that characteristic, the researchers had to determine the intrinsic, or ground state of the material's magnetic moments when all thermal fluctuations are removed. In this particular system, Wilson was able to determine experimentally that the magnetic moments are intrinsically in a fluctuating, disordered state, thus confirming that a quantum disordered state exists. To find the hypothesized state, said Wilson, ""First you have to put highly quantum magnetic moments into a material, but your material needs to be constructed such that the moments don't want to order. You do that by using the principle of 'magnetic frustration.'"" A simple way to think of that, according to Wilson, is to imagine a single triangle in the lattice structure of the material. ""Let's say I build my material so that the magnetic moments are all located on a triangular lattice,"" he said, ""and they all talk to one another in a way that has them wanting to orient antiferromagnetically, or antiparallel, to one another."" In that arrangement, any adjacent moment on the triangle wants to orient antiparallel to its neighbor. But because there are an odd number of points, you have one up at one point and one down (antiparallel to the first) at the second point, meaning that the third moment has a differently oriented moment on each side, so it doesn't know what to do. All of the moments are competing with one another. ""That's magnetic frustration, and, as it turns out, it reduces the temperature at which the moments are finally able to find some arrangement they all agree on,"" Wilson said. ""So, for instance, classically, nature decides that at some temperature the mismatched moments agree that they will all point to 120 degrees relative to each other. So they're not all 100 percent happy but it's some compromise that establishes an ordered state."" From there, he added, ""The idea is to take a frustrated lattice where you have already suppressed the ordered state, and add quantum fluctuations to it, which take over as you cool the material. Magnetic frustration lowers the ordering temperature enough so that quantum fluctuations eventually take over and the system can stabilize into a fundamentally disordered quantum spin state."" Wilson continued: ""That's the paradigm of what people are looking for; however, some materials may seem to display this state when actually, they don't. For instance, all real materials have disorder, such as chemical or structural disorder, and this can also prevent the magnetic moments from talking to each other effectively and becoming ordered. In such a case, Wilson says, ""They might form a disordered state, but it's more of a frozen, or static, disordered state than it is a dynamic quantum state. ""So, if I have a magnetic system that doesn't order at the lowest temperatures I can measure, it can be tricky trying to understand whether what I'm measuring is an intrinsic quantum spin liquid fluctuating type of state or a frozen, extrinsic, chemically driven disordered state. That is always debated."" Among the most interesting findings about this new material, Wilson said, is that even at the lowest measurable temperature -- .005 degree Centigrade above absolute zero -- it still doesn't order. ""However, in this material we can also apply a magnetic field, which breaks this competition engendered by magnetic frustration, and then we can drive it to order, inducing a special kind of antiferromagnetic state,"" he added. ""The reason that's important is because this special state is very delicate and a very good fingerprint for how much chemical disorder there is in the system and its influence on the magnetic ground state. The fact that we can drive this field-driven state tells us that the disordered state we see at low temperature with zero magnetic field is indeed an intrinsically quantum disordered state, consistent with being a quantum spin liquid state."" "
Science Daily,Biophysics: Stretching Proteins With Magnetic Tweezers,Matter & Energy,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904113217.htm,"   The mechanical forces required to activate proteins like VWF are often so small that their magnitude could not be determined using existing methods. Now, a team of scientists led by LMU physicists Martin Benoit and Professor Jan Lipfert has developed a much more sensitive procedure. Their 'magnetic tweezers' can quantify forces that are 100 times smaller than the commonly used alternative method currently available. As Lipfert and colleagues report in the journal PNAS, they have employed the technique to observe the unfolding of the VWF protein under the influence of low mechanical forces. A powerful approach to study mechanoregulation is so-called protein force spectroscopy. This involves tugging on an individual protein molecule and observing how an applied force alters its three-dimensional structure. Up to now, the method of choice for pulling has been an atomic force microscope, which works best in the range of 100 piconewton (pN). ""However, many molecular processes are activated by forces that are much weaker than that,"" says Lipfert. ""So for measurements at the level of single molecules, we need more sensitive instrumentation -- there's little point in using a bathroom scale to weigh out the ingredients of a cake."" The researchers developed a method in which the proteins are attached at one end to a glass surface and carry a tag at the other end that binds to tiny magnetic beads and the assembly is then subjected to an externa magnetic field. Extension of the protein induced by the field results in the vertical displacement of each bead, which can be detected by microscopy. ""This sort of set-up is referred to as magnetic tweezers,"" Lipfert explains. ""It has the great advantage that it allows us to apply and resolve very weak forces -- significantly less than 1 piconewton -- to the protein of interest. In addition, magnetic tweezers enable very stable measurements over long periods of time -- up to one week!"" To test the new method, the LMU group used VWF as their target protein. In the bloodstream, VWF circulates as a multimer of dimers that are made of two identical subunits. Under normal conditions of blood flow, it has a relatively compact globular form. However, any increase in the shear forces in the bloodstream owing to injury of the vasculature causes vWF to unfold. This exposes binding sites for receptors on blood platelets. Binding of VWF to platelets in turn triggers a reaction cascade that leads to clotting, which seals the wound. ""The cascade is induced by the action on the molecule of mechanical forces acting that are much weaker than those that have been measured up to now,"" says Lipfert. Analysis of the unzipping of VWF dimers with magnetic tweezers showed that the so-called VWF stem opens up under an applied force of less than 1 pN, when the subunits of the dimer are pulled apart like the two halves of a zipper. ""We assume that this pattern of behavior, which we were able to observe for the first time, represents the first step in blood coagulation,"" says Lipfert. ""Our approach provides a detailed picture of the forces and the changes in extension involved in unfolding the protein. We are confident that future application of the method will contribute to a better understanding of the mode of action of VWF and of the role of clinically relevant mutations."" "
Science Daily,Laser-Based Ultrasound Approach Provides New Direction for Nondestructive Testing,Matter & Energy,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904102631.htm,"   A team of researchers is using ultrasonic nondestructive testing (NDT) that involves amplifying the signal from a photoacoustic laser source using laser-absorbing patch made from an array of nanoparticles from candle soot and polydimethylsiloxane. They discuss their work in this week's Applied Physics Letters, from AIP Publishing. The approach marks one of the first NDT systems that combines elements of contact and noncontact ultrasound testing. The results of generating such ultrasonic waves with the photoacoustic patch demonstrate the promise of the broad range of noncontact applications for NDT. ""Laser-based NDT method has advantages of temperature-independent measurement and wide range of monitoring area by easily changing the position of devices,"" said Taeyang Kim, an author on the paper. ""This technique provides a very flexible and simple method for noncontact and remote generation of ultrasonic surface waves."" Ultrasound waves can be made when a high-powered laser strikes a surface. The heat produced by the pulses induces a pattern of expansion and compression on the illuminated area, yielding an ultrasonic signal. The waves produced, called Lamb waves, then travel through material as an elastic wave. The group used the candle soot nanoparticles paired with polydimethylsiloxane to absorb the laser. They turned to candle soot because it is readily available and efficient at absorbing lasers and can produce the elastic expansion needed to make the photoacoustic conversion that generates the Lamb wave. By placing the particle in the patch in a line array, they were able to narrow the bandwidth of the waves, filtering out unwanted wave signals and increasing analytical accuracy. The researchers opted for an aluminum sensing system for the receiving transducer. The patch increased the amplitude by more than twofold over conditions without the patch and confirmed it produced narrower bandwidth than other conditions. Kim said the question of how the approach's durability in an industrial setting remains, as well as how well the patches perform on curved and rough surfaces. ""New NDT systems will attract more attention to explore the optimal materials for the patch or various applications for NDT industries,"" he said. Next, the team looks to test the system in high-temperature nondestructive testing scenarios. "
Science Daily,New Insulation Technique Paves the Way for More Powerful and Smaller Chips,Matter & Energy,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904100759.htm,"   Computer chips are getting increasingly smaller. That's not new: Gordon Moore, one of the founders of chip manufacturer Intel, already predicted it in 1965. Moore's law states that the number of transistors in a chip, or integrated circuit, doubles about every two years. This prognosis was later adjusted to 18 months, but the theory still stands. Chips are getting smaller and their processing power is increasing. Nowadays, a chip can have over a billion transistors. But this continued reduction in size also brings with it a number of obstacles. The switches and wires are packed together so tightly that they generate more resistance. This, in turn, causes the chip to consume more energy to send signals. To have a well-functioning chip, you need an insulating substance that separates the wires from each other, and ensures that the electrical signals are not disrupted. However, that's not an easy thing to achieve at the nanoscale level. Nanoporous crystals A study led by KU Leuven professor Rob Ameloot (Department of Microbial and Molecular systems) shows that a new technique might provide the solution. ""We're using metal-organic frameworks (MOFs) as the insulating substance. These are materials that consist of metal ions and organic molecules. Together, they form a crystal that is porous yet sturdy."" For the first time, a research team at KU Leuven and imec managed to apply the MOF insulation to electronic material. An industrial method called chemical vapour deposition was used for this, says postdoctoral researcher Mikhail Krishtab (Department of Microbial and Molecular systems). ""First, we place an oxide film on the surface. Then, we let it react with vapour of the organic material. This reaction causes the material to expand, forming the nanoporous crystals."" ""The main advantage of this method is that it's bottom-up,"" says Krishtab. ""We first deposit an oxide film, which then swells up to a very porous MOF material. You can compare it to a souffl√©; that puffs up in the oven and becomes very light. The MOF material forms a porous structure that fills all the gaps between the conductors. That's how we know the insulation is complete and homogeneous. With other, top-down methods, there's always still the risk of small gaps in the insulation."" Powerful and energy efficient Professor Ameloot's research group has received an ERC Proof of Concept grant to further develop the technique, in collaboration with Silvia Armini from imec's team working on advanced dielectric materials for nanochips. ""At imec, we have the expertise to develop wafer-based solutions, scaling technologies from lab to fab and paving the way to realising a manufacturable solution for the microelectronics industry."" ""We've shown that the MOF material has the right properties,"" Ameloot continues. ""Now, we just have to refine the finishing. The surface of the crystals is still irregular at the moment. We have to smoothen this to integrate the material in a chip."" Once the technique has been perfected, it can be used to create powerful, small chips that consume less energy. Ameloot: ""Various AI applications require a lot of processing power. Think of self-driving cars and smart cities. Technology companies are constantly looking for new solutions that are both quick and energy efficient. Our research can be a valuable contribution to a new generation of chips."" "
Science Daily,Electronic Glove Offers 'Humanlike' Features for Prosthetic Hand Users,Matter & Energy,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904081320.htm,"   An electronic glove, or e-glove, developed by Purdue University researchers can be worn over a prosthetic hand to provide humanlike softness, warmth, appearance and sensory perception, such as the ability to sense pressure, temperature and hydration. The technology is published in the Aug. 30 edition of NPG Asia Materials. While a conventional prosthetic hand helps restore mobility, the new e-glove advances the technology by offering the realistic human hand-like features in daily activities and life roles, with the potential to improve their mental health and wellbeing by helping them more naturally integrate into social contexts. The e-glove uses thin, flexible electronic sensors and miniaturized silicon-based circuit chips on the commercially available nitrile glove. The e-glove is connected to a specially designed wristwatch, allowing for real-time display of sensory data and remote transmission to the user for post-data processing. Chi Hwan Lee, an assistant professor in Purdue's College of Engineering, in collaboration with other researchers at Purdue, the University of Georgia and the University of Texas, worked on the development of the e-glove technology. ""We developed a novel concept of the soft-packaged, sensor-instrumented e-glove built on a commercial nitrile glove, allowing it to seamlessly fit on arbitrary hand shapes,"" Lee said. ""The e-glove is configured with a stretchable form of multimodal sensors to collect various information such as pressure, temperature, humidity and electrophysiological biosignals, while simultaneously providing realistic human hand-like softness, appearance and even warmth."" Lee and his team hope that the appearance and capabilities of the e-glove will improve the well-being of prosthetic hand users by allowing them to feel more comfortable in social contexts. The glove is available in different skin tone colors, has lifelike fingerprints and artificial fingernails. ""The prospective end user could be any prosthetic hand users who have felt uncomfortable wearing current prosthetic hands, especially in many social contexts,"" Lee said. The fabrication process of the e-glove is cost-effective and manufacturable in high volume, making it an affordable option for users unlike other emerging technologies with mind, voice and muscle control embedded within the prosthetic at a high cost. Additionally, these emerging technologies do not provide the humanlike features that the e-glove provides. Lee and Min Ku Kim, an engineering doctoral student at Purdue and a co-author on the paper, have worked to patent the technology with the Purdue Research Foundation Office of Technology Commercialization. The team is seeking partners to collaborate in clinical trials or experts in the prosthetics field to validate the use of the e-glove and to continue optimizing the design of the glove. A video about the technology is available at https://youtu.be/lF1VYzKagNo. "
Science Daily,Secret Messages Hidden in Light-Sensitive Polymers,Matter & Energy,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904081316.htm,"   In a leap forward in this field, researchers at the Institut Charles Sadron (CNRS) and the Institut de Chimie Radicalaire (CNRS/Aix-Marseille Universit√©) have developed light-sensitive polymers where light can change the information stored on the molecular scale. Three types of information change have been shown in this work: revealing, changing and erasing a message. These French scientists have shown that some polymers can act like invisible ink: when exposed to the appropriate wavelength, their monomers are transformed, and the sequence becomes legible. The message only appears if it is subjected to the right light source. This is the first example of a secret message stored on a molecule. This study also shows that monomers being changed by light can be used to erase or change the information contained in some polymers. Chemists have for example 'transformed copper into gold' by changing the chemical symbol for copper written on a polymer, Cu, into the chemical symbol for gold, Au. The polymers are 'read' using mass spectrometry, a technology used routinely in many analytical laboratories. The teams involved in this recent work now wish to continue it by exploring how to control the physical properties of the polymers using light, for applications other than information storage and decoding, such as design of new materials. - A polymer is composed of simple chemical units, monomers. A polymer can take the shape of a sequence of two different monomers that can be read as 0 or 1 in a message written in binary notation. "
Science Daily,Surgical Masks as Good as Respirators for Flu and Respiratory Virus Protection,Matter & Energy,2019-09-03,-,https://www.sciencedaily.com/releases/2019/09/190903134732.htm,"   A study published today in JAMA compared the ubiquitous surgical (or medical) mask, which costs about a dime, to a less commonly used respirator called an N95, which costs around $1. The study reported ""no significant difference in the effectiveness"" of medical masks vs. N95 respirators for prevention of influenza or other viral respiratory illness. ""This study showed there is no difference in incidence of viral respiratory transmission among health care workers wearing the two types of protection,"" said Dr. Trish Perl, Chief of UT Southwestern's Division of Infectious Diseases and Geographic Medicine and the report's senior author. ""This finding is important from a public policy standpoint because it informs about what should be recommended and what kind of protective apparel should be kept available for outbreaks."" Medical personnel -- in particular nurses, doctors, and others with direct patient contact -- are at risk when treating patients with contagious diseases such as influenza (flu). A large study conducted in a New York hospital system after the 2009 outbreak of H1N1, or swine flu, found almost 30 percent of health care workers in emergency departments contracted the disease themselves, Dr. Perl said. During that pandemic, the U.S. Centers for Disease Control and Prevention (CDC) recommended using the tighter-fitting N95 respirators, designed to fit closely over the nose and mouth and filter at least 95 percent of airborne particles, rather than the looser-fitting surgical masks routinely worn by health care workers, Dr. Perl said. But some facilities had trouble replenishing N95s as supplies were used. In addition, there are concerns health care workers might be less vigilant about wearing the N95 respirators since many perceive them to be less comfortable than medical masks, such as making it harder to breathe and being warmer on the wearer's face. Earlier clinical studies comparing the masks and respirators yielded mixed results, said Dr. Perl, also a Professor of Internal Medicine who holds the Jay P. Sanford Professorship in Infectious Diseases. The new study was performed at multiple medical settings in seven cities around the country, including Houston, Denver, Washington, and New York, by researchers at the University of Texas, the CDC, Johns Hopkins University, the University of Colorado, Children's Hospital Colorado, the University of Massachusetts, the University of Florida, and several Department of Veterans Affairs hospitals. Researchers collected data during four flu seasons between 2011 and 2015, examining the incidence of flu and acute respiratory illnesses in the almost 2,400 health care workers who completed the study. The project was funded by the CDC, the Veterans Health Administration, and the Biomedical Advanced Research and Development Authority (BARDA), which is part of the U.S. Health and Human Services Department and was founded in the years after Sept. 11, 2001, to help secure the nation against biological and other threats. ""It was a huge and important study -- the largest ever done on this issue in North America,"" Dr. Perl said. In the end, 207 laboratory-confirmed influenza infections occurred in the N95 groups versus 193 among medical mask wearers, according to the report. In addition, there were 2,734 cases of influenza-like symptoms, laboratory-confirmed respiratory illnesses, and acute or laboratory-detected respiratory infections (where the worker may not have felt ill) in the N95 groups, compared with 3,039 such events among medical mask wearers. ""The takeaway is that this study shows one type of protective equipment is not superior to the other,"" she said. ""Facilities have several options to provide protection to their staff -- which include surgical masks -- and can feel that staff are protected from seasonal influenza. Our study supports that in the outpatient setting there was no difference between the tested protections."" Dr. Perl said she expects more studies to arise from the data collected in this report; she now plans to investigate the dynamics of virus transmission to better understand how respiratory viruses are spread. "
Science Daily,"Remora-Inspired Suction Disk Mimics Fish's Adhesion Ability, Offers Evolutionary Insight",Matter & Energy,2019-09-03,-,https://www.sciencedaily.com/releases/2019/09/190903162537.htm,"   Key to the remora's adhesion are the disk's well-known capabilities for generating suction, as well as friction created by spiky bones within the disk called lamellae to maintain hold on its host. However, the factors driving the evolution of remora's unique disc morphology have long eluded researchers seeking to understand, and even engineer new devices and adhesives that mimic, the fish's uncanny ability to lock on to various surface types without harming their host or expending much energy, often for hours at a time under extreme oceanic forces. In a study led at New Jersey Institute of Technology (NJIT), researchers have showcased a new biologically inspired remora disc capable of replicating the passive forces of suction and friction that power the fish's ability, demonstrating up to 60% greater hold than has been measured for live remoras attached to shark skin. Using the disc model to explore evolutionary drivers of the remora's disc, researchers say the study's findings provide evidence that today's living species of remora have evolved a greater number of lamellae over time to enhance their holding power and ability to attach to a broader range of hosts with smoother surfaces, thereby increasing their chance for survival. The study, featured in Bioinspiration and Biomimetics, indicates the disc model may be used to inform the design of more effective, lower-cost adhesive technologies in the future. ""The beauty behind the remora's adhesive mechanism is that biological tissues inherently do most of the work,"" said Brooke Flammang, professor of biological sciences at NJIT who led the study. ""The most significant aspect of this research is that our robotic disc relies completely on the fundamental physics driving the adhesive mechanism in remoras, allowing us to determine biologically relevant performance and gain insight into the evolution of the remora's disc. This was previously not possible with past designs that required a human operator to control the system."" Diverging from many of their closest scavenger-like ancestors, such as cobia (Rachycentron canadum), the remora fish (of the family Echeneidae) is believed to have first begun attaching to hosts with rough surfaces, akin to sharks, after having evolved its suction disc from dorsal fin spines nearly 32 million years ago. The disc of living remoras today now features a fleshy-soft outer lip for suction while the disc's interior houses many more linear rows of tissue (lamellae) with tooth-like tissue projections (spinules), which the fish raises to generate friction against various host bodies to prevent slipping during hitchhiking. According to Flammang, while scientists have shed some light on the origins of the remora's modified fin structure, fundamental aspects of the disk's evolution have largely remained unclear. ""The evolution of the remora's disc is largely unknown,"" said Flammang. ""There is one fossil remora, Opisthomyzon, in the fossil record that has a disc with fewer lamellae [than today's remoras] without spinules towards the back of the head."" Flammang says this raises two questions: ""how"" and ""why."" ""The 'how' is from the dorsal fin, although the intermediate evolutionary stages aren't known,"" explained Flammang. ""If you look at a phylogeny of remoras it shows that those species that are thought to be more derived have more lamellae ... the 'why' has been assumed to be for adhesive performance, but that was never tested before this paper."" To learn more, Kaelyn Gamel, the study's first author and former graduate researcher in the Flammang lab, designed a remora-inspired disc from commercially available 3-D printed materials that could autonomously maintain attachment to various surfaces and be modified by adding and removing lamellae, enabling the team to investigate the performance of increased lamellar number on shear adhesion. ""Our disc's capability to add and remove lamellae while acting as a passive system allowed us to change the amount of friction along with the ambient pressure within the disc,"" said Gamel, now a Ph.D. researcher at the University of Akron. ""We were able to compare the difference between no friction, some friction and a lot of friction based on the variation in lamellae number."" In collaboration with Austin Garner, a researcher at the University of Akron, the team conducted pull-off tests with their model disc underwater, experimenting with the model's lamellar number (up to 12 lamellae) to measure the shear force and time it took to pull the disc from silicon molds with surfaces ranging from completely smooth to those exceeding shark skin roughness (350-grit, 180-grit and 100-grit). Overall, the team found that their disc's adhesive performance was strongly correlated with an increase in the disc's lamellae, observing a ""sweet spot"" in suction power between nine and 12 lamellae. When modified to 12 lamellae and 294 spinules, the team's disc weighed just 45 grams and withstood 27 N (newton) forces for 50 seconds -- almost three times the force that would typically pull a remora from a shark. The tests also revealed a minimum of six lamellae -- the number coincidentally found on the 32-million-year-old fossil Opisthomyzon -- were needed to maintain adhesion. ""What is most striking about these results is that for a given disc shape, there is an optimal range in which the friction and suction phenomena are balanced, and [as their disc size has gotten longer] remoras have evolved to maintain this sweet spot of high-performance adhesion,"" explained Flammang. The team now says their remora disk model will be used for future evolutionary studies to learn whether suction or friction predominated attachment in earliest remora ancestors and how evolution of disc shape affects adhesion. The disc may also have engineering applications in everything from medical biosensors and drug delivery devices to geo-sensing tags for ecological studies and tracking marine life. ""One of the greatest advantages to our design is that it operates autonomously because it relies only on the physics of the system for operation,"" said Flammang. ""This makes it easily scalable for a multitude of new technologies, both for medical and scientific purposes."" "
Science Daily,Explosive Fireballs: Never-Before-Seen Insight,Matter & Energy,2019-09-03,-,https://www.sciencedaily.com/releases/2019/09/190903153819.htm,"   The ability to measure and monitor the dramatic changes during explosions could help scientists understand and even control them. Measurements using rugged temperature or pressure probes placed inside an exploding fireball can provide physical data but cannot measure chemical changes that may be generated during the explosion. Sampling the end products of a detonation is possible but provides information only once the explosion is over. In this work, molecules in the fireball are detected by monitoring the way they interact with light, especially in the infrared region. These measurements are fast and can be taken a safe distance away. Since fireballs are turbulent and full of strongly absorbing substances, lasers are needed. Using a new instrument built in their lab, the investigators measured explosive events at faster speeds, at higher resolutions and for longer time periods than previously possible using infrared laser light. ""The swept-ECQCL approach enables new measurements by combining the best features of high-resolution tunable laser spectroscopy with broadband methods such as FTIR,"" co-author Mark Phillips explained. The study looked at four types of high-energy explosives, all placed in a specially designed chamber to contain the fireball. A laser beam from the swept-ECQCL was directed through this chamber while rapidly varying the laser light's wavelength. The laser light transmitted through the fireball was recorded throughout each explosion to measure changes in the way infrared light was absorbed by molecules in the fireball. The explosion produces substances such as carbon dioxide, carbon monoxide, water vapor and nitrous oxide. These can all detected by the characteristic way each absorbs infrared light. Detailed analysis of the results provided the investigators with information about temperature and concentrations of these substances throughout the explosive event. They were also able to measure absorption and emission of infrared light from tiny solid particles (soot) created by the explosion. The swept-ECQCL measurements provide a new way to study explosive detonations that could have other uses. In future studies, the investigators hope to extend the measurements to more wavelengths, faster scan rates, and higher resolutions. "
Science Daily,AI Learns to Model Our Universe,Space & Time,2019-08-28,-,https://www.sciencedaily.com/releases/2019/08/190828100554.htm,"   Researchers seek to understand our Universe by making model predictions to match observations. Historically, they have been able to model simple or highly simplified physical systems, jokingly dubbed the ""spherical cows,"" with pencils and paper. Later, the arrival of computers enabled them to model complex phenomena with numerical simulations. For example, researchers have programmed supercomputers to simulate the motion of billions of particles through billions of years of cosmic time, a procedure known as the N-body simulations, in order to study how the Universe evolved to what we observe today. ""Now with machine learning, we have developed the first neural network model of the Universe, and demonstrated there's a third route to making predictions, one that combines the merits of both analytic calculation and numerical simulation,"" said Yin Li, a Postdoctoral Researcher at the Kavli Institute for the Physics and Mathematics of the Universe, University of Tokyo, and jointly the University of California, Berkeley. A comparison of the accuracy of two models of the Universe. The new deep learning model (left), dubbed D3M, is much more accurate than an existing analytic method (right) called 2LPT. The colors represent the error in displacement at each point relative to the numerical simulation, which is accurate but much slower than the deep learning model. At the beginning of our Universe, things were extremely uniform. As time went by, the denser parts grew denser and sparser parts became sparser due to gravity, eventually forming a foam-like structure known as the ""cosmic web."" To study this structure formation process, researchers have tried many methods, including analytic calculations and numerical simulations. Analytic methods are fast, but fail to produce accurate results for large density fluctuations. On the other hand, numerical (N-body) methods simulate structure formation accurately, but tracking gazillions of particles is costly, even on supercomputers. Thus, to model the Universe, scientists often face the accuracy versus efficiency trade-off. However, the explosive growth of observational data in quality and quantity calls for methods that excel in both accuracy and efficiency. To tackle this challenge, a team of researchers from the US, Canada, and Japan, including Li, set their sights on machine learning, a cutting-edge approach to detecting patterns and making predictions. Just as machine learning can transform a young man's portrait into his older self, Li and colleagues asked whether it can also predict how universes evolve based on their early snapshots. They trained a convolutional neural network with simulation data of trillions of cubic light years in volume, and built a deep learning model that was able to mimic the structure formation process. The new model is not only many times more accurate than the analytic methods, but is also much more efficient than the numerical simulations used for its training. ""It has the strengths of both previous [analytic calculation and numerical simulation] methods,"" said Li. Li says the power of AI emulation will scale up in the future. N-body simulations are already heavily optimized, and as a first attempt, his team's AI model still has large room for improvement. Also, more complicated phenomena incur a larger cost on simulation, but not likely so on emulation. Li and his colleagues expect a bigger performance gain from their AI emulator when they move on to including other effects, such as hydrodynamics, into the simulations. ""It won't be long before we can uncover the initial conditions of and the physics encoded in our Universe along this path,"" he said. "
Science Daily,'Radical' Wrinkle in Forming Complex Carbon Molecules in Space,Space & Time,2019-09-03,-,https://www.sciencedaily.com/releases/2019/09/190903134740.htm,"   The team's research has now identified several avenues by which ringed molecules known as polycyclic aromatic hydrocarbons, or PAHs, can form in space. The latest study is a part of an ongoing effort to retrace the chemical steps leading to the formation of complex carbon-containing molecules in deep space. PAHs -- which also occur on Earth in emissions and soot from the combustion of fossil fuels -- could provide clues to the formation of life's chemistry in space as precursors to interstellar nanoparticles. They are estimated to account for about 20 percent of all carbon in our galaxy, and they have the chemical building blocks needed to form 2D and 3D carbon structures. In the latest study, published in Nature Communications, researchers produced a chain of ringed, carbon-containing molecules by combining two highly reactive chemical species that are called free radicals because they contain unpaired electrons. The study ultimately showed how these chemical processes could lead to the development of carbon-containing graphene-type PAHs and 2D nanostructures. Graphene is a one-atom-thick layer of carbon atoms. Importantly, the study showed a way to connect a five-sided (pentagon-shaped) molecular ring with a six-sided (hexagonal) molecular ring and to also convert five-sided molecular rings to six-sided rings, which is a stepping stone to a broader range of large PAH molecules. ""This is something that people have tried to measure experimentally at high temperatures but have not done before,"" said Musahid Ahmed, a scientist in Berkeley Lab's Chemical Sciences Division. He led the chemical-mixing experiments at Berkeley Lab's Advanced Light Source (ALS) with Professor Ralf I. Kaiser at the University of Hawaii at Manoa. ""We believe this is yet another pathway that can give rise to PAHs."" Professor Alexander M. Mebel at Florida International University assisted in the computational work for the study. Previous studies by the same research team have also identified a couple of other pathways for PAHs to develop in space. The studies suggest there could be multiple chemical routes for life's chemistry to take shape in space. ""It could be all the above, so that it isn't just one,"" Ahmed said. ""I think that's what makes this interesting."" The experiments at Berkeley Lab's ALS -- which produces X-rays and other types of light supporting many different types of simultaneous experiments -- used a portable chemical reactor that combines chemicals and then jets them out to study what reactants formed in the heated reactor. Researchers used a light beam tuned to a wavelength known as ""vacuum ultraviolet"" or VUV produced by the ALS, coupled with a detector (called a reflectron time-of-flight mass spectrometer), to identify the chemical compounds jetting out of the reactor at supersonic speeds. The latest study combined the chemical radicals CH3 (aliphatic methyl radical) with C9H7 (aromatic 1-indenyl radical) at a temperature of about 2,105 Fahrenheit degrees to ultimately produce molecules of a PAH known as naphthalene (C10H8) that is composed of two joined benzene rings. The conditions required to produce naphthalene in space are present in the vicinity of carbon-rich stars, the study noted. The reactants produced from two radicals, the study notes, had been theorized but hadn't been demonstrated before in a high-temperature environment because of experimental challenges. ""The radicals are short-lived -- they react with themselves and react with anything else around them,"" Ahmed said. ""The challenge is, 'How do you generate two radicals at the same time and in the same place, in an extremely hot environment?' We heated them up in the reactor, they collided and formed the compounds, and then we expelled them out of the reactor."" Kaiser said, ""For several decades, radical-radical reactions have been speculated to form aromatic structures in combustion flames and in deep space, but there has not been much evidence to support this hypothesis."" He added, ""The present experiment clearly provides scientific evidence that reactions between radicals at elevated temperatures do form aromatic molecules such as naphthalene."" While the method used in this study sought to detail how specific types of chemical compounds form in space, the researchers noted that the methods used can also enlighten broader studies of chemical reactions involving radicals exposed to high temperatures, such as in the fields of materials chemistry and materials synthesis. "
Science Daily,Hints of a Volcanically Active Exo-Moon,Space & Time,2019-08-29,-,https://www.sciencedaily.com/releases/2019/08/190829115425.htm,"   Sodium gas as circumstantial evidence Astronomers have not yet discovered a rocky moon beyond our solar system and it's on the basis of circumstantial evidence that the researchers in Bern conclude that the exo-Io exists: Sodium gas was detected at the WASP 49-b at an anomalously high-altitude. ""The neutral sodium gas is so far away from the planet that it is unlikely to be emitted solely by a planetary wind,"" says Oza. Observations of Jupiter and Io in our solar system, by the international team, along with mass loss calculations show that an exo-Io could be a very plausible source of sodium at WASP 49-b. ""The sodium is right where it should be"" says the astrophysicist. Tides keep the system stable Already in 2006, Bob Johnson of the University of Virginia and the late Patrick Huggins at New York University, USA had shown that large amounts of sodium at an exoplanet could point to a hidden moon or ring of material, and ten years ago, researchers at Virginia calculated that such a compact system of three bodies: star, close-in giant planet and moon, can be stable over billions of years. Apurva Oza was then a student at Virginia, and after his PhD on moons atmospheres in Paris, decided to pick up the theoretical calculations of these researchers. He now publishes the results of his work together with Johnson and colleagues in the Astrophysical Journal. ""The enormous tidal forces in such a system are the key to everything,"" explains the astrophysicist. The energy released by the tides to the planet and its moon keeps the moon's orbit stable, simultaneously heating it up and making it volcanically active. In their work, the researchers were able to show that a small rocky moon can eject more sodium and potassium into space through this extreme volcanism than a large gas planet, especially at high altitudes. ""Sodium and potassium lines are quantum treasures to us astronomers because they are extremely bright,"" says Oza, ""the vintage street lamps that light up our streets with yellow haze, is akin to the gas we are now detecting in the spectra of a dozen exoplanets."" ""We need to find more clues"" The researchers compared their calculations with these observations and found five candidate systems where a hidden exomoon can survive against destructive thermal evaporation. For WASP 49-b the observed data can be best explained by the existence of an exo-Io. However, there are other options. For example, the exoplanet could be surrounded by a ring of ionized gas, or non-thermal processes. ""We need to find more clues,"" Oza admits. The researchers are therefore relying on further observations with ground-based and space-based instruments. ""While the current wave of research is going towards habitability and biosignatures, our signature is a signature of destruction,"" says the astrophysicist. A few of these worlds could be destroyed in a few billion years due to the extreme mass loss. ""The exciting part is that we can monitor these destructive processes in real time, like fireworks,"" says Oza. "
Science Daily,Busy Older Stars Outpace Stellar Youngsters,Space & Time,2019-08-28,-,https://www.sciencedaily.com/releases/2019/08/190828193809.htm,"   The findings provide fresh insights into the history of our Galaxy and increase our understanding of how stars form and evolve. Researchers calculate that the old stars are moving more quickly in and out of the disc -- the pancake-shaped mass at the heart of the Galaxy where most stars are located. A number of theories could explain this movement -- it all depends where the star is in the disc. Stars towards the outskirts could be knocked by gravitational interactions with smaller galaxies passing by. Towards the inner parts of the disc, the stars could be disturbed by massive gas clouds which move along with the stars inside the disc. They could also be thrown out of the disc by the movement of its spiral structure. Dr Ted Mackereth, a galactic archaeologist at the University of Birmingham, is lead author on the paper. He explains: ""The specific way that the stars move tells us which of these processes has been dominant in forming the disc we see today. We think older stars are move active because they have been around the longest, and because they were formed during a period when the Galaxy was a bit more violent, with lots of star formation happening and lots of disturbance from gasses and smaller satellite galaxies. There are lots of different processes at work, and untangling all these helps us to build up a picture of the history of our Galaxy."" The study uses data from the Gaia satellite, currently working to chart the movements of around 1 billion stars in the Milky Way. It also takes information from APOGEE, an experiment run by the Sloan Digital Sky Survey that uses spectroscopy to measure the distribution of elements in stars, as well as images from the recently-retired Kepler space telescope. Measurements provided by Kepler show how the brightness of stars varies over time, which gives insights into how they vibrate. In turn, that yields information about their interior structure, which enables scientists to calculate their age. The Birmingham team, working with colleagues at the University of Toronto and teams involved with the Sloan Digital Sky Survey, were able to take these different data strands and calculate the differences in velocity between different sets of stars grouped by age. They found that the older stars were moving in many different directions with some moving very quickly out from the galactic disk. Younger stars move closely together at much slower speeds out from the disc, although they are faster than the older stars as they rotate around the Galaxy within the disc. The eventual goal of the research is to link what is known about the Milky Way with information about how other galaxies in the universe formed, ultimately being able to place our Galaxy within the very earliest signatures of the universe. The research is published in the Monthly Notices of the Royal Astronomical Society and funded by the Science and Technology Facilities Council, the Royal Astronomical Society and the European Research Council. "
Science Daily,Earth's Fingerprint Hints at Finding Habitable Planets Beyond the Solar System,Space & Time,2019-08-28,-,https://www.sciencedaily.com/releases/2019/08/190828140132.htm,"   McGill Physics student Evelyn Macdonald and her supervisor Prof. Nicolas Cowan used over a decade of observations of Earth's atmosphere taken by the SCISAT satellite to construct a transit spectrum of Earth, a sort of fingerprint for Earth's atmosphere in infrared light, which shows the presence of key molecules in the search for habitable worlds. This includes the simultaneous presence of ozone and methane, which scientists expect to see only when there is an organic source of these compounds on the planet. Such a detection is called a ""biosignature."" ""A handful of researchers have tried to simulate Earth's transit spectrum, but this is the first empirical infrared transit spectrum of Earth,"" says Prof. Cowan. ""This is what alien astronomers would see if they observed a transit of Earth."" The findings, published Aug. 28 in the journal Monthly Notices of the Royal Astronomical Society, could help scientists determine what kind of signal to look for in their quest to find Earth-like exoplanets (planets orbiting a star other than our Sun). Developed by the Canadian Space Agency, SCISAT was created to help scientists understand the depletion of Earth's ozone layer by studying particles in the atmosphere as sunlight passes through it. In general, astronomers can tell what molecules are found in a planet's atmosphere by looking at how starlight changes as it shines through the atmosphere. Instruments must wait for a planet to pass -- or transit -- over the star to make this observation. With sensitive enough telescopes, astronomers could potentially identify molecules such as carbon dioxide, oxygen or water vapour that might indicate if a planet is habitable or even inhabited. Cowan was explaining transit spectroscopy of exoplanets at a group lunch meeting at the McGill Space Institute (MSI) when Prof. Yi Huang, an atmospheric scientist and fellow member of the MSI, noted that the technique was similar to solar occultation studies of Earth's atmosphere, as done by SCISAT. Since the first discovery of an exoplanet in the 1990s, astronomers have confirmed the existence of 4,000 exoplanets. The holy grail in this relatively new field of astronomy is to find planets that could potentially host life -- an Earth 2.0. A very promising system that might hold such planets, called TRAPPIST-1, will be a target for the upcoming James Webb Space Telescope, set to launch in 2021. Macdonald and Cowan built a simulated signal of what an Earth-like planet's atmosphere would look like through the eyes of this future telescope which is a collaboration between NASA, the Canadian Space Agency and the European Space Agency. The TRAPPIST-1 system located 40 light years away contains seven planets, three or four of which are in the so-called ""habitable zone"" where liquid water could exist. The McGill astronomers say this system might be a promising place to search for a signal similar to their Earth fingerprint since the planets are orbiting an M-dwarf star, a type of star which is smaller and colder than our Sun. ""TRAPPIST-1 is a nearby red dwarf star, which makes its planets excellent targets for transit spectroscopy. This is because the star is much smaller than the Sun, so its planets are relatively easy to observe,"" explains Macdonald. ""Also, these planets orbit close to the star, so they transit every few days. Of course, even if one of the planets harbours life, we don't expect its atmosphere to be identical to Earth's since the star is so different from the Sun."" According to their analysis, Macdonald and Cowan affirm that the Webb Telescope will be sensitive enough to detect carbon dioxide and water vapour using its instruments. It may even be able to detect the biosignature of methane and ozone if enough time is spent observing the target planet. Prof. Cowan and his colleagues at the Montreal-based Institute for Research on Exoplanets are hoping to be some of the first to detect signs of life beyond our home planet. The fingerprint of Earth assembled by Macdonald for her senior undergraduate thesis could tell other astronomers what to look for in this search. She will be starting her Ph.D. in the field of exoplanets at the University of Toronto in the Fall. "
Science Daily,Newly Discovered Giant Planet Slingshots Around Its Star,Space & Time,2019-08-28,-,https://www.sciencedaily.com/releases/2019/08/190828092502.htm,"   ""This planet is unlike the planets in our solar system, but more than that, it is unlike any other exoplanets we have discovered so far,"" says Sarah Blunt, a Caltech graduate student and first author on the new study publishing in The Astronomical Journal. ""Other planets detected far away from their stars tend to have very low eccentricities, meaning that their orbits are more circular. The fact that this planet has such a high eccentricity speaks to some difference in the way that it either formed or evolved relative to the other planets."" The planet was discovered using the radial velocity method, a workhorse of exoplanet discovery that detects new worlds by tracking how their parent stars ""wobble"" in response to gravitational tugs from those planets. However, analyses of these data usually require observations taken over a planet's entire orbital period. For planets orbiting far from their stars, this can be difficult: a full orbit can take tens or even hundreds of years. The California Planet Search, led by Caltech Professor of Astronomy Andrew W. Howard, is one of the few groups that watches stars over the decades-long timescales necessary to detect long-period exoplanets using radial velocity. The data needed to make the discovery of the new planet were first provided by W. M. Keck Observatory in Hawaii. In 1997, the team began using the High-Resolution Echelle Spectrometer (HIRES) on the Keck I telescope to take measurements of the planet's star, called HR 5183. ""The key was persistence,"" said Howard. ""Our team followed this star with Keck Observatory for more than two decades and only saw evidence for the planet in the past couple years! Without that long-term effort, we never would have found this planet."" In addition to Keck Observatory, the California Planet Search also used the Lick Observatory in Northern California and the McDonald Observatory in Texas. The astronomers have been watching HR 5183 since the 1990s, but do not have data corresponding to one full orbit of the planet, called HR 5183 b, because it circles its star roughly every 45 to 100 years. The team instead found the planet because of its strange orbit. ""This planet spends most of its time loitering in the outer part of its star's planetary system in this highly eccentric orbit, then it starts to accelerate in and does a slingshot around its star,"" explains Howard. ""We detected this slingshot motion. We saw the planet come in and now it's on its way out. That creates such a distinctive signature that we can be sure that this is a real planet, even though we haven't seen a complete orbit."" The new findings show that it is possible to use the radial velocity method to make detections of other far-flung planets without waiting decades. And, the researchers suggest, looking for more planets like this one could illuminate the role of giant planets in shaping their solar systems. Planets take shape out of disks of material left over after stars form. That means that planets should start off in flat, circular orbits. For the newly detected planet to be on such an eccentric orbit, it must have gotten a gravitational kick from some other object. The most plausible scenario, the researchers propose, is that the planet once had a neighbor of similar size. When the two planets got close enough to each other, one pushed the other out of the solar system, forcing HR 5183 b into a highly eccentric orbit. ""This newfound planet basically would have come in like a wrecking ball,"" says Howard, ""knocking anything in its way out of the system."" This discovery demonstrates that our understanding of planets beyond our solar system is still evolving. Researchers continue to find worlds that are unlike anything in our solar system or in solar systems we have already discovered. ""Copernicus taught us that Earth is not the center of the solar system, and as we expanded into discovering other solar systems of exoplanets, we expected them to be carbon copies of our own solar system,"" Howard explains, ""But it's just been one surprise after another in this field. This newfound planet is another example of a system that is not the image of our solar system but has remarkable features that make our universe incredibly rich in its diversity."" "
Science Daily,Astronomers Find a Golden Glow from a Distant Stellar Collision,Space & Time,2019-08-27,-,https://www.sciencedaily.com/releases/2019/08/190827123524.htm,"   The impact also created a kilonova -- a turbocharged explosion that instantly forged several hundred planets' worth of gold and platinum. The observations provided the first compelling evidence that kilonovae produce large quantities of heavy metals, a finding long predicted by theory. Astronomers suspect that all of the gold and platinum on Earth formed as a result of ancient kilonovae created during neutron star collisions. Based on data from the 2017 event, first spotted by the Laser Interferometer Gravitational-wave Observatory (LIGO), astronomers began to adjust their assumptions of how a kilonova should appear to Earth-bound observers. A team led by Eleonora Troja, an associate research scientist in the University of Maryland's Department of Astronomy, re-examined data from a gamma-ray burst spotted in August 2016 and found new evidence for a kilonova that went unnoticed during the initial observations. NASA's Neil Gehrels Swift Observatory began tracking the 2016 event, named GRB160821B, minutes after it was detected. The early catch enabled the research team to gather new insights that were missing from the kilonova observations of the LIGO event, which did not begin until nearly 12 hours after the initial collision. Troja and her colleagues reported these new findings in the journal Monthly Notices of the Royal Astronomical Society on August 27, 2019. ""The 2016 event was very exciting at first. It was nearby and visible with every major telescope, including NASA's Hubble Space Telescope. But it didn't match our predictions -- we expected to see the infrared emission become brighter and brighter over several weeks,"" said Troja, who also has an appointment at NASA's Goddard Space Flight Center. ""Ten days after the event, barely any signal remained. We were all so disappointed. Then, a year later, the LIGO event happened. We looked at our old data with new eyes and realized we had indeed caught a kilonova in 2016. It was a nearly perfect match. The infrared data for both events have similar luminosities and exactly the same time scale."" The similarities between the two events suggest that the 2016 kilonova also resulted from the merger of two neutron stars. Kilonovae may also result from the merger of a black hole and neutron star, but it is unknown whether such an event would yield a different signature in X-ray, infrared, radio and optical light observations. According to Troja, the information collected from the 2016 event does not contain as much detail as the observations of the LIGO event. But the coverage of those first few hours -- missing from the record of the LIGO event -- revealed important new insights into the early stages of a kilonova. For example, the team got their first look at the new object that remained after the collision, which was not visible in the LIGO event data. ""The remnant could be a highly magnetized, hypermassive neutron star known as a magnetar, which survived the collision and then collapsed into a black hole,"" said Geoffrey Ryan, a Joint Space-Science Institute (JSI) Prize Postdoctoral Fellow in the UMD Department of Astronomy and a co-author of the research paper. ""This is interesting, because theory suggests that a magnetar should slow or even stop the production of heavy metals, which is the ultimate source of a kilonova's infrared light signature. Our analysis suggests that heavy metals are somehow able to escape the quenching influence of the remnant object."" Troja and her colleagues plan to apply the lessons they learned to re-evaluate past events, while also improving their approach to future observations. A number of candidate events have been identified with optical light observations, but Troja is more interested in events with a strong infrared light signature -- the telltale indicator of heavy metal production. ""The very bright infrared signal from this event arguably makes it the clearest kilonova we have observed in the distant universe,"" Troja said. ""I'm very much interested in how kilonova properties change with different progenitors and final remnants. As we observe more of these events, we may learn that there are many different types of kilonovae all in the same family, as is the case with the many different types of supernovae. It's so exciting to be shaping our knowledge in real time."" "
Science Daily,The Dark Side of Extrasolar Planets Share Surprisingly Similar Temperatures,Space & Time,2019-08-27,-,https://www.sciencedaily.com/releases/2019/08/190827111114.htm,"   Using data from the Spitzer Space and the Hubble Space telescopes, the researchers from the McGill Space Institute found that the nightside temperature of 12 hot Jupiters they studied was about 800¬∞C. Unlike our familiar planet Jupiter, so-called hot Jupiters circle very close to their host star -- so close that it typically takes fewer than three days to complete an orbit. As a result, hot Jupiters have daysides that permanently face their host stars and nightsides that always face the darkness of space, similarly to how the same side of the Moon always faces the Earth. The tight orbit also means these planets receive more light from their star, which is what makes them extremely hot on the dayside. But scientists had previously measured significant amounts of heat on the nightside of hot Jupiters, as well, suggesting some kind of energy transfer from one side to the other. ""Atmospheric circulation models predicted that the nightside temperatures should vary much more than they do,"" said Dylan Keating, a Physics PhD student under the supervision of McGill professor Nicolas Cowan. ""This is surprising because the planets we studied all receive different amounts of irradiation from their host stars and the dayside temperatures among them varies by almost 1700¬∞C."" Keating, the first author of a new Nature Astronomy study describing the findings, said the nightside temperatures are probably the result of condensation of vaporized rock in these very hot atmospheres. ""The uniformity of the nightside temperatures suggests that clouds on this side of the planets are likely similar to one another in composition. Our analysis suggests that these clouds are likely made of minerals such as manganese sulfide or silicates: in other words, rocks,"" Keating explained. According to Cowan, because the basic physics of cloud formation are universal, the study of the nightside clouds on hot Jupiters could give insight into cloud formation elsewhere in the Universe, including on Earth. Keating said that future space telescope missions -- such as the James Webb Space Telescope and the European Space Agency's ARIEL mission -- could be used to further characterize the dominant cloud composition on hot Jupiter nightsides, as well as to improve models of atmospheric circulation and cloud formation of these planets. ""Observing hot Jupiters at both shorter and longer wavelengths will help us determine what types of clouds are on the nightsides of these planets,"" Keating explained. "
Science Daily,Artificial Intelligence Used to Recognize Primate Faces in the Wild,Computers & Math,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904165232.htm,"   'For species like chimpanzees, which have complex social lives and live for many years, getting snapshots of their behaviour from short-term field research can only tell us so much,' says Dan Schofield, researcher and DPhil student at Oxford University's Primate Models Lab, School of Anthropology. 'By harnessing the power of machine learning to unlock large video archives, it makes it feasible to measure behaviour over the long term, for example observing how the social interactions of a group change over several generations.' The computer model was trained using over 10 million images from Kyoto University's Primate Research Institute (PRI) video archive of wild chimpanzees in Guinea, West Africa. The new software is the first to continuously track and recognise individuals in a wide range of poses, performing with high accuracy in difficult conditions such as low lighting, poor image quality and motion blur. 'Access to this large video archive has allowed us to use cutting edge deep neural networks to train models at a scale that was previously not possible,' says Arsha Nagrani, co-author of the study and DPhil student at the Department of Engineering Science, University of Oxford. 'Additionally, our method differs from previous primate face recognition software in that it can be applied to raw video footage with limited manual intervention or pre-processing, saving hours of time and resources.' The technology has potential for many uses, such as monitoring species for conservation. Although the current application focused on chimpanzees, the software provided could be applied to other species, and help drive the adoption of artificial intelligence systems to solve a range of problems in the wildlife sciences. 'All our software is available open-source for the research community,' says Nagrani. 'We hope that this will help researchers across other parts of the world apply the same cutting-edge techniques to their unique animal data sets. As a computer vision researcher, it is extremely satisfying to see these methods applied to solve real, challenging biodiversity problems.' 'With an increasing biodiversity crisis and many of the world's ecosystems under threat, the ability to closely monitor different species and populations using automated systems will be crucial for conservation efforts, as well as animal behaviour research' adds Schofield. 'Interdisciplinary collaborations like this have huge potential to make an impact, by finding novel solutions for old problems, and asking biological questions which were previously not feasible on a large scale.'### "
Science Daily,Emotion-Reading Algorithms Cannot Predict Intentions Via Facial Expressions,Computers & Math,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904165231.htm,"   Computers aren't very good at discerning misrepresentation, and that's a problem as the technologies are increasingly deployed in society to render decisions that shape public policy, business and people's lives. Turns out that algorithms fail basic tests as truth detectors, according to researchers who study theoretical factors of expression and the complexities of reading emotions at the USC Institute for Creative Technologies. The research team completed a pair of studies using science that undermines popular psychology and AI expression understanding techniques, both of which assume facial expressions reveal what people are thinking. ""Both people and so-called 'emotion reading' algorithms rely on a folk wisdom that our emotions are written on our face,"" said Jonathan Gratch, director for virtual human research at ICT and a professor of computer science at the USC Viterbi School of Engineering. ""This is far from the truth. People smile when they are angry or upset, they mask their true feelings, and many expressions have nothing to do with inner feelings, but reflect conversational or cultural conventions."" Gratch and colleagues presented the findings today at the 8th International Conference on Affective Computing and Intelligent Interaction in Cambridge, England. Of course, people know that people can lie with a straight face. Poker players bluff. Job applicants fake interviews. Unfaithful spouses cheat. And politicians can cheerfully utter false statements. Yet, algorithms aren't so good at catching duplicity, even as machines are increasingly deployed to read human emotions and inform life-changing decisions. For example, the Department of Homeland Security invests in such algorithms to predict potential threats. Some nations use mass surveillance to monitor communications data. Algorithms are used in focus groups, marketing campaigns, to screen loan applicants or hire people for jobs. ""We're trying to undermine the folk psychology view that people have that if we could recognize people's facial expressions, we could tell what they're thinking,"" said Gratch, who is also a professor of psychology. ""Think about how people used polygraphs back in the day to see if people were lying. There were misuses of the technology then, just like misuses of facial expression technology today. We're using na√Øve assumptions about these techniques because there's no association between expressions and what people are really feeling based on these tests."" To prove it, Gratch and fellow researchers Su Lei and Rens Hoegen at ICT, along with Brian Parkinson and Danielle Shore at the University of Oxford, examined spontaneous facial expressions in social situations. In one study, they developed a game that 700 people played for money and then captured how people's expressions impacted their decisions and how much they earned. Next, they allowed subjects to review their behavior and provide insights into how they were using expressions to gain advantage and if their expressions matched their feelings. Using several novel approaches, the team examined the relationships between spontaneous facial expressions and key events during the game. They adopted a technique from psychophysiology called ""event-related potentials"" to address the extreme variability in facial expressions and used computer vision techniques to analyze those expressions. To represent facial movements, they used a recently proposed method called facial factors, which captures many nuances of facial expressions without the difficulties modern analysis techniques provide. The scientists found that smiles were the only expressions consistently provoked, regardless of the reward or fairness of outcomes. Additionally, participants were fairly inaccurate in perceiving facial emotion and particularly poor at recognizing when expressions were regulated. The findings show people smile for lots of reasons, not just happiness, a context important in the evaluation of facial expressions. ""These discoveries emphasize the limits of technology use to predict feelings and intentions,"" Gratch said. ""When companies and governments claim these capabilities, the buyer should beware because often these techniques have simplistic assumptions built into them that have not been tested scientifically."" Prior research shows that people will make conclusions about other's intentions and likely actions simply based off of the other's expressions. While past studies exist using automatic expression analysis to make inferences, such as boredom, depression and rapport, less is known about the extent to which perceptions of expression are accurate. These recent findings highlight the importance of contextual information when reading other's emotions and support the view that facial expressions communicate more than we might believe. "
Science Daily,AI Learns to Model Our Universe,Computers & Math,2019-08-28,-,https://www.sciencedaily.com/releases/2019/08/190828100554.htm,"   Researchers seek to understand our Universe by making model predictions to match observations. Historically, they have been able to model simple or highly simplified physical systems, jokingly dubbed the ""spherical cows,"" with pencils and paper. Later, the arrival of computers enabled them to model complex phenomena with numerical simulations. For example, researchers have programmed supercomputers to simulate the motion of billions of particles through billions of years of cosmic time, a procedure known as the N-body simulations, in order to study how the Universe evolved to what we observe today. ""Now with machine learning, we have developed the first neural network model of the Universe, and demonstrated there's a third route to making predictions, one that combines the merits of both analytic calculation and numerical simulation,"" said Yin Li, a Postdoctoral Researcher at the Kavli Institute for the Physics and Mathematics of the Universe, University of Tokyo, and jointly the University of California, Berkeley. A comparison of the accuracy of two models of the Universe. The new deep learning model (left), dubbed D3M, is much more accurate than an existing analytic method (right) called 2LPT. The colors represent the error in displacement at each point relative to the numerical simulation, which is accurate but much slower than the deep learning model. At the beginning of our Universe, things were extremely uniform. As time went by, the denser parts grew denser and sparser parts became sparser due to gravity, eventually forming a foam-like structure known as the ""cosmic web."" To study this structure formation process, researchers have tried many methods, including analytic calculations and numerical simulations. Analytic methods are fast, but fail to produce accurate results for large density fluctuations. On the other hand, numerical (N-body) methods simulate structure formation accurately, but tracking gazillions of particles is costly, even on supercomputers. Thus, to model the Universe, scientists often face the accuracy versus efficiency trade-off. However, the explosive growth of observational data in quality and quantity calls for methods that excel in both accuracy and efficiency. To tackle this challenge, a team of researchers from the US, Canada, and Japan, including Li, set their sights on machine learning, a cutting-edge approach to detecting patterns and making predictions. Just as machine learning can transform a young man's portrait into his older self, Li and colleagues asked whether it can also predict how universes evolve based on their early snapshots. They trained a convolutional neural network with simulation data of trillions of cubic light years in volume, and built a deep learning model that was able to mimic the structure formation process. The new model is not only many times more accurate than the analytic methods, but is also much more efficient than the numerical simulations used for its training. ""It has the strengths of both previous [analytic calculation and numerical simulation] methods,"" said Li. Li says the power of AI emulation will scale up in the future. N-body simulations are already heavily optimized, and as a first attempt, his team's AI model still has large room for improvement. Also, more complicated phenomena incur a larger cost on simulation, but not likely so on emulation. Li and his colleagues expect a bigger performance gain from their AI emulator when they move on to including other effects, such as hydrodynamics, into the simulations. ""It won't be long before we can uncover the initial conditions of and the physics encoded in our Universe along this path,"" he said. "
Science Daily,New Insulation Technique Paves the Way for More Powerful and Smaller Chips,Computers & Math,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904100759.htm,"   Computer chips are getting increasingly smaller. That's not new: Gordon Moore, one of the founders of chip manufacturer Intel, already predicted it in 1965. Moore's law states that the number of transistors in a chip, or integrated circuit, doubles about every two years. This prognosis was later adjusted to 18 months, but the theory still stands. Chips are getting smaller and their processing power is increasing. Nowadays, a chip can have over a billion transistors. But this continued reduction in size also brings with it a number of obstacles. The switches and wires are packed together so tightly that they generate more resistance. This, in turn, causes the chip to consume more energy to send signals. To have a well-functioning chip, you need an insulating substance that separates the wires from each other, and ensures that the electrical signals are not disrupted. However, that's not an easy thing to achieve at the nanoscale level. Nanoporous crystals A study led by KU Leuven professor Rob Ameloot (Department of Microbial and Molecular systems) shows that a new technique might provide the solution. ""We're using metal-organic frameworks (MOFs) as the insulating substance. These are materials that consist of metal ions and organic molecules. Together, they form a crystal that is porous yet sturdy."" For the first time, a research team at KU Leuven and imec managed to apply the MOF insulation to electronic material. An industrial method called chemical vapour deposition was used for this, says postdoctoral researcher Mikhail Krishtab (Department of Microbial and Molecular systems). ""First, we place an oxide film on the surface. Then, we let it react with vapour of the organic material. This reaction causes the material to expand, forming the nanoporous crystals."" ""The main advantage of this method is that it's bottom-up,"" says Krishtab. ""We first deposit an oxide film, which then swells up to a very porous MOF material. You can compare it to a souffl√©; that puffs up in the oven and becomes very light. The MOF material forms a porous structure that fills all the gaps between the conductors. That's how we know the insulation is complete and homogeneous. With other, top-down methods, there's always still the risk of small gaps in the insulation."" Powerful and energy efficient Professor Ameloot's research group has received an ERC Proof of Concept grant to further develop the technique, in collaboration with Silvia Armini from imec's team working on advanced dielectric materials for nanochips. ""At imec, we have the expertise to develop wafer-based solutions, scaling technologies from lab to fab and paving the way to realising a manufacturable solution for the microelectronics industry."" ""We've shown that the MOF material has the right properties,"" Ameloot continues. ""Now, we just have to refine the finishing. The surface of the crystals is still irregular at the moment. We have to smoothen this to integrate the material in a chip."" Once the technique has been perfected, it can be used to create powerful, small chips that consume less energy. Ameloot: ""Various AI applications require a lot of processing power. Think of self-driving cars and smart cities. Technology companies are constantly looking for new solutions that are both quick and energy efficient. Our research can be a valuable contribution to a new generation of chips."" "
Science Daily,Automated Text Analysis: The Next Frontier of Marketing Innovation,Computers & Math,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904091123.htm,"   The study, forthcoming in the January issue of the Journal of Marketing, is titled ""Uniting the Tribes: Using Text for Marketing Insights"" and authored by Jonah Berger, Ashlee Humphreys, Wendy Moe, Oded Netzer, and David Schweidel. Online reviews, customer service calls, press releases, news articles, marketing communications, and other interactions create a wealth of textual data companies can analyze to optimize services and develop new products. By some estimates, 80-95% of all business data is unstructured, with most of that being text. This text has the potential to provide critical insights about its producers, including individuals' identities, their relationships, their goals, and how they display key attitudes and behaviors. This text can be aggregated to create insights about organizations and social institutions and how attitudes vary over cultural contexts, demographics, groups, and time. Berger explains that ""The digitization of information has made a wealth of textual data readily available. But by itself, all this data is just that. Data. For data to be useful, researchers have to be able to extract underlying insight -- to measure, track, understand, and interpret the causes and consequences of marketplace behavior."" But how can marketers do that? The research team explains how researchers and managers can use text to better understand the individuals and organizations who produce the text. The article also explores how the content of text affects various audiences. For example, how consumers may be influenced to change their behaviors or brands influenced to attend to issues raised by consumers depends in large part on the content of text. Moe adds that ""Automated text analysis opens the black-box of interactions, allowing researchers to directly access what is being said and how it is said in marketplace communication."" Given the volume of text data available, automated text analysis methods are critical, but need to be handled carefully. Researchers should avoid over-fitting and weigh the importance of features to glean and use the right predictors from text. Thus, this article also provides an overview of the methodologies and metrics used in text analysis, providing a set of guidelines and procedures for marketing researchers and marketing scholars. Understanding these methods help us understand how text is used and processed. For example, virtual assistants are currently under scrutiny for the fact that humans are listening to the audio recordings. However, this process is necessary to train the machines used for automated text analysis. The goal of this article is to further the collective understanding of text analysis and how it can be used for insights. Researchers and marketers can use this article to create frameworks, establish and communicate policies, and strengthen cross-functional collaboration with teams working on textual analytics projects. "
Science Daily,Electronic Glove Offers 'Humanlike' Features for Prosthetic Hand Users,Computers & Math,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904081320.htm,"   An electronic glove, or e-glove, developed by Purdue University researchers can be worn over a prosthetic hand to provide humanlike softness, warmth, appearance and sensory perception, such as the ability to sense pressure, temperature and hydration. The technology is published in the Aug. 30 edition of NPG Asia Materials. While a conventional prosthetic hand helps restore mobility, the new e-glove advances the technology by offering the realistic human hand-like features in daily activities and life roles, with the potential to improve their mental health and wellbeing by helping them more naturally integrate into social contexts. The e-glove uses thin, flexible electronic sensors and miniaturized silicon-based circuit chips on the commercially available nitrile glove. The e-glove is connected to a specially designed wristwatch, allowing for real-time display of sensory data and remote transmission to the user for post-data processing. Chi Hwan Lee, an assistant professor in Purdue's College of Engineering, in collaboration with other researchers at Purdue, the University of Georgia and the University of Texas, worked on the development of the e-glove technology. ""We developed a novel concept of the soft-packaged, sensor-instrumented e-glove built on a commercial nitrile glove, allowing it to seamlessly fit on arbitrary hand shapes,"" Lee said. ""The e-glove is configured with a stretchable form of multimodal sensors to collect various information such as pressure, temperature, humidity and electrophysiological biosignals, while simultaneously providing realistic human hand-like softness, appearance and even warmth."" Lee and his team hope that the appearance and capabilities of the e-glove will improve the well-being of prosthetic hand users by allowing them to feel more comfortable in social contexts. The glove is available in different skin tone colors, has lifelike fingerprints and artificial fingernails. ""The prospective end user could be any prosthetic hand users who have felt uncomfortable wearing current prosthetic hands, especially in many social contexts,"" Lee said. The fabrication process of the e-glove is cost-effective and manufacturable in high volume, making it an affordable option for users unlike other emerging technologies with mind, voice and muscle control embedded within the prosthetic at a high cost. Additionally, these emerging technologies do not provide the humanlike features that the e-glove provides. Lee and Min Ku Kim, an engineering doctoral student at Purdue and a co-author on the paper, have worked to patent the technology with the Purdue Research Foundation Office of Technology Commercialization. The team is seeking partners to collaborate in clinical trials or experts in the prosthetics field to validate the use of the e-glove and to continue optimizing the design of the glove. A video about the technology is available at https://youtu.be/lF1VYzKagNo. "
Science Daily,A New Alphabet to Write and Read Quantum Messages With Very Fast Particles,Computers & Math,2019-09-03,-,https://www.sciencedaily.com/releases/2019/09/190903114223.htm,"   Let us imagine the following situation: Anna and Bill want to communicate exchanging a message by using a property of a quantum particle, say the spin of an electron, which is an intrinsic form of particle's rotation. Bill needs Anna's message as quickly as possible, so Anna has to send the electron at maximum speed, very close to the speed of light. Given that Anna has the electron in her laboratory localized, one of the fundamentals of quantum physics, the Heisenberg uncertainty principle, forbids the velocity of the electron to be defined with arbitrary precision. When the electron travels extremely fast, that means, relativistically, the interplay between special relativity and quantum physics causes the spin and the velocity of the electron to get entangled. Due to this correlation, which is stronger than what is classically possible, Bill is not able to read out the spin with the standard method. Can Anna and Bill improve their communication strategy? A group of researchers led by ƒåaslav Brukner at the University of Vienna and the Institute for Quantum Optics and Quantum Information (IQOQI-Vienna) of the Austrian Academy of Sciences have introduced a novel alternative to the standard alphabet used by Anna and Bill. Their technique guarantees that the message, written by Anna and read by Bill, can be decoded unambiguously even when the particle behaves according to both quantum mechanics, because of Heisenberg's uncertainty principle, and special relativity, due to its very high velocity. The novel method as presented in the journal Physical Review Letters delivers a new definition of the spin of quantum particles that move very fast. Thus it modifies both the way Anna writes the message and the way Bill reads it. Key to this technique is a ""translation"" of the way the message would be written and read between the standard alphabet, used when the electron is at rest, and the new alphabet, used when the electron travels very fast. ""These results are indicative that this translation procedure could open up to new applications in relativistic quantum information,"" says Flaminia Giacomini, the lead author of the paper. For instance, this technique could be helpful in satellite-based quantum communication, where a particle carrying a message has to travel quickly between two far-away points. "
Science Daily,"At the Edge of Chaos, Powerful New Electronics Could Be Created",Computers & Math,2019-09-03,-,https://www.sciencedaily.com/releases/2019/09/190903124002.htm,"   A team of physicists at the University of Groningen, led by Professor of Functional Nanomaterials Beatriz Noheda, made their observation in thin films of barium titanate (BaTiO3), a ferroelastic material. Ferroic materials are characterized by their ordered structure, in shape (ferroelastic), charge (ferroelectric) or magnetic moment (ferromagnetic), for example. 'These materials are always crystals in which the atoms are arranged with characteristic symmetries,' Noheda explains. Twins Electric or magnetic dipoles are aligned within domains in the crystals. 'However, the dipoles could be pointing up or down, as both states are equivalent.' As a result, crystals of these materials will have both types of domains. The same goes for ferroelastic materials, best known for their shape memory. In this case, however, the situation is a bit more complicated, Noheda explains: 'The unit cells in these crystals are elongated, which means that domains of the different unit cells do not easily match in shape. This creates an elastic strain that reduces the crystal stability.' The crystal can improve the stability naturally by forming twins of domains, which are slightly tilted in opposite directions to relieve the stress. The result is a material in which these twinned pairs form alternating domains, with a fixed periodicity. Heating causes a phase change in the material, in which both the direction and the periodicity of the domain walls is altered. 'The question was how this change takes place,' says Noheda. Domain walls Increasing the temperature increases the disorder (entropy) in the material. Thus, a tug-of-war starts between the intrinsic tendency for order and the increasing entropy. It is this process that was observed for the first time by the Groningen team, using atomic force microscopy. When heating samples from 25 ¬∞C to 70 ¬∞C, a phase change takes place, altering the position of domain walls. When the transition starts, domain walls of the new phase appear gradually and both phases exist together at intermediate temperatures (30 ¬∞C to 50 ¬∞C). 'This doesn't happen in a random way, but by repeated doubling,' says Noheda. Cooling the material reduces the periodicity of the domains by repeated halving. 'This doubling or halving is well known in non-linear dynamical systems, when they are close to the transition to chaotic behaviour,' explains Noheda, 'However, it had never been observed in spatial domains, but only in time periods.' The resemblance between the behaviour of the thin films and non-linear systems suggests that the material is itself at the edge of chaos during heating. 'This is an interesting observation, because it means that the response of the system is highly dependent on initial conditions. Thus, we could get very diverse responses following a small change in these conditions.' Neuromorphic computing The paper includes theoretical calculations from colleagues at Penn State University (US) and the University of Cambridge (UK), which show that the behaviour observed in the ferroelastic barium titanate is generic for ferroic materials. Thus, a ferroelectric material at the edge of chaos could give a highly diverse response over a small range of input voltages. 'That is exactly what you want, to create the type of adaptable response needed for neuromorphic computing, such as reservoir computing, which benefits from non-linear systems that can produce highly diverse input-output sets.' The paper in Physical Review Letters is a proof of principle, showing how a material can be designed to exist at the edge of chaos, where it is highly responsive. Noheda also points out how the doubling of domains creates a structure similar to the bifurcating dendrites connecting the pyramidal cells in the brain. These cells play an important role in cognitive abilities. Ultimately, ferroic materials on the edge of chaos may be used to create electronic brain-like systems for complex computing. "
Science Daily,An Astonishing Parabola Trick: Unusual Magnetic Behavior,Computers & Math,2019-09-03,-,https://www.sciencedaily.com/releases/2019/09/190903113337.htm,"   We all know that our left hand is different from our right -- a left glove won't fit your right hand and vice versa. Scientists use the term ""chirality"" to describe objects that do not align with their mirror image. Chemists, in particular, are familiar with this property in molecules, as in left- and right-rotating lactic acid. Humans metabolize the right-rotating variant more easily than its ""mirror image."" Such chiral effects are known to occur in magnetic materials, where magnetic textures also have chiral properties: the arrangement of individual magnetic moments inside the material, or, figuratively speaking, the alignment of the many tiny ""compass needles"" that make up a magnet, could form right- and left-handed alignments. Under certain conditions, some textures behave like image and mirror image -- a left-handed texture cannot be made congruent with its right-handed version. The interesting aspect here is that ""the two textures can present different magnetic behaviors,"" as HZDR physicist Dr. Denys Makarov points out. ""To put it simply: a right-handed texture can be more energetically preferable than a left-handed texture. Since systems in nature tend to assume their lowest possible energetic state, the right-handed state is preferred."" Such chiral effects hold great technological promise. Among other things, they could be helpful in the future development of highly energy-efficient electronic components such as sensors, switches, and non-volatile storage devices. Magnetic curved architectures ""Helimagnets are materials with well-defined chiral magnetic properties, due to a lack of internal magnetic symmetry,"" explains the lead author of the paper, Dr. Oleksii Volkov from HZDR's Institute of Ion Beam Physics and Materials Research. ""Despite the fact that they have been known for a long time, these are rather exotic materials that are difficult to produce. Moreover, helimagnets usually exhibit their unique chiral properties at low temperatures."" That is why Makarov's team chose a different path. They used a common magnetic material, iron-nickel alloy (known as Permalloy), to build curved objects like parabola-shaped strips. Using lithography, they formed various parabolic strips of several micrometers from thin sheets of Permalloy. The physicists then exposed the samples to a magnetic field, thus orienting the magnetic moments in the parabola along this magnetic field. They then experimentally explored the magnetization reversal by using a highly sensitive analysis method at HZB's synchrotron. The team was able to show that the magnetic moments in the parabolic strip remained in their original direction until a reversed magnetic field of a certain critical value was applied. Surprisingly strong effect This delayed response is due to chiral effects caused by the curvature at the apex area of the parabola strips. ""Theorists have predicted this unusual behavior for some time, but it was actually considered more of a theoretical trick,"" explains Dr. Florian Kronast of Helmholtz-Zentrum Berlin. ""But now we have shown that this trick actually works in practice. We detected magnetic chiral response in a conventional soft ferromagnetic material, just through the geometric curvature of the strips we used."" In the process, the team were faced with two more surprises: On the one hand, the effect was remarkably strong, which means it could be used to influence the magneto-electric responses of materials. On the other hand, the effect was detected in a relatively large object: micrometer-sized parabolas that can be produced using conventional lithography. Previously, experts had assumed that these curvature-induced chiral effects could only be observed in magnetic objects with dimensions of about a dozen of nanometers. ""In terms of possible applications, we are looking forward to novel magnetic switches and data storage devices that utilize geometrically-induced chiral properties,"" Makarov emphasizes. There are concepts that envision future digital data storage in certain magnetic objects, so-called chiral domain walls or skyrmions. The recent discovery might help to produce such objects quite easily -- at room temperature, and using common materials. In addition, the newly discovered effect also paves the way for novel, highly sensitive magnetic field sensors. "
Science Daily,AI Learns the Language of Chemistry to Predict How to Make Medicines,Computers & Math,2019-09-03,-,https://www.sciencedaily.com/releases/2019/09/190903111250.htm,"   A central challenge in drug discovery and materials science is finding ways to make complicated organic molecules by chemically joining together simpler building blocks. The problem is that those building blocks often react in unexpected ways. ""Making molecules is often described as an art realised with trial-and-error experimentation because our understanding of chemical reactivity is far from complete,"" said Dr Alpha Lee from Cambridge's Cavendish Laboratory, who led the studies. ""Machine learning algorithms can have a better understanding of chemistry because they distil patterns of reactivity from millions of published chemical reactions, something that a chemist cannot do."" The algorithm developed by Lee and his group uses tools in pattern recognition to recognise how chemical groups in molecules react, by training the model on millions of reactions published in patents. The researchers looked at chemical reaction prediction as a machine translation problem. The reacting molecules are considered as one 'language,' while the product is considered as a different language. The model then uses the patterns in the text to learn how to 'translate' between the two languages. Using this approach, the model achieves 90% accuracy in predicting the correct product of unseen chemical reactions, whereas the accuracy of trained human chemists is around 80%. The researchers say that the model is accurate enough to detect errors in the data and correctly predict a plethora of difficult reactions. The model also knows what it doesn't know. It produces an uncertainty score, which eliminates incorrect predictions with 89% accuracy. As experiments are time-consuming, accurate prediction is crucial to avoid pursuing expensive experimental pathways that eventually end in failure. In the second study, Lee and his group, collaborating with the biopharmaceutical company Pfizer, demonstrated the practical potential of the method in drug discovery. The researchers showed that when trained on published chemistry research, the model can make accurate predictions of reactions based on lab notebooks, showing that the model has learned the rules of chemistry and can apply it to drug discovery settings. The team also showed that the model can predict sequences of reactions that would lead to a desired product. They applied this methodology to diverse drug-like molecules, showing that the steps that it predicts are chemically reasonable. This technology can significantly reduce the time of preclinical drug discovery because it provides medicinal chemists with a blueprint of where to begin. ""Our platform is like a GPS for chemistry,"" said Lee, who is also a Research Fellow at St Catharine's College. ""It informs chemists whether a reaction is a go or a no-go, and how to navigate reaction routes to make a new molecule."" The Cambridge researchers are currently using this reaction prediction technology to develop a complete platform that bridges the design-make-test cycle in drug discovery and materials discovery: predicting promising bioactive molecules, ways to make those complex organic molecules, and selecting the experiments that are the most informative. The researchers are now working on extracting chemical insights from the model, attempting to understand what it has learned that humans have not. ""We can potentially make a lot of progress in chemistry if we learn what kinds of patterns the model is looking at to make a prediction,"" said Peter Bolgar, a PhD student in synthetic organic chemistry involved in both studies. ""The model and human chemists together would become extremely powerful in designing experiments, more than each would be without the other."" The research was supported by the Winton Programme for the Physics of Sustainability and the Herchel Smith Fund. "
Science Daily,Realistic Robots Get Under Gal√°pagos Lizards' Skin,Earth & Climate,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904213718.htm,"   To avoid injury from male-to-male contests, some animal species display behaviours such as color changes or sequences of movements that showcase body size and fighting ability. In lizards, one of the most recognised behaviours is the bobbing or pushup display. Dr David Clark at Alma College, US and colleagues investigated whether lizards would react more quickly and strongly to their opponent's bobbing display, if that display occurred immediately or with a delay following an initial challenge. The authors used remote-controlled realistic lizard robots made from hand carved wood, high resolution photos and latex limbs to simulate an opponent's reaction to a wild lizards' display. The authors positioned lizard robots approximately 1-3m from 20 wild Gal√°pagos Lava Lizards (Microlophus bivitattus) found on the island of San Crist√≥bal. After provoking an initial response by the native lizard, the researchers remotely activated the lizard robot to respond with a pre-set counter movement either immediately, or after a 30-second delay. Dr David Clark, the corresponding author of the study said: ""We had hypothesized that our Lava Lizard subjects would respond differently if the robot responded immediately to their bobbing display than if the response from the robot was delayed. The results suggest that our hypothesis was correct. We found that an immediate response by the robot stimulated the wild lizard to respond more quickly and significantly more often than when the robot's response was delayed by 30 seconds."" The authors suggest that the live lizards may have perceived a rapid response from their robotic contestant as more aggressive than a delayed response. This ability to assess their contestant's level of aggression may help the lizard size up their competitor and may influence their decision to retreat or instigate a contest, helping them avoid disadvantageous injury. Dr Clark said: ""Ours is the first study to use a lizard robot that interacts with wild subjects in real-time. Previous research in this area has used either pre-recorded video playback or robots with movements set on a ""loop."" The findings confirm that realistic robotic stimuli can be used to interact with animals, to communicate with them and even manipulate their behaviour. Our results further our understanding of how lava lizards communicate with each other in their natural habitat."" The authors say that bobbing display communication in lizards could now be explored further by altering display speeds, bobbing height and the distance between the robot and subject. "
Science Daily,Artificial Intelligence Used to Recognize Primate Faces in the Wild,Earth & Climate,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904165232.htm,"   'For species like chimpanzees, which have complex social lives and live for many years, getting snapshots of their behaviour from short-term field research can only tell us so much,' says Dan Schofield, researcher and DPhil student at Oxford University's Primate Models Lab, School of Anthropology. 'By harnessing the power of machine learning to unlock large video archives, it makes it feasible to measure behaviour over the long term, for example observing how the social interactions of a group change over several generations.' The computer model was trained using over 10 million images from Kyoto University's Primate Research Institute (PRI) video archive of wild chimpanzees in Guinea, West Africa. The new software is the first to continuously track and recognise individuals in a wide range of poses, performing with high accuracy in difficult conditions such as low lighting, poor image quality and motion blur. 'Access to this large video archive has allowed us to use cutting edge deep neural networks to train models at a scale that was previously not possible,' says Arsha Nagrani, co-author of the study and DPhil student at the Department of Engineering Science, University of Oxford. 'Additionally, our method differs from previous primate face recognition software in that it can be applied to raw video footage with limited manual intervention or pre-processing, saving hours of time and resources.' The technology has potential for many uses, such as monitoring species for conservation. Although the current application focused on chimpanzees, the software provided could be applied to other species, and help drive the adoption of artificial intelligence systems to solve a range of problems in the wildlife sciences. 'All our software is available open-source for the research community,' says Nagrani. 'We hope that this will help researchers across other parts of the world apply the same cutting-edge techniques to their unique animal data sets. As a computer vision researcher, it is extremely satisfying to see these methods applied to solve real, challenging biodiversity problems.' 'With an increasing biodiversity crisis and many of the world's ecosystems under threat, the ability to closely monitor different species and populations using automated systems will be crucial for conservation efforts, as well as animal behaviour research' adds Schofield. 'Interdisciplinary collaborations like this have huge potential to make an impact, by finding novel solutions for old problems, and asking biological questions which were previously not feasible on a large scale.'### "
Science Daily,Methane-Producing Microorganism Makes a Meal of Iron,Earth & Climate,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904175713.htm,"   ""The microorganism Methanosarcina acetivorans is a methanogen that plays an important part in the carbon cycle, by which dead plant material is recycled back into carbon dioxide that then generates new plant material by photosynthesis,"" said James Ferry, Stanley Person Professor of Biochemistry and Molecular Biology at Penn State, who led the research team. ""Methanogens produce about 1 billion metric tons of methane annually, which plays a critical role in climate change. Understanding the process by which this microorganism produces methane is important for predicting future climate change and for potentially manipulating how much of this greenhouse gas the organism releases."" Methanosarcina acetivorans, which is found in environments like the ocean floor and rice paddies where it helps to decompose dead plant material, converts acetic acid into methane and carbon dioxide. Prior to this study, however, researchers were not certain how the microorganism had enough energy to survive in the oxygen-free -- anaerobic -- environments where it lives. The researchers determined that an oxidized form of iron called ""iron three,"" essentially rust, allows the microorganism to work more efficiently, using more acetic acid, creating more methane, and creating more ATP -- a chemical that provides energy for biological reactions essential for growth. ""Most organisms like humans use a process called respiration to create ATP, but this requires oxygen,"" said Ferry. ""When no oxygen is present, many organisms instead use a less efficient process called fermentation to create ATP, like the processes used by yeast in the production of wine and beer. But the presence of iron allows M. acetivorans to use respiration even in the absence of oxygen."" The findings allowed the researchers to update the biological pathway by which M. acetivorans converts acetic acid to methane, which now includes respiration. Pathways like this one involve many intermediate steps, during which energy is often lost in the form of heat. The researchers also determined that in the presence of iron, energy loss in this microorganism is reduced due to a recently discovered process called electron bifurcation. ""Electron bifurcation takes one of those steps that has the potential for tremendous heat loss and harvests that energy in the form of ATP rather than heat,"" said Ferry. ""This makes the process more efficient."" This updated pathway could allow researchers to predict the amount of methane that the microorganism will release into the atmosphere. ""Rice paddies -- a major source of the methane in the atmosphere -- contain decaying rice plants submerged in water that are ultimately processed by M. acetivorans. If we measure the amount of iron three present in the paddies, we can predict how much methane will be released by the microorganisms, which can improve our climate change models."" In the absence of iron, the microorganism produces roughly equal amounts of methane and carbon dioxide from acetic acid. But with increasing amounts of iron, it produces more carbon dioxide relative to methane, so providing the organism with additional iron could alter the relative amounts of these greenhouse gasses that are produced. ""Methane is 30 times more potent as a greenhouse gas than carbon dioxide, which makes it more problematic in terms of our warming planet,"" said Ferry. ""Now that we better understand this biochemical pathway, we see that we can use iron to alter the ratios of the gasses being produced. In the future, we might even be able to go further and inhibit the production of methane by this microorganism. ""In addition to the practical applications, this is a major addition to understanding the biology of the largely unseen but hugely important anaerobic world."" In addition to Ferry, the research team includes Divya Prakash and Shikha Chauhan at Penn State. The research was supported by US Department of Energy and the Penn State Eberly College of Science. "
Science Daily,Natural Ways of Cooling Cities,Earth & Climate,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904165242.htm,"   Urban heat islands are a phenomenon where the temperature in a city is noticeably higher than in the surrounding rural area. When combined with the sort of heatwave that hit many parts of Europe at the beginning of July, urban heat can pose a real threat to the elderly, sick or other vulnerable people. Scientists at ETH Zurich have researched urban heat islands across the globe and have found that the effectiveness of heat-reduction strategies in cities varies depending on the regional climate. ""We already know that plants create a more pleasant environment in a city, but we wanted to quantify how many green spaces are actually needed to produce a significant cooling effect,"" says Gabriele Manoli, former postdoc with the Chair of Hydrology and Water Resources Management at ETH Zurich and lead author of the recently published article in the journal Nature. More green spaces: not always the most efficient solution Manoli and his colleagues from ETH Zurich, Princeton University and Duke University studied data from some 30,000 cities worldwide and their surrounding environment, taking into consideration the average summer temperature, the population size and the annual rainfall. The urban heat island phenomenon is more pronounced the bigger the city and the more rainfall in that region. As a general rule, more rain encourages plant growth in the surrounding area, making this cooler than the city. This effect is the strongest when annual rainfall averages around 1500 millimetres as in Tokyo, but does not increase further with more rain. Two climate extremes illustrate well the role of vegetation on the urban heat island phenomenon: very dry regions on the one hand, and tropical areas on the other. Through carefully targeted planting, a city like Phoenix in the USA could achieve cooler temperatures than the surrounding countryside, where conditions are almost desert-like. By comparison, a city surrounded by tropical forests, such as Singapore, would need far more green spaces to reduce temperatures, but this would also create more humidity. In cities located in tropical zones, other cooling methods are therefore expected to be more effective, such as increased wind circulation, more use of shade and new heat-dispersing materials. ""There is no single solution,"" Manoli says. ""It all depends on the surrounding environment and regional climate characteristics."" Useful information for city planners Manoli explains that the main benefit of the study is a preliminary classification of cities, in the form of a clear visualisation guiding planners on possible approaches to mitigate the urban heat island effect. ""Even so, searching for solutions to reduce temperatures in specific cities will require additional analysis and in-depth understanding of the microclimate,"" he stresses. ""Such information, however, is based on data and models available to city planners and decision-makers only in a handful of cities, such as Zurich, Singapore or London."" Manoli is currently analysing data from other periods of the year and is studying which types of plant are most suitable for reducing temperatures. The support provided by the Branco Weiss Fellowship allowed the environmental engineer to work with scientists from the areas of physics, urban studies and social sciences with a specific focus on interdisciplinary research topics. "
Science Daily,Earthquake Study Casts Doubt on Early Warnings but Hints at Improved Forecasting,Earth & Climate,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904130614.htm,"   Since the 1980s seismologists -- earthquake researchers -- have wondered how feasible it might be to predict how an earthquake will behave given some information about its initial conditions. In particular whether you can tell the eventual magnitude based on seismic measurements near the point of origin, or epicenter. Most researchers consider this idea too improbable given the randomness of earthquake behavior, but Ide thinks there's more to it than that. ""Taking inspiration from a study comparing different-sized earthquakes, I decided to analyze a seismic data set from a region known as the Tohoku-Hokkaido subduction zone in eastern Japan,"" said Ide. ""A systematic comparison of around 100,000 seismic events over 15 years leads me to believe earthquakes are not different in random ways but share many similarities."" To draw comparisons between different earthquakes, Ide first selected the larger examples from the data set with magnitudes greater than 4.5. He also selected smaller earthquakes in the same regions as these larger ones. Ide then ascertained mathematically how similar seismic signals were between pairs of large and small earthquakes. He used a statistical function for the comparison of signals called a cross-correlation on data from 10 seismic stations close to the pairs of earthquakes in each case. ""Some pairs of large and small earthquakes start with exactly the same shaking characteristics, so we cannot tell the magnitude of an earthquake from initial seismic observations,"" explained Ide. ""This is bad news for earthquake early warning. However, for future forecasting attempts, given this symmetry between earthquakes of different magnitudes, it is good to know they are not completely random."" "
Science Daily,Putting a Price on Carbon Pollution Alone Unlikely to Help Reach Climate Goals,Earth & Climate,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904113219.htm,"   The Paris Agreement, signed in 2015, requires nations to collectively limit global warming to 2¬∞C by 2100, and to pursue efforts to limit the temperature increase even further to 1.5¬∞C. This goal requires human-caused carbon dioxide (CO2) emissions to reach zero by 2070 and become negative afterwards, using strategies that remove CO2 from the air, such as carbon capture technologies or planting trees. However, a new study by Imperial College London researchers shows that carbon taxes, which are the currently favoured system for reaching this target, will not be enough to avoid catastrophic climate change. They instead suggest that alongside carbon taxes, which put a price on emissions, there also need to be incentives for strategies that remove CO2 from the atmosphere. They say this will encourage these strategies to be implemented at a commercial scale in order to reach the Paris Agreement goals. The study is published in Joule. Study lead author Habiba Daggash, from the Centre for Environmental Policy at Imperial, said: ""The current system of penalising greenhouse gas emissions through carbon taxes is not sufficient to avoid catastrophic climate change, even if very high taxes are enforced. Therefore, using this strategy alone, the Paris Agreement that most countries have committed to could not be delivered. ""The system needs to be adapted to recognise that not only do emissions need to be penalised, but actions that result in permanent removal of greenhouse gases from the atmosphere must also be credited."" Placing a price on carbon, usually in the form of taxes on emissions, has been touted as a way of allowing market forces to produce a low-carbon economy, in which using low-carbon forms of energy is seen as an advantage. Using the UK as an example, Habiba and Dr Niall Mac Dowell, also from the Centre for Environmental Policy, modelled the future UK energy system based on several scenarios concerning levels of carbon taxation and incentives for carbon removal. Their analysis shows that much higher carbon taxes than current levels are enough to create a push for low-carbon technologies that satisfy emissions goals in the short term. However, higher carbon taxes are not enough to incentivise the development and deployment of carbon removal strategies, which are necessary to reach long-term goals. If, instead, governments incentivised carbon removal strategies much earlier, then carbon taxes could remain lower while still encouraging removal strategies to be developed and deployed on a large scale. Habiba said: ""Early incentives could both reduce the cost of delivering the Paris Agreement and satisfy our long-term need for negative emissions."" The team say that the UK case study could apply to other regions, and are now investigating the situation in developing economies, using Nigeria as a case study. "
Science Daily,New Model Predicts Painted Lady Butterfly Migrations Based on Breeding Sites Data,Earth & Climate,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904100743.htm,"   The new approach could be used to study potential effects of climate change in the behaviour of migratory insects Researchers from the Institute of Evolutionary Biology (IBE), a joint research institute of the Spanish National Research Council (CSIC) and Pompeu Fabra University (UPF), in Barcelona, Spain, and from the University of Grenoble-Alpes in France, have developed a method for predicting where the populations of the migratory Painted Lady butterfly (Vanessa cardui) distribute along the year and across their Europe-Africa migratory range. Their findings are published today in the journal Proceedings of the Royal Society B. In a previously published study, the researchers demonstrated that Painted Lady butterflies migrate from Europe to tropical Africa by the end of summer, crossing the Mediterranean Sea and Sahara Desert. In a follow-up study, the researchers showed that the offspring of these migrants reverse their migration towards Europe in spring. Thus, the Painted Lady butterfly travels 15,000 km between Africa and Europe through multiple generations to seasonally exploit resources and favourable climates in both continents. ""The challenge now is to understand how migratory species are able to optimize time and space as to properly find the environmental requirements that each generation need for their survival"" states Gerard Talavera, the leading author, researcher at IBE and a National Geographic Explorer. - The key is to find the caterpillars - Migratory insects are in a continuous move, and it is difficult to track from where to where they migrate. One of the main reasons for species to migrate is to find the optimal environmental conditions to raise a new generation. The immatures (eggs, caterpillars and cocoons) are key stages in the butterfly life cycle, which, unlike the adults, cannot escape from adverse situations. Thus, their breeding habitat is a very good indicator of the specific requirements that the species need to survive. The present study has gathered information of up to 646 breeding occurrences of Painted Lady butterflies in 30 countries. By using time-series of 35 years of monthly climatic data, the researchers have built a model that defines the breeding requirements of the species and produced a map of the most probable areas for the species to breed every month. ""We thought that we could learn about the movements of the adults by looking at where the caterpillars grow at different times of the year"" says Mattia Menchetti, member of the research team. ""If we can map in space and time the sites where they breed along the year, then we can understand from where to where the adults can migrate."" The species rely on their reproductive success in both continents: Africa and Europe The model shows that the species is forced to move across its overall range, since suitable breeding habitat is rarely permanent all the year. ""Because the species breeds continuously for the entire year, its reproductive success relies on both continents. The results show the relevance of the sub-Saharan winter population stock in sustaining the migrations of the species into Europe,"" says Talavera. However, the situation could eventually revert if the overall permanent suitable extent grows substantially in the future, as a consequence of global warming. ""We cannot discard that the impact of rapid climate change may affect the butterfly migratory phenomena in unpredictable ways, as has already been shown to happen in migratory birds,"" adds Talavera. The overwintering missing generations might be near the equator  Even if it has been proved that most populations of the Painted Lady butterfly spend the winters in the sub-Sahara, many of the precise localities are still unknown. Thanks to this new modelling approach, the researchers have identified the potential niche requirements of the species during the winter in Africa, and thus the sites where these could aggregate to breed. According to the results of the study, the butterflies could locate near the equatorial latitudes between December and February. This scenario confirms that the overall migratory circuit undertaken by the annual successive generations might encompass up to 15,000 km, from the equator (e.g. Kenyan and Cameroonian highlands) to northern Scandinavia. A global project  The findings published in Proceedings of the Royal Society B are part of a wider project aimed at studying the Painted Lady's migratory behaviour and routes worldwide. With that goal in mind, the team lead a long-term global citizen science project called The Worldwide Painted Lady Migration, which invites citizens from all over the word to communicate observations of the Painted Lady butterfly. "
Science Daily,New Way to Reduce Food Waste,Earth & Climate,2019-09-03,-,https://www.sciencedaily.com/releases/2019/09/190903153825.htm,"   That, in turn, raises the cost and environmental impact of feeding the world's population. Researchers are suggesting a potential solution -- they found that 'humanizing' produce can change consumer attitudes toward fresh fruits and vegetables that are showing signs of age. The work, published in the Journal of the Association for Consumer Research, found that depicting imperfect-looking but still nutritious produce with human characteristics enhanced the food's appeal. ""We suggest that when old produce is humanized, it is evaluated more favorably, since it leads consumers to evaluate the old produce with a more compassionate lens,"" the researchers wrote. Vanessa Patrick, Bauer Professor of Marketing at the University of Houston and a coauthor on the paper, said the researchers examined how attitudes toward human aging -- ""old is gold,"" vs. ""young is good"" -- translated to attitudes toward so-called ""mature"" produce. The project involved anthropomorphizing bananas, cucumbers and zucchini, or depicting the produce in ways that suggest human-like traits. Bananas, for example, were depicted sunbathing while reclining in a chaise. Cucumber slices were used to create a picture of a human face. ""With fresh produce, aging promotes visible changes, much as it does in humans,"" Patrick said. ""That can create a connection with human qualities of aging when the food is anthropomorphized."" In the study, participants were shown depictions of both fresh and slightly-past-its-prime produce in both anthropomorphized and unadorned states. Those who saw the anthropomorphized aging produce rated it as more desirable than participants who saw the same produce without the anthropomorphic effects. Anthropomorphism didn't affect perceptions of fresh produce. The researchers said the results suggest grocery store managers and other marketers should consider using similar strategies to promote produce that has begun to show signs of aging but remains nutritious and tasty. ""Making food that would otherwise go to waste more appealing to consumers may allow store managers to avoid having to reduce the price for that older produce, which would improve the bottom line,"" Patrick said. "
Science Daily,New Whale Species Discovered Along the Coast of Hokkaido,Earth & Climate,2019-09-03,-,https://www.sciencedaily.com/releases/2019/09/190903113335.htm,"   In a collaboration between the National Museum of Nature and Science, Hokkaido University, Iwate University, and the United States National Museum of Natural History, a beaked whale species which has long been called Kurotsuchikujira (black Baird's beaked whale) by local Hokkaido whalers has been confirmed as the new cetacean species Berardius minimus (B. minimus). Beaked whales prefer deep ocean waters and have a long diving capacity, making them hard to see and inadequately understood. The Stranding Network Hokkaido, a research group founded and managed by Professor Takashi F. Matsuishi of Hokkaido University, collected six stranded un-identified beaked whales along the coasts of the Okhotsk Sea. The whales shared characteristics of B. bairdii (Baird's beaked whale) and were classified as belonging to the same genus Berardius. However, a number of distinguishable external characteristics, such as body proportions and color, led the researchers to investigate whether these beaked whales belong to a currently unclassified species. ""Just by looking at them, we could tell that they have a remarkably smaller body size, more spindle-shaped body, a shorter beak, and darker color compared to known Berardius species,"" explained Curator Emeritus Tadasu K. Yamada of the National Museum of Nature and Science from the research team. In the current study, the specimens of this unknown species were studied in terms of their morphology, osteology, and molecular phylogeny. The results, published in the journal Scientific Reports, showed that the body length of physically mature individuals is distinctively smaller than B. bairdii (6.2-6.9m versus 10.0m). Detailed cranial measurements and DNA analyses further emphasized the significant difference from the other two known species in the genus Berardius. Due to it having the smallest body size in the genus, the researchers named the new species B. minimus. ""There are still many things we don't know about B. minimus,"" said Takashi F. Matsuishi. ""We still don't know what adult females look like, and there are still many questions related to species distribution, for example. We hope to continue expanding what we know about B. minimus."" Local Hokkaido whalers also refer to some whales in the region as Karasu (crow). It is still unclear whether B. minimus (or Kurotsuchikujira) and Karasu are the same species or not, and the research team speculate that it is possible Karasu could be yet another different species. This study was conducted in collaboration with multiple institutions. Dr. Shino Kitamura and Dr. Shuichi Abe of Iwate University carried out the DNA analyses while Dr. Tadasu K. Yamada and Dr. Yuko Tajima of the National Museum of Nature and Science made osteological specimens, morphological observations and detailed measurements to depict systematic uniqueness. Dr. Takashi F. Matsuishi and Dr. Ayaka Matsuda of Hokkaido University made the multivariate analyses. Dr. James G. Mead of Smithsonian Institution contributed to discussions related to systematic comparison. "
Science Daily,Birds in Serious Decline at Lake Constance,Earth & Climate,2019-09-03,-,https://www.sciencedaily.com/releases/2019/09/190903105223.htm,"   This seeming contradiction is due to the fact that the most common species are disappearing particularly rapidly. Six of the ten most common bird species around Lake Constance have declined dramatically in number, while two have remained the same and only two have increased. The population of house sparrows, for example, has declined by 50 percent since 1980, at which time it was still the most common species. ""These are really shocking figures -- particularly when you consider that the bird population started declining decades before the first count in 1980,"" explains Hans-G√ºnther Bauer from the Max Planck Institute of Animal Behavior. Viewed over a lengthier period, the fall in numbers may therefore be even greater. Agricultural landscape hostile to birds It is particularly noticeable how differently the various habitats have been affected. The study indicates that bird populations around Lake Constance are dwindling particularly rapidly in countryside, which is intensively used by humans. This applies above all to modern farmland: 71 percent of the species that inhabit fields and meadows have declined in numbers, in some cases drastically. The partridge, for example, which was once a common inhabitant of the region's farmland, has completely died out around Lake Constance. The great grey shrike, the meadow pipit and the little owl have also disappeared from the area. One of the main reasons for this decline is the scarcity of food. According to the ornithologists, 75 percent of the bird species that eat flying insects and 57 percent of those that eat terrestrial invertebrates have decreased in number around Lake Constance. ""This confirms what we have long suspected: the human extermination of insects is having a massive impact on our birds,"" says Bauer. In addition, today's efficient harvesting methods leave hardly any seeds behind for granivorous species. Moreover, the early, frequent mowing of large areas of grassland, the agricultural practice of monoculture, the early ripening of winter grains, the implementation of drainage measures and the shortage of fallow land are destroying the habitats of many species that live in the open countryside. However, the birds are disappearing not only from the fields and meadows but also from the towns and villages around Lake Constance. ""The increasing need for order and decreasing tolerance of dirt and noise are making life more and more difficult for local birds. It appears that successful breeding is becoming increasingly rare since the birds are being forced to nest amid tower blocks, ornamental trees and immaculate kitchen gardens,"" says Bauer. Even species that can survive virtually anywhere, such as blackbirds (down 28 percent), chaffinches and robins (each down 24 percent) are suffering greatly due to the deteriorating conditions in settled areas. Winners and losers in the woods and on the water In contrast, the woodland birds around Lake Constance appear to be doing comparatively well. 48 percent of the forest-dwelling species are increasing in number, while only 35 percent are dwindling. One example is the spotted woodpecker, whose numbers have grown by 84 percent. Like other woodpeckers, it seems to have benefited from the larger quantities of timber in the forest. Furthermore, more of the species that inhabit the wetlands around Lake Constance have increased than decreased. The winners here include the mute swan. Nevertheless, the numbers of many forest-dwelling species are also declining. The wood warbler population, for example, has fallen by 98 percent, firecrest numbers by 61 percent. This is how the intensive use of timber around Lake Constance and the shorter felling intervals are making themselves felt. Trees containing nests are being felled even in protected areas, and breeding seasons are largely being ignored. Older trees are often felled for traffic safety reasons; new paths are laid in the forests and wet areas are drained. All in all, the last population count in 2010-2012 documents the same developments and causes as those that preceded it. However, the situation has clearly worsened in some cases. There is hardly any indication that things have changed for the better since then. ""The living conditions for birds around Lake Constance have in fact deteriorated further over the last seven years. This means that their numbers have presumably fallen still further in this time,"" says Bauer. More food and living space for birds With its diverse structure and location in the foothills of the Alps, the Lake Constance region actually provides excellent living conditions for birds. However, the changes it has undergone over the last few decades are typical of densely populated regions with intensive farming and forestry. ""This means that the rapid decline in the populations of many species that we have observed around Lake Constance is sure to be happening in other regions as well,"" says Bauer. The study is one of only a few long-term investigations of breeding bird populations ever conducted in Germany. In order to collect the most recent data, which dates from between 2010 and 2012, 90 volunteers joined the scientists and counted all the birds in an area of approximately 1,100 square kilometres surrounding Lake Constance. The ornithologists first recorded the bird population between 1980 and 1981 and have repeated the count every ten years ever since. The next count will take place between 2020 and 2022.- Measures that would benefit the bird populations include:    - The scientists are calling for agricultural and forestry policy to be reconsidered in order to counteract the rapid loss of biodiversity. - Drastically restricting the use of insecticides and herbicides in forestry and agriculture, in public spaces and in private gardens - Significantly reducing the use of fertilisers - Converting at least ten percent of agricultural land to ecological conservation areas - Leaving some areas of arable land and grassland uncultivated in winter and during the breeding season - Late mowing outside the grassland birds' breeding season, maintenance of flower strips and fallow areas for seed production - At least five percent of woodland should be left completely unused - Creating natural gardens using indigenous plants "
Science Daily,Concussions Linked to Erectile Dysfunction in Former Pro Football Players,Science & Society,2019-08-26,-,https://www.sciencedaily.com/releases/2019/08/190826121940.htm,"   The research -- based on a survey of more than 3,400 former NFL players representing the largest study cohort of former professional football players to date -- was conducted by investigators at the Harvard T.H. Chan School of Public Health and Harvard Medical School as part of the ongoing Football Players Health Study at Harvard University, a research program that encompasses a constellation of studies designed to evaluate various aspects of players' health across their lifespans. The researchers caution that their findings are observational -- based on self-reported concussion symptoms and indirect measures of ED and low testosterone. The results do not prove a cause-effect link between concussion and ED, nor do they explain exactly how head trauma might precipitate the onset of ED, the investigators noted. However, the findings do reveal an intriguing and powerful link between history of concussions and hormonal and sexual dysfunction, regardless of player age. Notably, the ED risk persisted even when researchers accounted for other possible causes such as diabetes, heart disease or sleep apnea, for example. Taken together, these findings warrant further study to tease out the precise mechanism behind it. One possible explanation, the research team said, could be injury to the brain's pituitary gland that sparks a cascade of hormonal changes culminating in diminished testosterone and ED. This biological mechanism has emerged as a plausible explanation in earlier studies that echo the current findings, such as reports of higher ED prevalence and neurohormonal dysfunction among people with head trauma and traumatic brain injury, including military veterans and civilians with head injuries. The new findings also suggest that sleep apnea and use of prescription pain medication contribute to low testosterone and ED. It remains unclear whether they do so independently, as consequences of head injury or both, the researchers said. Sexual function is not only a critical marker of overall health but also central to overall well-being, the researchers note. Understanding the mechanisms behind the possible downstream effects of head injury, they said, can inform treatments and preventive strategies. ""Former players with ED may be relieved to know that concussions sustained during their NFL careers may be contributing to a condition that is both common and treatable,"" said study lead author Rachel Grashow, a researcher at the Harvard T.H. Chan School of Public Health. The results are based on a survey of 3,409 former NFL players, average age 52 years (age range 24 to 89), conducted between 2015 and 2017. Participants were asked to report how often blows to the head or neck caused them to feel dizzy, nauseated or disoriented, or to experience headaches, loss of consciousness or vision disturbances -- all markers of concussion. Responders were grouped in four categories by number of concussive symptoms. Next, the former players were asked whether a clinician had recommended medication for either low testosterone or ED, and whether they were currently taking such medications. Men who reported the highest number of concussion symptoms were two and a half times more likely to report receiving either a recommendation for medication or to be currently taking medication for low testosterone, compared to men who reported the fewest concussion symptoms. Men with the most concussion symptoms were nearly two times more likely to report receiving a recommendation to take ED medication or to be currently taking ED medication than those reporting the fewest symptoms. Players who reported losing consciousness following head injury had an elevated risk for ED even in the absence of other concussion-related symptoms. Notably, even former players with relatively few concussion symptoms had an elevated risk for low testosterone, a finding that suggests there may be no safe threshold for head trauma, the team said. Of all participants, 18 percent reported low testosterone and nearly 23 percent reported ED. Slightly less than 10 percent of participants reported both. As expected, individuals with cardiovascular disease, diabetes, sleep apnea and depression, as well as those taking prescription pain medication -- all of which are known to affect sexual health -- were more likely to report low testosterone levels and ED. Yet, the link between concussion history and low testosterone levels and ED persisted even after researchers accounted for these other conditions. The link between history of concussion and ED was present among both the older and the younger players -- those under age 50 in this case -- the analysis showed, and it persisted over time. ""We found the same association of concussions with ED among both younger and older men in the study, and we found the same risk of ED among men who had last played twenty years ago,"" said study senior author Andrea Roberts, a researcher at the Harvard T.H. Chan School of Public Health. ""These findings suggest that increased risk of ED following head injury may occur at relatively young ages and may linger for decades thereafter."" Given that ED is both fairly common and easily treatable, those who experience symptoms are encouraged to report them to their physicians, the researchers said. Importantly, prompt evaluation of ED is critical because it can signal the presence of other conditions, including heart disease and diabetes. The findings also suggest that it may be important for clinicians to assess all patients with concussion history for the presence of neurohormonal changes. ""ED is a fact of life for many men,"" said Herman Taylor, director of player engagement and education and director of the Cardiovascular Research Institute at Morehouse School of Medicine. ""Anyone with symptoms should seek clinical attention and thorough evaluation, particularly since ED can be fueled by cardiovascular and metabolic disorders. The good news is that this is a treatable condition."" Co-investigators included Marc Weisskopf, Karen Miller, David M. Nathan, Ross Zafonte, Frank Speizer, Theodore Courtney, Aaron Baggish, Alvaro Pascual-Leone and Lee Nadler. The research was supported by the National Football League Players Association (NFLPA). "
Science Daily,Putting a Price on Carbon Pollution Alone Unlikely to Help Reach Climate Goals,Science & Society,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904113219.htm,"   The Paris Agreement, signed in 2015, requires nations to collectively limit global warming to 2¬∞C by 2100, and to pursue efforts to limit the temperature increase even further to 1.5¬∞C. This goal requires human-caused carbon dioxide (CO2) emissions to reach zero by 2070 and become negative afterwards, using strategies that remove CO2 from the air, such as carbon capture technologies or planting trees. However, a new study by Imperial College London researchers shows that carbon taxes, which are the currently favoured system for reaching this target, will not be enough to avoid catastrophic climate change. They instead suggest that alongside carbon taxes, which put a price on emissions, there also need to be incentives for strategies that remove CO2 from the atmosphere. They say this will encourage these strategies to be implemented at a commercial scale in order to reach the Paris Agreement goals. The study is published in Joule. Study lead author Habiba Daggash, from the Centre for Environmental Policy at Imperial, said: ""The current system of penalising greenhouse gas emissions through carbon taxes is not sufficient to avoid catastrophic climate change, even if very high taxes are enforced. Therefore, using this strategy alone, the Paris Agreement that most countries have committed to could not be delivered. ""The system needs to be adapted to recognise that not only do emissions need to be penalised, but actions that result in permanent removal of greenhouse gases from the atmosphere must also be credited."" Placing a price on carbon, usually in the form of taxes on emissions, has been touted as a way of allowing market forces to produce a low-carbon economy, in which using low-carbon forms of energy is seen as an advantage. Using the UK as an example, Habiba and Dr Niall Mac Dowell, also from the Centre for Environmental Policy, modelled the future UK energy system based on several scenarios concerning levels of carbon taxation and incentives for carbon removal. Their analysis shows that much higher carbon taxes than current levels are enough to create a push for low-carbon technologies that satisfy emissions goals in the short term. However, higher carbon taxes are not enough to incentivise the development and deployment of carbon removal strategies, which are necessary to reach long-term goals. If, instead, governments incentivised carbon removal strategies much earlier, then carbon taxes could remain lower while still encouraging removal strategies to be developed and deployed on a large scale. Habiba said: ""Early incentives could both reduce the cost of delivering the Paris Agreement and satisfy our long-term need for negative emissions."" The team say that the UK case study could apply to other regions, and are now investigating the situation in developing economies, using Nigeria as a case study. "
Science Daily,Automated Text Analysis: The Next Frontier of Marketing Innovation,Science & Society,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904091123.htm,"   The study, forthcoming in the January issue of the Journal of Marketing, is titled ""Uniting the Tribes: Using Text for Marketing Insights"" and authored by Jonah Berger, Ashlee Humphreys, Wendy Moe, Oded Netzer, and David Schweidel. Online reviews, customer service calls, press releases, news articles, marketing communications, and other interactions create a wealth of textual data companies can analyze to optimize services and develop new products. By some estimates, 80-95% of all business data is unstructured, with most of that being text. This text has the potential to provide critical insights about its producers, including individuals' identities, their relationships, their goals, and how they display key attitudes and behaviors. This text can be aggregated to create insights about organizations and social institutions and how attitudes vary over cultural contexts, demographics, groups, and time. Berger explains that ""The digitization of information has made a wealth of textual data readily available. But by itself, all this data is just that. Data. For data to be useful, researchers have to be able to extract underlying insight -- to measure, track, understand, and interpret the causes and consequences of marketplace behavior."" But how can marketers do that? The research team explains how researchers and managers can use text to better understand the individuals and organizations who produce the text. The article also explores how the content of text affects various audiences. For example, how consumers may be influenced to change their behaviors or brands influenced to attend to issues raised by consumers depends in large part on the content of text. Moe adds that ""Automated text analysis opens the black-box of interactions, allowing researchers to directly access what is being said and how it is said in marketplace communication."" Given the volume of text data available, automated text analysis methods are critical, but need to be handled carefully. Researchers should avoid over-fitting and weigh the importance of features to glean and use the right predictors from text. Thus, this article also provides an overview of the methodologies and metrics used in text analysis, providing a set of guidelines and procedures for marketing researchers and marketing scholars. Understanding these methods help us understand how text is used and processed. For example, virtual assistants are currently under scrutiny for the fact that humans are listening to the audio recordings. However, this process is necessary to train the machines used for automated text analysis. The goal of this article is to further the collective understanding of text analysis and how it can be used for insights. Researchers and marketers can use this article to create frameworks, establish and communicate policies, and strengthen cross-functional collaboration with teams working on textual analytics projects. "
Science Daily,What If We Paid Countries to Protect Biodiversity?,Science & Society,2019-08-30,-,https://www.sciencedaily.com/releases/2019/08/190830112815.htm,"   After long negotiations, the international community has agreed to safeguard the global ecosystems and improve on the status of biodiversity. The global conservation goals for 2020, called the Aichi targets, are an ambitious hallmark. Yet, effective implementation is largely lacking. Biodiversity is still dwindling at rates only comparable to the last planetary mass extinction. Additional effort is required to reach the Aichi targets and even more so to halt biodiversity loss. ""Human well-being depends on ecological life support. Yet, we are constantly losing biodiversity and therefore the resilience of ecosystems. At the international level, there are political goals, but the implementation of conservation policies is a national task. There is no global financial mechanism that can help nations to reach their biodiversity targets,"" says lead author Nils Droste from Lund University, Sweden. Brazil has successfully implemented Ecological Fiscal Transfer systems that compensate municipalities for hosting protected areas at a local level since the early 1990's. According to previous findings, such mechanisms help to create additional protected areas. The international research team has therefore set out to scale this idea up to the global level where not municipalities but nations are in charge of designating protected areas. They developed and compared three different design options: An ecocentric model: where only protected area extent per country counts -- the bigger the protected area, the better; A socio-ecological model: where protected areas and Human Development Index count, adding development justice to the previous model; An anthropocentric model: where population density is also considered, as people benefit locally from protected areas. The socio-ecological design was the one that proved to be the most efficient. The model provided the highest marginal incentives -- that is, the most additional money for protecting an additional percent of a country's area -- for countries that are the farthest from reaching the global conservation goals. The result surprised the researchers. ""While we developed the socio-ecological design with a fairness element in mind, believing that developing countries might be more easily convinced by a design that benefits them, we were surprised how well this particular design aligns with the global policy goals,"" says Nils Droste. ""It would most strongly incentivize additional conservation action where the global community is lacking it the most,"" he adds. As the study was aimed at providing options, not prescriptions for policy makers, the study did not detail who should be paying or how large the fund should exactly be. Rather, it provides a yet unexplored option to develop a financial mechanism for biodiversity conservation akin to what the Green Climate Fund is for climate change. ""We know that we need to change land use in order to preserve biodiversity. Protecting land from degradation and providing healthy ecosystems, clean air or clean rivers is a function of the state. Giving a financial reward to governments for such public ecosystem services will ease the provision of corresponding conservation efforts and will help to put this on the agenda,"" concludes Nils Droste. "
Science Daily,Ancient Civilizations Were Already Messing Up the Planet,Science & Society,2019-08-29,-,https://www.sciencedaily.com/releases/2019/08/190829150702.htm,"   ""Through this crowdsourced data, we can see that there was global environmental impact by land use at least 3,000 years ago,"" says Gary Feinman, MacArthur Curator of Anthropology at the Field Museum and one of the study's 250 authors. ""And that means that the idea of seeing human impact on the environment as a newer phenomenon is too focused on the recent past."" Feinman says that to understand our current climate crisis, we need to understand the history of humans altering their environments. The study, led by Lucas Stephens of the University of Pennsylvania, is a part of a larger project called ArchaeoGLOBE, where online surveys are used to gather information from regional experts on how land use has changed over time in 146 different areas around the world. Land use can be anything from hunting and gathering to farming to grazing animals. And as it turns out, many of the ways ancient people used the land weren't as ""leave-no-trace"" as many have imagined. ""About 12,000 years ago, humans were mainly foraging, meaning they didn't interact with their environments as intensively as farmers generally do,"" says Feinman. ""And now we see that 3,000 years ago, we have people doing really invasive farming in many parts of the globe."" Humans in these time periods began clearing out forests to plant food and domesticating plants and animals to make them dependent on human interaction. Early herders also changed their surroundings through land clearance and selective breeding. While these changes were at varying paces, the examples are now known to be widespread and can provide insight on how we came to degrade our relationship with the Earth and its natural resources. ""We saw an accelerated trajectory of environmental impact,"" says Ryan Williams, associate curator and head of anthropology at the Field Museum and co-author of the study. ""While the rate at which the environment is currently changing is much more drastic, we see the effects that human impacts had on the Earth thousands of years ago."" The results, however, are more optimistic than they seem. Now that researchers know the beginnings of environmental impact, they can use this data to study what solutions ancient civilizations used to mitigate the negative effects of deforestation, water scarcity, and more. In addition to pointing out the history behind what most assume is a recent phenomenon, the study is one of the first of its kind to operate on such a large scale. Use of online resources and professional connections helped the project span across the world. The emphasis now, however, is on the parts we often miss. ""We need to invest in these regions that haven't been as intensively studied,"" says Williams. ""If we incentivize and create opportunities for researchers there then you can just imagine what the results of the next study like this could be."" For a long time, war, environment, transportation and colonization prevented researchers from being able to work together and share their findings about certain parts of the world. As a result, today's archaeologists are still adding to and growing the network of expertise in these regions. ""What really got me here was not so much the results, although I think that the results provide a foundation to support what many archeologists suspected,"" says Feinman. ""But I think the most innovative aspect of this was the whole research design. To gather information from 250 scholars and to make sure that the whole world was covered, that's really something."" While today's climate change and environmental destruction are happening more quickly and on a far larger scale than the world has ever seen, Feinman notes that this study helps provide a historical context to today's problems. ""There's such a focus on how the present is different from the past in contemporary science. I think this study provides a check, a counter-weight to that, by showing that yes, there have been more accelerated changes in land use recently, but humans have been doing this for a long time. And the patterns start 3,000 years ago,"" says Feinman. ""It shows that the problems we face today are very deep-rooted, and they are going to take more than simple solutions to solve. They cannot be ignored."" "
Science Daily,Ultra-Fast Bomb Detection Method Could Upgrade Airport Security,Science & Society,2019-08-29,-,https://www.sciencedaily.com/releases/2019/08/190829101051.htm,"   In a comprehensive two-part paper published by the journal Propellants, Explosives, Pyrotechnics and Forensic Science International: Synergy, a team of researchers from Surrey detail how they have built on their previous ground-breaking work on super-fast fingerprint drug testing, to develop a technique that is able to detect key explosives in just 30 seconds. The new method, which uses swabbing material to collect samples of explosives, is able to detect substances such as nitrotoluenes, trinitrotriazine, hexamethylene triperoxide diamine and nitroglycerine. Detection of peroxide-based explosives is key as high-profile terrorist attacks such as the London bombings in 2007 used devices made from these materials. Surrey's swab spray technique is able to achieve higher sensitivity results than previously published works and was also tested on dirty surfaces such as new and used keyboards. Dr Melanie Bailey, co-author of the paper from the University of Surrey, said: ""It's the unfortunate reality that security, especially in our airports, has to stay several steps ahead of those that wish to cause harm and destruction. The current thermal based way of detecting explosive material is becoming outdated and has the propensity of producing false positives. What we demonstrate with our research is an extremely fast, accurate and sensitive detection system that is able to identify a wide range of explosive materials."" Dr Catia Costa, co-author of the paper from the University of Surrey, said: ""The need for fast screening methods with enhanced selectivity and sensitivity to explosives has reached a new boiling point with the recent terrorist activity. The use of paper spray for applications such as these may help reduce false-negative events whilst also allowing simultaneous detection of other substances such as drugs, as previously reported by our group."" Dr Patrick Sears, co-author of the paper from the University of Surrey, said: ""The critical advantage of this system is the ability to uniquely identify the explosive being detected, making it much less likely to create false alarms. The selectivity of this system means that it could also be used to identify a range of other threat materials whilst the sensitivity would allow the detection of invisible traces of explosives."" "
Science Daily,Most-Comprehensive Analysis of Fentanyl Crisis Urges Innovative Action,Science & Society,2019-08-29,-,https://www.sciencedaily.com/releases/2019/08/190829081407.htm,"   ""This crisis is different because the spread of synthetic opioids is largely driven by suppliers' decisions, not by user demand,"" said Bryce Pardo, lead author of the study and an associate policy researcher at RAND, a nonprofit research organization. ""Most people who use opioids are not asking for fentanyl and would prefer to avoid exposure."" While fentanyl had appeared in U.S. illicit drug markets before, production was limited to one or a few capable chemists, and bottlenecks in production and distribution slowed the drug's diffusion. Law enforcement was able to detect and shut down illicit manufacture to contain these outbreaks. RAND researchers found that today's synthetic opioid surge is fueled by multiple sources. Mexican drug trafficking organizations smuggle fentanyl into the U.S., and China's pharmaceutical and chemical industries are inadequately regulated, allowing producers to advertise and ship synthetic opioids to buyers anywhere in the world. While traditional criminal organizations play a role in the spread of fentanyl, the internet also has made it easier to traffic these drugs and to share information about their synthesis. Overdose deaths involving fentanyl and other synthetic opioids have increased from about 3,000 in 2013 to more than 30,000 in 2018. These deaths have remained concentrated in Appalachia, the mid-Atlantic and New England. ""While synthetic opioids have not yet become entrenched in illicit drug markets west of the Mississippi River, authorities must remain vigilant,"" said Jirka Taylor, study co-author and senior policy analyst at RAND. ""Even delaying the onset in these markets by a few years could save thousands of lives."" For U.S. policymakers, nontraditional strategies may be required to address this new challenge. The researchers avoid making specific policy recommendations, but advocate consideration of a broad array of innovative approaches such as supervised consumption sites, creative supply disruption, drug content testing, and increasing access to novel treatments that are available in other countries, such as heroin-assisted treatment. ""Indeed, it might be that the synthetic opioid problem will eventually be resolved with approaches or technologies that do not currently exist or have yet to be tested,"" said Beau Kilmer, study co-author and director of the RAND Drug Policy Research Center. ""Limiting policy responses to existing approaches will likely be insufficient and may condemn many people to early deaths."" RAND researchers say that since the diffusion of fentanyl is driven by suppliers' decisions, it makes sense to consider supply disruption as one piece of a comprehensive response, particularly where that supply is not yet firmly entrenched. But the researchers note there is little reason to believe that tougher sentences, including drug-induced homicide laws for low-level retailers and couriers, will make a difference. Instead, they call for an exploration of innovative disruption efforts that confuse or dissuade online sourcing. The study is the most comprehensive document to be published on the past, present and future of illicit synthetic opioids. RAND researchers analyzed mortality and drug seizure data, reviewed existing literature, and conducted expert interviews and international case studies. RAND researchers examined synthetic opioid markets across the U.S. and in other parts of the world, such as Estonia (where fentanyl first appeared 20 years ago). Canada's experience with synthetic opioids is most similar to that in the United States in terms of its timing, sudden increase in drug-related harms, and regional concentration. ""Problems in parts of Canada are as severe as in the Eastern United States despite substantial differences in drug policy, and the delivery of public health and social services,"" said Jonathan Caulkins, study co-author and Stever University Professor at Carnegie Mellon University. A handful of other countries in Europe also have seen synthetic opioids increasingly displace heroin. Their experience is varied and shows a range of directions some future markets in the United States may take. For instance, Sweden developed an online market with fentanyl analogs sold primarily as nasal sprays. Evidence from abroad suggests synthetic opioids may be here to stay: the study found no instance where fentanyl lost ground to another opioid after attaining a dominant position in drug markets. Funding for the study was provided by RAND Ventures, which is supported by gifts from RAND supporters and income from operations. The study: The Future of Fentanyl and Other Synthetic Opioids. "
Science Daily,Clues to Early Social Structures May Be Found in Ancient Extraordinary Graves,Science & Society,2019-08-28,-,https://www.sciencedaily.com/releases/2019/08/190828143053.htm,"   As early farming communities gave rise to larger, more complex sedentary societies, new social hierarchies arose, presenting opportunities for individual people to achieve positions of importance. The authors cite two archetypal ""pathways to power"" such individuals might follow: one self-aggrandizing and often autocratic, and the other more group-oriented and egalitarian. But how these ""pathways"" were expressed in early cultures remains unclear. This study focused on a single burial in the Ba'ja settlement of southern Jordan, dating between 7,500-6,900 BC, during the Late Pre-Pottery B Period. The elaborate construction of this grave and sophistication of associated symbolic objects suggest the deceased was a person of importance in the ancient society. The authors suggest that the presence of exotic items in the grave indicate a person who achieved individual prestige by access to trade networks, while the proximity of the grave to other less elaborate graves indicates that they were nonetheless considered close in status to the broader community, not neatly fitting either archetype of a powerful individual. The authors propose that this sort of data can provide insights into cultural views toward leadership and social hierarchy in early cultures. They also suggest that further investigations of this body and others in Ba'ja, including ancient DNA analysis to illuminate familial relationships, may combine with grave information to create a more refined picture of early community social structures. The authors add: ""We suggest that leadership can be understood only by studying the social contexts and the pathways to power (not only the burials of extraordinary individuals). In fact, studying rich tombs to interpret social structures has been done before, but our new approach emphasizes the social environments of leadership. The key study of the elaborate burial of the late PPNB site of Ba'ja lets us surmise that access to leadership was possible through corporate leadership-type of primus inter pares than by autocratic coercive power."" "
Science Daily,Some Vaccine Doubters May Be Swayed by Proximity to Disease Outbreak,Science & Society,2019-08-28,-,https://www.sciencedaily.com/releases/2019/08/190828143108.htm,"   In both the US and globally, there is growing vaccine hesitancy, which can manifest itself in increased non-medical exemption rates, decreased vaccination rates and increased outbreaks of vaccine-preventable diseases. The formation of attitudes about vaccination is complex and linked to many factors including media and peer group influence, distrust of science, information access, and socio-economic barriers. In the new study, researchers surveyed 1,006 online respondents across the United States about their political beliefs, vaccination attitudes and demographics. The survey was carried out in January 2017, following local outbreaks of measles in 2016. The respondent pool was generated by a market research firm to be a nationally representative sample of the U.S. voting age population and the final sample matched known population in terms of gender, age, income race and Census region. The researchers found that an individual's proximity to a measles outbreak independent had no independent effect on measles vaccination attitudes (p = 0.43). However, they found that trust in government medical experts is strongly and positively related to vaccination attitudes (p=0.01). Moreover, the study uncovered an interactive relationship between the two variables. People who are skeptical of the CDC and similar institutions and live farther away from a disease outbreak harbor less favorable vaccination views than those who are skeptical but live in close proximity to an outbreak. People who have high levels of trust are not affected by disease proximity. The research therefore suggests that, unlike people who trust government experts, people who are skeptical of the CDC and similar institutions may consider whether or not a given disease occurs nearby when making decisions about vaccination. Justwan adds: ""In this paper, we explore whether people's vaccination attitudes with regards to measles are shaped by how far away they live from a recent outbreak. We find that this is the case -- but only for individuals who also distrust government medical experts. Put differently: citizens who are skeptical of the CDC and similar institutions base their vaccination decision-making to some degree on whether or not a given disease occurs in close vicinity to their community."" "
Science Daily,Nuclear Winter Would Threaten Nearly Everyone on Earth,Science & Society,2019-08-28,-,https://www.sciencedaily.com/releases/2019/08/190828080543.htm,"   Indeed, death by famine would threaten nearly all of the Earth's 7.7 billion people, said co-author Alan Robock, a Distinguished Professor in the Department of Environmental Sciences at Rutgers University-New Brunswick. The study in the Journal of Geophysical Research-Atmospheres provides more evidence to support The Treaty on the Prohibition of Nuclear Weapons passed by the United Nations two years ago, Robock said. Twenty-five nations have ratified the treaty so far, not including the United States, and it would take effect when the number hits 50. Lead author Joshua Coupe, a Rutgers doctoral student, and other scientists used a modern climate model to simulate the climatic effects of an all-out nuclear war between the United States and Russia. Such a war could send 150 million tons of black smoke from fires in cities and industrial areas into the lower and upper atmosphere, where it could linger for months to years and block sunlight. The scientists used a new climate model from the National Center for Atmospheric Research with higher resolution and improved simulations compared with a NASA model used by a Robock-led team 12 years ago. The new model represents the Earth at many more locations and includes simulations of the growth of the smoke particles and ozone destruction from the heating of the atmosphere. Still, the climate response to a nuclear war from the new model was nearly identical to that from the NASA model. ""This means that we have much more confidence in the climate response to a large-scale nuclear war,"" Coupe said. ""There really would be a nuclear winter with catastrophic consequences."" In both the new and old models, a nuclear winter occurs as soot (black carbon) in the upper atmosphere blocks sunlight and causes global average surface temperatures to plummet by more than 15 degrees Fahrenheit. Because a major nuclear war could erupt by accident or as a result of hacking, computer failure or an unstable world leader, the only safe action that the world can take is to eliminate nuclear weapons, said Robock, who works in the School of Environmental and Biological Sciences. "
Science Daily,Automated Text Analysis: The Next Frontier of Marketing Innovation,Business & Industry,2019-09-04,-,https://www.sciencedaily.com/releases/2019/09/190904091123.htm,"   The study, forthcoming in the January issue of the Journal of Marketing, is titled ""Uniting the Tribes: Using Text for Marketing Insights"" and authored by Jonah Berger, Ashlee Humphreys, Wendy Moe, Oded Netzer, and David Schweidel. Online reviews, customer service calls, press releases, news articles, marketing communications, and other interactions create a wealth of textual data companies can analyze to optimize services and develop new products. By some estimates, 80-95% of all business data is unstructured, with most of that being text. This text has the potential to provide critical insights about its producers, including individuals' identities, their relationships, their goals, and how they display key attitudes and behaviors. This text can be aggregated to create insights about organizations and social institutions and how attitudes vary over cultural contexts, demographics, groups, and time. Berger explains that ""The digitization of information has made a wealth of textual data readily available. But by itself, all this data is just that. Data. For data to be useful, researchers have to be able to extract underlying insight -- to measure, track, understand, and interpret the causes and consequences of marketplace behavior."" But how can marketers do that? The research team explains how researchers and managers can use text to better understand the individuals and organizations who produce the text. The article also explores how the content of text affects various audiences. For example, how consumers may be influenced to change their behaviors or brands influenced to attend to issues raised by consumers depends in large part on the content of text. Moe adds that ""Automated text analysis opens the black-box of interactions, allowing researchers to directly access what is being said and how it is said in marketplace communication."" Given the volume of text data available, automated text analysis methods are critical, but need to be handled carefully. Researchers should avoid over-fitting and weigh the importance of features to glean and use the right predictors from text. Thus, this article also provides an overview of the methodologies and metrics used in text analysis, providing a set of guidelines and procedures for marketing researchers and marketing scholars. Understanding these methods help us understand how text is used and processed. For example, virtual assistants are currently under scrutiny for the fact that humans are listening to the audio recordings. However, this process is necessary to train the machines used for automated text analysis. The goal of this article is to further the collective understanding of text analysis and how it can be used for insights. Researchers and marketers can use this article to create frameworks, establish and communicate policies, and strengthen cross-functional collaboration with teams working on textual analytics projects. "
Science Daily,Deep Transformations Needed to Achieve Sustainable Development Goals,Business & Industry,2019-08-26,-,https://www.sciencedaily.com/releases/2019/08/190826112705.htm,"   The UN Sustainable Development Goals (SDGs) focus on time-bound targets for prosperity, people, planet, peace, and partnership -- collectively known as the five Ps. By adopting the 2030 Agenda with its 17 SDGs and the Paris Climate Agreement, UN member states effectively created a framework for national action and global cooperation on sustainable development, while the Paris Agreement committed signatory countries to achieving net-zero greenhouse gas emissions by the middle of the century. SDG 13 on climate change specifically links to the Paris Agreement noting that the UN Framework Convention on Climate Change ""is the primary international, intergovernmental forum for negotiating the global response to climate change."" Despite the interconnectivity and clear aims of these global goals, stakeholders seem to lack a shared understanding of how the 17 SDGs can be operationalized. Building on previous work by The World in 2050 -- a global research initiative established by IIASA -- the authors of the study published in the journal Nature Sustainability propose six transformations to organize SDG interventions through a semi-modular action agenda that can be designed by discrete, yet interacting, parts of government. According to the paper, the proposed framework may be operationalized within the structures of governments while still respecting the strong interdependencies across the 17 SDGs. The authors also outline an action agenda for science to provide the knowledge required for designing, implementing, and monitoring the SDG Transformations. ""The 2030 Agenda and the Paris Agreement have given the world an aspirational narrative and an actionable agenda to achieve a just, safe, and sustainable future for all within planetary boundaries. The six transformations provide an integrated and holistic framework for action that reduces the complexity, yet encompasses the 17 SDGs, their 169 targets, and the Paris Agreement. They provide a new approach to shift from incremental to transformational change; to identify synergies using sustainable development pathways; formulate actionable roadmaps; and a focus on inter-relationships to uncover multiple benefits and synergies,"" explains study co-author Nebojsa Nakicenovic, executive director of The World in 2050 (TWI2050) research initiative at IIASA. In their paper the researchers considered which key interventions would be necessary to achieve the SDG outcomes and how their implementation might be organized into a limited set of six transformations namely education, gender, and inequality; health, wellbeing, and demography; energy decarbonization and sustainable industry; sustainable food, land, water, and oceans; sustainable cities and communities; and digital revolution for sustainable development. To simplify the discussion of interlinkages between interventions and SDGs, the authors further identified intermediate outputs generated by combinations of interventions, which in turn contribute to the achievement of each SDG. Each SDG transformation describes a major change in societal structure (economic, political, technological, and social) to achieve long-term sustainable development, while also each contributing to multiple SDGs. Excluding any of them would make it virtually impossible to achieve the SDGs. Pursuing the six transformations will require deep, deliberate, long-term structural changes in resource use, infrastructure, institutions, technologies, and social relations, which have to happen in a relatively short time window. Previous societal transformations, like industrialization in 19th century Europe, were initiated by technological changes like the steam engine and were largely undirected, while 20th century technologies like semiconductors, the Internet and Global Positioning Systems, were promoted through directed innovation to meet military aims. The authors emphasize that it is crucial that SDG transformations are formally directed in order to meet time-bound, quantitative targets, such as net-zero carbon emissions by mid-century. ""By achieving change in these six key areas, we can save both people and planet. To deliver on both ambitious climate targets and meet all the Sustainable Development Goals, we identify very concrete levers that governments can pull. For instance, investing in agriculture with known technologies and management practices can enable both food security, human health, and climate mitigation. Investing in young children's education is another example. It improves human wellbeing, increases economic development, and stabilizes population growth,"" says study co-author Johan Rockstr√∂m from the Potsdam Institute for Climate Impact Research in Germany. ""The six transformations in this paper have the ultimate goal of enhancing human prosperity and reducing inequalities. This is of course not easy. In fact, it is the largest human endeavor of all time. Science is here to provide governments with a fact-based framework. If political leadership fails to act, however, we would face unprecedented risks for the stability of societies, and for our Earth system."" "
Science Daily,Victorian Child Hearing-Loss Databank to Go Global,Education & Learning,2019-08-30,-,https://www.sciencedaily.com/releases/2019/08/190830092107.htm,"   The Victorian Childhood Hearing Impairment Longitudinal Databank, which has collected information for eight years, is featured in the latest International Journal of Epidemiology. Its data shows that language development and speech in hearing-impaired children lags behind other children, despite advancements in earlier detection and intervention in the past decade. The paper's* lead author, Murdoch Children's Research Institute's (MCRI) Dr Valerie Sung, says researchers world-wide can use the databank to answer questions around childhood hearing loss. ""This register can help us understand why some children with a hearing loss do so well, while others experience greater difficulties,"" she says. ""Universal newborn hearing screening is detecting hearing loss earlier than ever before, usually within a few weeks of birth. ""Children with hearing loss have very early access to hearing aids, early intervention services and for some, cochlear implantation. It was expected that hearing-impaired children would quickly come to enjoy the same language and educational outcomes as their hearing peers. ""However, early clinical diagnosis and intervention does not guarantee equality in health outcomes, with language and related outcomes of children with hearing loss remaining on average well below population means and the children's true cognitive potential. ""Demonstrating the reasons for this inequality has been hampered until now by the lack of population based prospective research."" The Victorian Childhood Hearing Impairment Longitudinal Databank (VicCHILD) is a population-based longitudinal databank open to every child with permanent hearing loss in Victoria. VicCHILD started in 2012 and stems from 25 years of work by The Royal Children's Hospital and MCRI. At the end 2018, 807 children were enrolled and provided baseline data. By 2020 more than 1000 children will be taking part, making it the largest hearing databank in the world. VicCHILD collects data at enrolment, two years of age, school entry and late primary /early high school. It involves parent questionnaires, child assessments and taking saliva samples. Dr Sung, who is also a honorary fellow at the University of Melbourne, says about 600 Australian infants each year are diagnosed with congenital hearing loss within weeks of birth. ""As these children grow, they can face challenges in things that come naturally to others like language and learning. This can impact their quality of life,"" she says. ""Hearing loss incurs significant burden and medical costs and impacts adversely on educational attainment and employment opportunities. ""This important bank of information could improve interventions and ultimately the lives of children with hearing loss and their families. It will also act as a platform for research trials to understand the effectiveness of different interventions."" "
Science Daily,"Millennials, Think You're Digitally Better Than Us? Yes, According to Science",Education & Learning,2019-08-28,-,https://www.sciencedaily.com/releases/2019/08/190828092457.htm,"   Legend has it that millennials, specifically the ""Net Generation,"" use many technologies simultaneously, masterfully switching from one to the next. They claim that it's easy and that they can do it much better than older generations. Research, so far, hasn't proven this claim and the consequences of these incessant interruptions on attention and performance. Florida Atlantic University researchers in the Charles E. Schmidt College of Science are one of the first to examine this phenomenon in college-age students. The study provides some of the first results on whether or not ""Net Genners,"" who have grown up with widespread access to technology, are developing greater digital literacy than generations before them, and if this has enriched them with an ability to switch their attention more efficiently. For the study, researchers simulated a typical working environment, complete with IT interruptions, to allow them to track the effects on participants' inhibitory processes. One hundred and seventy-seven mostly college-age participants were divided into three groups: those who received IT interruptions; those who did not, and a control group. Researchers compared the three groups' accuracy and response time on completing tasks, gauging their level of anxiety. Results, published in the journal Applied Neuropsychology: Adult, indicate that there is no need to ""pardon these interruptions,"" at least for this younger generation. Findings show that switching between technologies did not deplete or diminish performance in the group that had the IT interruptions compared to the control group or the group that did not receive IT interruptions. Unexpectedly, however, researchers discovered diminished performance in the participants from the group that did not receive any IT interruptions. All three groups reported low levels of anxiety during the study. Seventy-five percent of two of the groups reported their anxiety as ""not at all"" or ""a little bit,"" and the researchers did not find any significant differences between groups. ""We were really surprised to find impaired performance in the group that did not receive any information technology interruptions. It appears that the Net Generation thrives on switching their attention and they can do it more efficiently because information technology is woven throughout their daily lives,"" said M√≥nica Rosselli, Ph.D., senior author, professor and assistant chair of psychology in FAU's Charles E. Schmidt College of Science, and a member of the FAU Brain Institute (I-BRAIN), one of the University's four research pillars. ""Because younger generations are so accustomed to using instant messaging, pop-ups like the ones we used for our study, may blend into the background and may not appear surprising or unplanned, and therefore may not produce anxiety."" Prior research in the general population has found that it takes about 25 minutes to return to an original task following an IT interruption and 41 percent of these interruptions result in discontinuing the interrupted task altogether. Emails alone cause about 96 interruptions in an eight-hour day with an added one-and-a-half hours of recovery time per day. Results of the new FAU study sheds light on younger generations who have commonly used instant messaging as a major communication tool and this communication preference may reveal a perception gap between generations. ""How we adapt to technology and leverage it to our advantage by deciding what information we attend to at any given moment has substantial implications on our ability to remain valuable and productive in our respective work and education domains,"" said Deven M. Christopher, co-author and a graduate psychology student at FAU. ""Results from our study may provide a basis for further research, especially because younger generations are developing in a more connected world than preceding generations."" "
Science Daily,Family-School Engagement Has Specific Perks for Young Students,Education & Learning,2019-08-27,-,https://www.sciencedaily.com/releases/2019/08/190827123536.htm,"   After surveying more than 3,170 students and 200 teachers, researchers at the University of Missouri found that families are less engaged with their child's schooling in middle school than they are when their child is in elementary school. However, the researchers also found a silver lining: Both elementary school children and middle school children are less likely to have concentration problems and behavioral issues at the end of a school year if their parents made a greater effort to be engaged with their schooling earlier in the year. ""In addition to being less likely to have emotional or behavioral issues in class, we also found that students with engaged parents ended the year with better social skills and were able to focus on tasks easier,"" said Tyler Smith, a senior research associate in the College of Education. ""This means that when parents are more involved at school, the benefits to their child grow over time."" The researchers said that family-school engagement often drops from elementary to middle school for several reasons, including a change in student-teacher ratio and a desire to respect their child's growing sense of independence. ""Keeping in contact with multiple teachers can be more challenging for parents with children in middle school, but our study shows evidence that parents and teachers should continue to make an effort to connect,"" said Keith Herman, a professor in the College of Education and co-author on the study. ""There are many options for parents to become more involved at both levels without feeling intrusive."" Herman suggests that parents can explore getting involved with their child's schooling in a variety of ways. Options outside of the home include attending school functions, volunteering at events and joining parent groups. However, parents and family members can also take a more active role by helping with homework and keeping in touch with the child's teacher(s). Smith adds that teachers can also do their part in encouraging families to get more involved by providing opportunities for parents to connect with them. ""Teachers have a lot on their hands, obviously, but even small efforts to help build better family-teacher relationships can have big payoffs for everyone involved,"" Smith said. ""Teachers might consider inviting parents to special events or giving students assignments that involve their parents so that the students can help begin to build that relationship naturally."" "
Science Daily,Possible Genetic Link Between Children's Language and Mental Health,Education & Learning,2019-08-20,-,https://www.sciencedaily.com/releases/2019/08/190820081851.htm,"   The University of York-led study examined genetic variants in six genes that are thought to contribute to language development in children. The researchers used Polygenic scoring, a statistical technique which adds up the effect of different genetic variants, to determine whether variants that are associated with children's language are also associated with poor mental health. They found that nearly half of the genetic variants which contribute to children's language were also associated with poor mental health. As part of the study, the team analysed genetic data from over 5,000 children, as well as parental responses to questionnaires and clinical assessments on children's language ability. If future research confirms these findings, it may have important implications for timing of mental health provision for children with language disorders, the researchers say. Lead author of the study, Dr Umar Toseeb, from the Department of Education at the University of York, said: ""This study provides very preliminary evidence that children with language disorders, such as developmental language disorder (DLD), may experience poor mental health due to shared biological mechanisms. ""This means that children with DLD may have poor mental health because the genes that are responsible for building neural systems responsible for language might also be responsible for mental health. ""If our findings are confirmed in future work, it could mean that, rather than wait for children with developmental language disorder to show symptoms of poor mental health before intervening, mental health support is put in place as soon as language difficulties become apparent, as a preventative measure."" The mental health difficulties often experienced my children with a DLD have commonly been thought to be caused by their struggles with language, but this study is the first to suggest that there may also be genetic factors which put children with DLD at risk of poor mental health. First author of the study, Dr Dianne Newbury, from the Department of Biological and Medical Sciences at Oxford Brookes University, said: ""This is the first study to demonstrate these genetic effects but they need to be replicated in larger independent datasets to confirm the findings. ""We looked at genetic variation across six genes, but there are many thousands more in the human genome that we did not investigate, so these results only represent a subset of the relevant networks. ""The study illustrates the complexity of language related genetic networks and shows that this is an area that should be investigated further."" "
