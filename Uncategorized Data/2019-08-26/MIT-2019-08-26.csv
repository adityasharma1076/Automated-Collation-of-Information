Source,Heading,Category,Date,Time,URL,Text
MIT News,Two studies reveal benefits of mindfulness for middle school students,Research,2019-08-26,-,http://news.mit.edu/2019/mindfulness-mental-health-benefits-students-0826,"  Two new studies from MIT suggest that mindfulness — the practice of focusing one’s awareness on the present moment — can enhance academic performance and mental health in middle schoolers. The researchers found that more mindfulness correlates with better academic performance, fewer suspensions from school, and less stress. “By definition, mindfulness is the ability to focus attention on the present moment, as opposed to being distracted by external things or internal thoughts. If you’re focused on the teacher in front of you, or the homework in front of you, that should be good for learning,” says John Gabrieli, the Grover M. Hermann Professor in Health Sciences and Technology, a professor of brain and cognitive sciences, and a member of MIT’s McGovern Institute for Brain Research. The researchers also showed, for the first time, that mindfulness training can alter brain activity in students. Sixth-graders who received mindfulness training not only reported feeling less stressed, but their brain scans revealed reduced activation of the amygdala, a brain region that processes fear and other emotions, when they viewed images of fearful faces. Together, the findings suggest that offering mindfulness training in schools could benefit many students, says Gabrieli, who is the senior author of both studies.  “We think there is a reasonable possibility that mindfulness training would be beneficial for children as part of the daily curriculum in their classroom,” he says. “What’s also appealing about mindfulness is that there are pretty well-established ways of teaching it.” In the moment Both studies were performed at charter schools in Boston. In one of the papers, which appears today in the journal Behavioral Neuroscience, the MIT team studied about 100 sixth-graders. Half of the students received mindfulness training every day for eight weeks, while the other half took a coding class. The mindfulness exercises were designed to encourage students to pay attention to their breath, and to focus on the present moment rather than thoughts of the past or the future. Students who received the mindfulness training reported that their stress levels went down after the training, while the students in the control group did not. Students in the mindfulness training group also reported fewer negative feelings, such as sadness or anger, after the training. About 40 of the students also participated in brain imaging studies before and after the training. The researchers measured activity in the amygdala as the students looked at pictures of faces expressing different emotions. At the beginning of the study, before any training, students who reported higher stress levels showed more amygdala activity when they saw fearful faces. This is consistent with previous research showing that the amygdala can be overactive in people who experience more stress, leading them to have stronger negative reactions to adverse events. “There’s a lot of evidence that an overly strong amygdala response to negative things is associated with high stress in early childhood and risk for depression,” Gabrieli says. After the mindfulness training, students showed a smaller amygdala response when they saw the fearful faces, consistent with their reports that they felt less stressed. This suggests that mindfulness training could potentially help prevent or mitigate mood disorders linked with higher stress levels, the researchers say. Richard Davidson, a professor of psychology and psychiatry at the University of Wisconsin, says that the findings suggest there could be great benefit to implementing mindfulness training in middle schools. “This is really one of the very first rigorous studies with children of that age to demonstrate behavioral and neural benefits of a simple mindfulness training,” says Davidson, who was not involved in the study. Evaluating mindfulness In the other paper, which appeared in the journal Mind, Brain, and Education in June, the researchers did not perform any mindfulness training but used a questionnaire to evaluate mindfulness in more than 2,000 students in grades 5-8. The questionnaire was based on the Mindfulness Attention Awareness Scale, which is often used in mindfulness studies on adults. Participants are asked to rate how strongly they agree with statements such as “I rush through activities without being really attentive to them.” The researchers compared the questionnaire results with students’ grades, their scores on statewide standardized tests, their attendance rates, and the number of times they had been suspended from school. Students who showed more mindfulness tended to have better grades and test scores, as well as fewer absences and suspensions. “People had not asked that question in any quantitative sense at all, as to whether a more mindful child is more likely to fare better in school,” Gabrieli says. “This is the first paper that says there is a relationship between the two.” The researchers now plan to do a full school-year study, with a larger group of students across many schools, to examine the longer-term effects of mindfulness training. Shorter programs like the two-month training used in the Behavioral Neuroscience study would most likely not have a lasting impact, Gabrieli says. “Mindfulness is like going to the gym. If you go for a month, that’s good, but if you stop going, the effects won’t last,” he says. “It’s a form of mental exercise that needs to be sustained.” The research was funded by the Walton Family Foundation, the Poitras Center for Psychiatric Disorders Research at the McGovern Institute for Brain Research, and the National Council of Science and Technology of Mexico. Camila Caballero ’13, now a graduate student at Yale University, is the lead author of the Mind, Brain, and Education study. Caballero and MIT postdoc Clemens Bauer are lead authors of the Behavioral Neuroscience study. Additional collaborators were from the Harvard Graduate School of Education, Transforming Education, Boston Collegiate Charter School, and Calmer Choice. "
MIT News,What’s the best way to cut vehicle greenhouse-gas emissions?,Research,2019-08-26,-,http://news.mit.edu/2019/lightweight-vehicle-electric-emissions-0826,"  Policies to encourage reductions in greenhouse gas emissions tend to stress the need to switch as many vehicles as possible to electric power. But a new study by MIT and the Ford Motor Company finds that depending on the location, in some cases an equivalent or even bigger reduction in emissions could be achieved by switching to lightweight conventional (gas-powered) vehicles instead — at least in the near term. The study looked at a variety of factors that can affect the relative performance of these vehicles, including the role of low temperatures in reducing battery performance, regional differences in average number of miles driven annually, and the different mix of generating sources in different parts of the U.S. The results are being published today in the journal Environmental Science & Technology, in a paper by MIT Principal Research Scientist Randolph Kirchain, recent graduate Di Wu PhD ’18, graduate student Fengdi Guo, and three researchers from Ford. The study combined a variety of datasets to examine the relative impact of different vehicle choices down to a county-by-county level across the nation. It showed that while electric vehicles provide the greatest impact in reducing greenhouse gas emissions for most of the country, especially on both coasts and in the south, significant parts of the Midwest had the opposite result, with lightweight gasoline-powered vehicles achieving a greater reduction. The biggest factor leading to that conclusion was the mix of generating sources going into the grid in different regions, Kirchain says. That mix is “cleaner” on both the East and West coasts, with higher usage of renewable energy sources and relatively low-emissions natural gas, while in the upper Midwest there is still a much higher proportion of coal-burning power plants. That means that even though electric vehicles produce no greenhouse emissions while they are being driven, the process of recharging the car’s batteries results in significant emissions. In those locations, buying a lightweight car, defined as one whose structure is built largely from aluminum or specialized lightweight steel, would actually result in fewer emissions than buying a comparable electric car, the study found. The research was made possible by Ford’s collection of vehicle-performance data from about 30,000 cars, over a total of about 300 million miles of driving. They come from conventional midsize conventional gasoline cars, and the researchers used standard modeling techniques to calculate the performance of equivalent vehicles that were either hybrid-electric, battery-electric, or lightweight versions of conventional cars.  “We tried to add as much spatial resolution as possible, compared to other studies in the literature, to try to get a sense of the combined effects” of the various factors of temperature, the grid, and driving conditions, Kirchain explains. That combination of data showed, among other things, that “some of the areas with more carbon-heavy grids also happen to be colder, and somewhat more rural,” he says. “All three of those things can tilt emissions in a negative way for electric vehicles” in terms of their impact on reducing emissions. The combined effects are strongest in parts of Wisconsin and Michigan, where lightweight cars would have a significant advantage over EVs in reducing emissions, the study showed. The impact of cold weather on battery performance, he says, “is something that is discussed in the EV literature, but not as much in the popular discussions of the topic.” Conversely, gasoline-powered vehicles suffer an efficiency penalty in urban driving, but they have lower emissions in regions that are more rural and spread out. The data on car performance the team had to work with thanks to their collaboration with Ford researchers “was unique,” Kirchain says. “In the past, a ‘large’ study of this type would be a few dozen vehicles,” and those would mainly come from people who volunteered to share their data and therefore were more likely to be concerned about environmental impact. The extensive Ford data, by contrast, provide “a broader cross-section of drivers and driving conditions.” Kirchain stresses that the intent of this study is not in any way to minimize the importance of switching over ground transportation to electric power in order to curb greenhouse emissions. “We’re not trying to undermine the fact that electrification is the long-term solution — and the short-term solution for most of the country,” he says. But over the next few decades, which is considered a critical period in determining the planet’s climate outcomes, it’s important to know what measures will actually be most effective in reducing carbon emissions in order to set policies and incentives that will produce the best outcomes, he says. The relative advantage of lightweight vehicles compared to electric ones, according to their modeling, “goes down over time, as the grid improves,” he says. “But it doesn’t go away completely until you get to close to 2050 or so.” Lightweight aluminum is now used in the Ford F-150 pickup truck, and in the all-electric Tesla sedans. Currently, there are no high-volume lightweight gasoline-powered midsize cars on the market in the U.S., but they could be built if incentives similar to those used to encourage the production of electric cars were in place, Kirchain suggests. Right now, he says, the U.S. has “a patchwork of regulations and incentives that are providing extra incentives for electrification.” But there are certain parts of the country, he says, where it would make more sense to provide incentives “for any option that provides sufficient fuel savings, not just for electrification,” he says. “At least for the north central part of the country, policymakers should consider a more nuanced approach,” he adds. “This is a significant advance,” says Heather MacLean, professor of civil and mineral engineering at the University of Toronto, who was not associated with this work. This study, she says, “illustrates the importance of the regional disaggregation in the analysis, and that if it were absent results would be incorrect. This is an unequivocal call for regional policies that use the latest research to build rational agendas, rather than prescribing overarching global solutions.” The research team included Robert De Kleine, Hyung Chul Kim, and Timothy Wallington of the Research and Innovation Center of Ford Motor Company, in Dearborn, Michigan. "
MIT News,A much less invasive way to monitor pressure in the brain,Research,2019-08-23,-,http://news.mit.edu/2019/less-invasive-brain-pressure-0823,"  Traumatic brain injuries, as well as infectious diseases such as meningitis, can lead to brain swelling and dangerously high pressure in the brain. If untreated, patients are at risk for brain damage, and in some cases elevated pressure can be fatal. Current techniques for measuring pressure within the brain are so invasive that the measurement is only performed in the patients at highest risk. However, that may soon change, now that a team of researchers from MIT and Boston Children’s Hospital has devised a much less invasive way to monitor intracranial pressure (ICP). “Ultimately the goal is to have a monitor at the bedside in which we only use minimally invasive or noninvasive measurements and produce estimates of ICP in real time,” says Thomas Heldt, the W. M. Keck Career Development Professor in Biomedical Engineering in MIT’s Institute of Medical Engineering and Science, an associate professor of electrical and biomedical engineering, and a principal investigator in MIT’s Research Laboratory of Electronics. In a study of patients ranging in age from 2 to 25 years, the researchers showed that their measurement is nearly as accurate as the current gold standard technique, which requires drilling a hole in the skull. Heldt is the senior author of the paper, which appears in the Aug. 23 issue of the Journal of Neurosurgery: Pediatrics. MIT research scientist Andrea Fanelli is the study’s lead author. Elevated risk Under normal conditions, ICP is between 5 and 15 millimeters of mercury (mmHg). When the brain suffers a traumatic injury or swelling caused by inflammation, pressure can go above 20 mmHg, impeding blood flow into the brain. This can lead to cell death from lack of oxygen, and in severe cases swelling pushes down on the brainstem — the area that controls breathing — and can cause the patient to lose consciousness or even stop breathing. Measuring ICP currently requires drilling a hole in the skull and inserting a catheter into the ventricular space, which contains cerebrospinal fluid. This invasive procedure is only done for patients in intensive care units who are at high risk of elevated ICP. When a patient’s brain pressure becomes dangerously high, doctors can help relieve it by draining cerebrospinal fluid through a catheter inserted into the brain. In very severe cases, they remove a piece of the skull so the brain has more room to expand, then replace it once the swelling goes down. Heldt first began working on a less invasive way to monitor ICP more than 10 years ago, along with George Verghese, the Henry Ellis Warren Professor of Electrical Engineering at MIT, and then-graduate student Faisal Kashif. The researchers published a paper in 2012 in which they developed a way to estimate ICP based on two measurements: arterial blood pressure, which is taken by inserting a catheter at the patient’s wrist, and the velocity of blood flow entering the brain, measured by holding an ultrasound probe to the patient’s temple. For that initial study, the researchers developed a mathematical model of the relationship between blood pressure, cerebral blood flow velocity, and ICP. They tested the model on data collected several years earlier from patients with traumatic brain injury at Cambridge University, with encouraging results. In their new study, the researchers wanted to improve the algorithm that they were using to estimate ICP, and also to develop methods to collect their own data from pediatric patients. They teamed up with Robert Tasker, director of the pediatric neurocritical care program at Boston Children’s Hospital and a co-author of the new paper, to identify patients for the study and help move the technology to the bedside. The system was tested only on patients whose guardians approved the procedure. Arterial blood pressure and ICP were already being measured as part of the patients’ routine monitoring, so the only additional element was the ultrasound measurement. Fanelli also devised a way to automate the data analysis so that only data segments with the highest signal-to-noise ratio were used, making the estimates of ICP more accurate. “We built a signal processing pipeline that was able to automatically detect the segments of data that we could trust versus the segments of data that were too noisy to be used for ICP estimation,” he says. “We wanted to have an automated approach that could be completely user-independent.” Expanded monitoring The ICP estimates generated by this new technique were, on average, within about 1 mmHg of the measurements taken with the invasive method. “From a clinical perspective, it was well within the limits that we would consider useful,” Tasker says. In this study, the researchers focused on patients with severe injuries because those are the patients who already had an invasive ICP measurement being done. However, a less invasive approach could allow ICP monitoring to be expanded to include patients with diseases such as meningitis and encephalitis, as well as malaria, which can all cause brain swelling. “In the past, for these conditions, we would never consider ICP monitoring. What the current research has opened up for us is the possibility that we can include these other patients and try to identify not only whether they’ve got raised ICP but some degree of magnitude to that,” Tasker says. “These findings are very encouraging and may open the way for reliable, non-invasive neuro-critical care,” says Nino Stocchetti, a professor of anesthesia and intensive care medicine at Policlinico of Milan, Italy, who was not involved in the research. “As the authors acknowledge, these results ‘indicate a promising route’ rather than being conclusive: additional work, refinements and more patients remain necessary.” The researchers are now running two additional studies, at Beth Israel Deaconess Medical Center and Boston Medical Center, to test their system in a wider range of patients, including those who have suffered strokes. In addition to helping doctors evaluate patients, the researchers hope that their technology could also help with research efforts to learn more about how elevated ICP affects the brain. “There’s been a fundamental limitation of studying intracranial pressure and its relation to a variety of conditions, simply because we didn’t have an accurate and robust way to get at the measurement noninvasively,” Heldt says. The researchers are also working on a way to measure arterial blood pressure without inserting a catheter, which would make the technology easier to deploy in any location. “This estimate could be of greatest benefit in the pediatrician’s office, the ophthalmologist’s office, the ambulance, the emergency department, so you want to have a completely noninvasive arterial blood pressure measurement,” Heldt says. “We’re working to develop that.” The research was funded by the National Institutes for Neurological Disorders and Stroke, Maxim Integrated Products, and the Boston Children’s Hospital Department of Anesthesiology, Critical Care, and Pain Medicine. "
MIT News,Using CRISPR to program gels with new functions,Research,2019-08-22,-,http://news.mit.edu/2019/crispr-edit-materials-gels-0822,"  The CRISPR genome-editing system is best-known for its potential to correct disease-causing mutations and add new genes into living cells. Now, a team from MIT and Harvard University has deployed CRISPR for a completely different purpose: creating novel materials, such as gels, that can change their properties when they encounter specific DNA sequences. The researchers showed they could use CRISPR to control electronic circuits and microfluidic devices, and to release drugs, proteins, or living cells from gels. Such materials could be used to create diagnostic devices for diseases such as Ebola, or to deliver treatments for diseases such as irritable bowel disease. “This study serves as a nice starting point for showing how CRISPR can be utilized in materials science for a really wide range of applications,” says James Collins, the Termeer Professor of Medical Engineering and Science in MIT’s Institute for Medical Engineering and Science (IMES) and Department of Biological Engineering, and the senior author of the study. The lead authors of the study, which appears in the Aug. 22 online edition of Science, are MIT graduate students Max Atti English, Luis Soenksen, and Raphael Gayet, and postdoc Helena de Puig. DNA interactions CRISPR is based on DNA-cutting proteins called Cas enzymes, which bind to short RNA guides that direct them to specific areas of the genome. Cas cuts DNA in those locations, deleting a gene or allowing new genetic sequences to be introduced. Over the past several years, much research has been devoted to developing CRISPR as a gene-editing tool for treating disease by cutting out or repairing faulty genes. The MIT and Harvard team set out to adapt it for creating materials that could respond to external cues such as the presence of a certain sequence of DNA. For this work, they used an enzyme known as Cas12a, which can be programmed to bind to specific sequences of double-stranded DNA by simply changing the guide RNA sequence that is given along with the enzyme. Once Cas12a encounters a target DNA sequence, also called a trigger, it cleaves the double-stranded DNA and transforms into an enzyme that can slice any single-stranded DNA it encounters. “By incorporating DNA into materials, you can use this enzyme to control the properties of the materials in response to a specific biological cue in the environment,” English says. The researchers took advantage of this to design gels that incorporate single-stranded DNA in key functional or structural roles. In one example, they created a gel made of polyethylene glycol (PEG) and used DNA to anchor enzymes or other large biomolecules to the gel. When activated by a trigger sequence, Cas12a cuts the DNA anchors, releasing the payload. That type of gel could be useful for releasing therapeutic compounds such as drugs or growth factors, the researchers say. In another example, they created an acrylamide gel in which single-stranded DNA forms an integral part of the gel structure. In that case, when Cas12a is activated by the trigger, the entire gel breaks down, enabling the release of larger cargoes such as cells or nanoparticles. “In that context, we consider the single-stranded DNA as a structural scaffold,” Gayet says. “The enzyme is able to catalyze the cleavage of the single-stranded DNA, which acts as a structural linker, and release all of those molecules.” The researchers are now exploring the possibility of using this approach to deliver engineered bacterial cells to help treat gastrointestinal diseases. Inexpensive diagnostics The researchers also created two CRISPR-controlled diagnostic devices, one based on an electronic circuit and the other on a microfluidic chip. To create the electronic circuit, the researchers designed a gel that includes single-stranded DNA and a material called carbon black, which conducts electricity. When attached to the surface of an electrode, this conductive gel allows electrical current to flow. However, if Cas12a is activated by a trigger sequence, such as a strand of viral DNA from a blood sample, the gel becomes detached from the electrode and current stops flowing. For their microfluidic sensor, the researchers created a DNA-containing gel that acts as a valve that controls the flow of a solution through the microfluidic channel. If the solution contains a blood sample with a target DNA sequence, the gel breaks down, turning off the valve, and the solution stops flowing. This microfluidic sensor can be connected to an RFID chip, allowing it to wirelessly transmit the results of the test. “A health care worker can be monitoring dozens of patients, and the presence or absence of the Ebola trigger will automatically relay a binary signal,” Soenksen says. While the researchers used fluid samples containing Ebola virus RNA to test this approach, it could also be adapted to detect other infectious diseases, as well as cancer cells circulating in a patient’s bloodstream. Philip LeDuc, a professor of mechanical engineering at Carnegie Mellon University, describes the work as “tremendously creative.” “This is a very non-obvious intersection of two different fields, and the influence of this work will be far-reaching,” says LeDuc, who was not involved in the study. “This transdisciplinary work may enable an entire new generation of approaches for applications from building artificial organs to improving the environment.” The research was funded by the Defense Threat Reduction Agency, the Paul G. Allen Frontiers Group, and the Wyss Institute for Biologically Inspired Engineering at Harvard University. "
MIT News,New method classifies brain cells based on electrical signals ,Research,2019-08-22,-,http://news.mit.edu/2019/new-method-classifies-brain-cells-based-electrical-signals-0822,"  For decades, neuroscientists have relied on a technique for reading out electrical “spikes” of brain activity in live, behaving subjects that tells them very little about the types of cells they are monitoring. In a new study, researchers at the University of Tuebingen, Germany, and MIT’s Picower Institute for Learning and Memory demonstrate a way to increase their insight by distinguishing four distinct classes of cells from that spiking information. The advance offers brain researchers the chance to better understand how different kinds of neurons are contributing to behavior, perception, and memory, and how they are malfunctioning in cases of psychiatric or neurological diseases. Much like mechanics can better understand and troubleshoot a machine by watching how each part works as it runs, neuroscientists, too, are better able to understand the brain when they can tease apart the roles different cells play while it thinks. “We know from anatomical studies that there are multiple types of cells in the brain and if they are there, they must be there for a reason,” says Earl Miller, the Picower Professor of Neuroscience in the Department of Brain and Cognitive Sciences at MIT, and co-senior author of the paper in Current Biology. “We can’t truly understand the functional circuitry of the brain until we fully understand what different roles these different cell types might play.” Miller collaborated with the Tuebingen-based team of lead author Caterina Trainito, Constantin von Nicolai, and Professor Markus Siegel, co-senior author and a former postdoc in Miller’s lab, to develop the new way to wring more neuron type information from electrophysiology measurements. Those measures track the rapid voltage changes, or spikes, that neurons exhibit as they communicate in circuits, a phenomenon essential for brain function. “Identifying different cell types will be key to understand both local and large-scale information processing in the brain,” Siegel says. Four is greater than two At best, neuroscientists have so far only been able to determine from electrophysiology whether a neuron was excitatory or inhibitory. That’s because they only analyzed the difference in the width of the spike. The typical amount of data in an electrophysiology study — spikes from a few hundred neurons — only supported that single degree of distinction, Miller says. But the new study could go farther because it derives from a dataset of recordings from nearly 2,500 neurons. Miller and Siegel gathered the data years ago at MIT from three regions in the cortex of animals who were performing experimental tasks that integrated perception and decision-making. “We recognized the uncommonly rich resource at our disposal,” Siegel says. Thus, the team decided to put the dataset through a ringer of sophisticated statistical and computational tools to analyze the waveforms of the spikes. Their analysis showed that the waveforms could actually be sorted along two dimensions: how quickly the waveform ranges between its lowest and highest voltage (“trough to peak duration”), and how quickly the voltage changes again afterward, returning from the peak to the normal level (“repolarization time”). Plotting those two factors against each other neatly sorted the cells into four distinct “clusters.” Not only were the clusters evident across the whole dataset, but individually within each of the three cortical regions, too. For the distinction to have any meaning, the four classes of cells would have to have functional differences. To test that, the researchers decided to sort the cells out based on other criteria such as their “firing rate” (how often they spike), whether they tend to fire in bursts, and how variable their intervals are between spikes — all factors in how they participate in and influence the circuits they are connected in. Indeed, the cell classes remained distinct by these measures. In yet another phase of analysis, the cell classes also remained distinguishable as the researchers watched them respond to the animals perceiving and processing visual stimulation. But in this case, they saw the cells play different roles in different regions. A class 1 cell, for example, might respond differently in one region than it did in another. “These cell types are truly different cell types that have different properties,” Miller says. “But they have different functions in different cortical areas because different cortical areas have different functions.” New research capability In the study, the authors speculate about which real neuron types their four mathematically defined classes most closely resemble, but they don’t yet offer a definitive determination. Still, Miller says the finer-grained distinctions the study draws are enough to make him want to reanalyze old neural spiking data to see what new things he can learn. One of Miller’s main research interests is the nature of working memory — our ability to hold information like directions in mind while we make use of it. His research has revealed that it is enabled by a complex interplay of brain regions and precisely timed bursts of neural activity. Now he may be able to figure out how different classes of neurons play specific roles in specific regions to endow us with this handy mental ability. And both Miller’s and Siegel’s labs are particularly interested in different brain rhythms, which are abundant in the brain and likely play a key role for orchestrating communication between neurons. The new results open a powerful new window for them to unravel which role different neuron classes play for these brain rhythms.     The U.S. National Institutes of Health, the European Research Council, the Deutsche Forschungsgemeinschaft, and the Center for Integrative Neuroscience provided funding for the study. "
MIT News,Study: Climate change could pose danger for Muslim pilgrimage,Research,2019-08-22,-,http://news.mit.edu/2019/climate-muslim-hajj-0822,"  For the world’s estimated 1.8 billion Muslims — roughly one-quarter of the world population — making a pilgrimage to Mecca is considered a religious duty that must be performed at least once in a lifetime, if health and finances permit. The ritual, known as the Hajj, includes about five days of activities, of which 20 to 30 hours involve being outside in the open air. According to a new study by researchers at MIT and in California, because of climate change there is an increasing risk that in coming years, conditions of heat and humidity in the areas of Saudi Arabia where the Hajj takes place could worsen, to the point that people face “extreme danger” from harmful health effects. In a paper in the journal Geophysical Review Letters, MIT professor of civil and environmental engineering Elfatih Eltahir and two others report the new findings, which show risks to Hajj participants could already be serious this year and next year, as well as when the Hajj, whose timing varies, again takes place in the hottest summer months, which will be from 2047 to 2052 and from 2079 to 2086. This will happen even if substantial measures are taken to limit the impact of climate change, the study finds, and without those measures, the dangers would be even greater. Planning for countermeasures or restrictions on participation in the pilgrimage may thus be needed. The timing of the Hajj varies from one year to the next, Eltahir explains, because it is based on the lunar calendar rather than the solar calendar. Each year the Hajj occurs about 11 days earlier, so there are only certain spans of years when it takes place during the hottest summer months. Those are the times that could become dangerous for participants, says Eltahir, who is the Breene M. Kerr Professor at MIT. “When it comes in the summer in Saudi Arabia, conditions become harsh, and a significant fraction of these activities are outdoors,” he says. There have already been signs of this risk becoming real. Although the details of the events are scant, there have been deadly stampedes during the Hajj in recent decades: one in 1990 that killed 1,462 people, and one in 2015 that left 769 dead and 934 injured. Eltahir says that both of these years coincided with peaks in the combined temperature and humidity in the region, as measured by the “wet bulb temperature,” and the stress of elevated temperatures may have contributed to the deadly events. “If you have crowding in a location,” Eltahir says, “the harsher the weather conditions are, the more likely it is that crowding would lead to incidents” such as those. Wet bulb temperature (abbreviated as TW), which is measured by attaching a wet cloth to the bulb of a thermometer, is a direct indicator of how effectively perspiration can cool off the body. The higher the humidity, the lower the absolute temperature that can trigger health problems. At anything above a wet bulb temperature of about 77 degrees Fahrenheit, the body can no longer cool itself efficiently, and such temperatures are classified as a “danger” by the U.S. National Weather Service. A TW above about 85 F is classified as “extreme danger,” at which heat stroke, which can damage the brain, heart, kidneys, and muscles and can even lead to death, is “highly likely” after prolonged exposure. Climate simulations carried out by Eltahir and his co-investigators, using both “business as usual” scenarios and scenarios that include significant countermeasures against climate change, show that the likelihood of exceeding these thresholds for extended periods will increase steadily over the course of this century with the countermeasures, and very severely so without them. Because evaporation is so crucial to maintaining a safe body temperature, the level of humidity in the air is key. Even an actual temperature of just 90 F, if the humidity rises to 95 percent, is enough to reach the deadly 85 degree TW threshold for “extreme danger.” At a lower humidity of 45 percent, the 85 TW threshold would not be reached until the actual temperature climbed to 104 F or more. (At very high humidity, the wet bulb temperature equals the actual temperature). Climate change will significantly increase the number of days each summer where wet bulb temperatures in the region will exceed the “extreme danger” limit. Even with mitigation measures in place, Eltahir says, “it will still be severe. There will still be problems, but not as bad” as would occur without those measures. The Hajj is “a very strong part of the culture” in Muslim communities, Eltahir says, so preparing for these potentially unsafe conditions will be important for officials in Saudi Arabia. A variety of protective measures have been in place in recent years, including nozzles that provide a mist of water in some of the outdoor locations to provide some cooling for participants, and widening some of the locations to reduce overcrowding. In the most potentially risky years ahead, Eltahir says, it may become necessary to severely limit the number of participants allowed to take part in the ritual. This new research “should help in informing policy choices, including climate change mitigation policies as well as adaptation plans,” he says. The research team included Suchul Kang, an MIT postdoc, and Jeremy Pal, a professor of civil engineering and environmental science at Loyola Marymount University in Los Angeles. The work was supported by a seed grant from the MIT Environmental Solutions Initiative. "
MIT News,Study links certain metabolites to stem cell function in the intestine,Research,2019-08-22,-,http://news.mit.edu/2019/ketones-stem-cell-intestine-0822,"  MIT biologists have discovered an unexpected effect of a ketogenic, or fat-rich, diet: They showed that high levels of ketone bodies, molecules produced by the breakdown of fat, help the intestine to maintain a large pool of adult stem cells, which are crucial for keeping the intestinal lining healthy. The researchers also found that intestinal stem cells produce unusually high levels of ketone bodies even in the absence of a high-fat diet. These ketone bodies activate a well-known signaling pathway called Notch, which has previously been shown to help regulate stem cell differentiation. “Ketone bodies are one of the first examples of how a metabolite instructs stem cell fate in the intestine,” says Omer Yilmaz, the Eisen and Chang Career Development Associate Professor of Biology and a member of MIT’s Koch Institute for Integrative Cancer Research. “These ketone bodies, which are normally thought to play a critical role in energy maintenance during times of nutritional stress, engage the Notch pathway to enhance stem cell function. Changes in ketone body levels in different nutritional states or diets enable stem cells to adapt to different physiologies.” In a study of mice, the researchers found that a ketogenic diet gave intestinal stem cells a regenerative boost that made them better able to recover from damage to the intestinal lining, compared to the stem cells of mice on a regular diet. Yilmaz is the senior author of the study, which appears in the Aug. 22 issue of Cell. MIT postdoc Chia-Wei Cheng is the paper’s lead author. An unexpected role Adult stem cells, which can differentiate into many different cell types, are found in tissues throughout the body. These stem cells are particularly important in the intestine because the intestinal lining is replaced every few days. Yilmaz’ lab has previously shown that fasting enhances stem cell function in aged mice, and that a high-fat diet can stimulate rapid growth of stem cell populations in the intestine. In this study, the research team wanted to study the possible role of metabolism in the function of intestinal stem cells. By analyzing gene expression data, Cheng discovered that several enzymes involved in the production of ketone bodies are more abundant in intestinal stem cells than in other types of cells. When a very high-fat diet is consumed, cells use these enzymes to break down fat into ketone bodies, which the body can use for fuel in the absence of carbohydrates. However, because these enzymes are so active in intestinal stem cells, these cells have unusually high ketone body levels even when a normal diet is consumed. To their surprise, the researchers found that the ketones stimulate the Notch signaling pathway, which is known to be critical for regulating stem cell functions such as regenerating damaged tissue. “Intestinal stem cells can generate ketone bodies by themselves, and use them to sustain their own stemness through fine-tuning a hardwired developmental pathway that controls cell lineage and fate,” Cheng says. In mice, the researchers showed that a ketogenic diet enhanced this effect, and mice on such a diet were better able to regenerate new intestinal tissue. When the researchers fed the mice a high-sugar diet, they saw the opposite effect: Ketone production and stem cell function both declined. Stem cell function The study helps to answer some questions raised by Yilmaz’ previous work showing that both fasting and high-fat diets enhance intestinal stem cell function. The new findings suggest that stimulating ketogenesis through any kind of diet that limits carbohydrate intake helps promote stem cell proliferation. “Ketone bodies become highly induced in the intestine during periods of food deprivation and play an important role in the process of preserving and enhancing stem cell activity,” Yilmaz says. “When food isn’t readily available, it might be that the intestine needs to preserve stem cell function so that when nutrients become replete, you have a pool of very active stem cells that can go on to repopulate the cells of the intestine.” The findings suggest that a ketogenic diet, which would drive ketone body production in the intestine, might be helpful for repairing damage to the intestinal lining, which can occur in cancer patients receiving radiation or chemotherapy treatments, Yilmaz says. The researchers now plan to study whether adult stem cells in other types of tissue use ketone bodies to regulate their function. Another key question is whether ketone-induced stem cell activity could be linked to cancer development, because there is evidence that some tumors in the intestines and other tissues arise from stem cells. “If an intervention drives stem cell proliferation, a population of cells that serve as the origin of some tumors, could such an intervention possibly elevate cancer risk? That’s something we want to understand,” Yilmaz says. “What role do these ketone bodies play in the early steps of tumor formation, and can driving this pathway too much, either through diet or small molecule mimetics, impact cancer formation? We just don’t know the answer to those questions.” The research was funded by the National Institutes of Health, a V Foundation V Scholar Award, a Sidney Kimmel Scholar Award, a Pew-Stewart Trust Scholar Award, the MIT Stem Cell Initiative, the Koch Institute Frontier Research Program through the Kathy and Curt Marble Cancer Research Fund, the Koch Institute Dana Farber/Harvard Cancer Center Bridge Project, and the American Federation of Aging Research. "
MIT News,High-precision technique stores cellular “memory” in DNA,Research,2019-08-22,-,http://news.mit.edu/2019/domino-cellular-memory-dna-0822,"  Using a technique that can precisely edit DNA bases, MIT researchers have created a way to store complex “memories” in the DNA of living cells, including human cells. The new system, known as DOMINO, can be used to record the intensity, duration, sequence, and timing of many events in the life of a cell, such as exposures to certain chemicals. This memory-storage capacity can act as the foundation of complex circuits in which one event, or series of events, triggers another event, such as the production of a fluorescent protein. “This platform gives us a way to encode memory and logic operations in cells in a scalable fashion,” says Fahim Farzadfard, a Schmidt Science Postdoctoral Fellow at MIT and the lead author of the paper. “Similar to silicon-based computers, in order to create complex forms of logic and computation, we need to have access to vast amounts of memory.” Applications for these types of complex memory circuits include tracking the changes that occur from generation to generation as cells differentiate, or creating sensors that could detect, and possibly treat, diseased cells. Timothy Lu, an MIT associate professor of electrical engineering and computer science and of biological engineering, is the senior author of the study, which appears in the Aug. 22 issue of Molecular Cell. Other authors of the paper include Harvard University graduate student Nava Gharaei, former MIT researcher Yasutomi Higashikuni, MIT graduate student Giyoung Jung, and MIT postdoc Jicong Cao. Written in DNA Several years ago, Lu’s lab developed a memory storage system based on enzymes called DNA recombinases, which can “flip” segments of DNA when a specific event occurs. However, this approach is limited in scale: It can only record one or two events, because the DNA sequences that have to be flipped are very large, and each requires a different recombinase. Lu and Farzadfard then developed a more targeted approach in which they could insert new DNA sequences into predetermined locations in the genome, but that approach only worked in bacterial cells. In 2016, they developed a memory storage system based on CRISPR, a genome-editing system that consists of a DNA-cutting enzyme called Cas9 and a short RNA strand that guides the enzyme to a specific area of the genome. This CRISPR-based process allowed the researchers to insert mutations at specific DNA locations, but it relied on the cell’s own DNA-repair machinery to generate mutations after Cas9 cut the DNA. This meant that the mutational outcomes were not always predictable, thus limiting the amount of information that could be stored. The new DOMINO system uses a variant of the CRISPR-Cas9 enzyme that makes more well-defined mutations because it directly modifies and stores bits of information in DNA bases instead of cutting DNA and waiting for cells to repair the damage. The researchers showed that they could get this system to work accurately in both human and bacterial cells. “This paper tries to overcome all the limitations of the previous ones,” Lu says. “It gets us much closer to the ultimate vision, which is to have robust, highly scalable, and defined memory systems, similar to how a hard drive would work.” To achieve this higher level of precision, the researchers attached a version of Cas9 to a recently developed “base editor” enzyme, which can convert the nucleotide cytosine to thymine without breaking the double-stranded DNA. Guide RNA strands, which direct the base editor where to make this switch, are produced only when certain inputs are present in the cell. When one of the target inputs is present, the guide RNA leads the base editor either to a stretch of DNA that the researchers added to the cell’s nucleus, or to genes found in the cell’s own genome, depending on the application. Measuring the resulting cytosine to thymine mutations allows the researchers to determine what the cell has been exposed to. “You can design the system so that each combination of the inputs gives you a unique mutational signature, and from that signature you can tell which combination of the inputs has been present,” Farzadfard says. Complex calculations The researchers used DOMINO to create circuits that perform logic calculations, including AND and OR gates, which can detect the presence of multiple inputs. They also created circuits that can record cascades of events that occur in a certain order, similar to an array of dominos falling. “This is very innovative work that enables recording and retrieving cellular information using DNA. The ability to perform sequential or logic computation and associative learning is particularly impressive,” says Wilson Wong, an associate professor of biomedical engineering at Boston University, who was not involved in the research. “This work highlights novel genetic circuits that can be achieved with CRISPR/Cas.” Most previous versions of cellular memory storage have required stored memories to be read by sequencing the DNA. However, that process destroys the cells, so no further experiments can be done on them. In this study, the researchers designed their circuits so that the final output would activate the gene for green fluorescent protein (GFP). By measuring the level of fluorescence, the researchers could estimate how many mutations had accumulated, without killing the cells. The technology could potentially be used to create mouse immune cells that produce GFP when certain signaling molecules are activated, which researchers could analyze by periodically taking blood samples from the mice. Another possible application is designing circuits that can detect gene activity linked to cancer, the researchers say. Such circuits could also be programmed to turn on genes that produce cancer-fighting molecules, allowing the system to both detect and treat the disease. “Those are applications that may be further away from real-world use but are certainly enabled by this type of technology,” Lu says. The research was funded by the National Institutes of Health, the Office of Naval Research, the National Science Foundation, the Defense Advanced Research Projects Agency, the MIT Center for Microbiome Informatics and Therapeutics, and the NSF Expeditions in Computing Program Award. "
