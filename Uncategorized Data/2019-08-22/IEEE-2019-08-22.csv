Source,Heading,Category,Date,Time,URL,Text
IEEE,6 Things to Know About the Biggest Chip Ever Built,Semiconductors,2019-08-22,-,https://spectrum.ieee.org/tech-talk/semiconductors/processors/4-things-to-know-about-the-biggest-chip-ever-built,"        On Monday at the IEEE Hot Chips symposium at Stanford University, startup Cerebras unveiled the largest chip ever built. It is roughly a silicon wafer-size system meant to reduce AI training time from months to minutes. It is the first commercial attempt at a wafer-scale processor since Trilogy Systems failed at the task in the 1980s.  1 | The stats As the largest chip ever built, Cerebras’s Wafer Scale Engine (WSE) naturally comes with a bunch of superlatives. Here they are with a bit of context where possible:  Size: 46,225 square millimeters. That’s about 75 percent of a sheet of letter-size paper, but 56 times as large as the biggest GPU. Transistors: 1.2 trillion. Nvidia’s GV100 Volta packs in 2.1 billion. Processor cores: 400,000. Not to pick on the GV100 too much, but it has 5,660. Memory: 18 gigabytes of on-chip SRAM, about 3,000 times as much as our pal the GV100.  Memory bandwidth: 9 petabytes per second. That’s 10,000 times our favorite GPU, according to Cerebras.   2 | Why do you need this monster? Cerebras makes a pretty good case in its white paper [PDF] for why such a ridiculously large chip makes sense. Basically, the company argues that the demand for training deep learning systems and other AI systems is getting out of hand. The company says that training a new model—creating a system that, once trained, can recognize people or win a game of Go—is taking weeks or months and costing hundreds of thousands of dollars of compute time. That cost means there’s little room for experimentation, and that’s stifling new ideas and innovation. The startup’s answer is that the world needs more, and cheaper, training compute resources. Training needs to take minutes not months, and to do that you need more cores, more memory close to those cores, and a low-latency, high-bandwidth connection between the cores. Those are goals that are clearly in effect for everyone in the AI space. But, by its own admission, Cerebras took the idea to its logical extreme. A big chip offers more silicon area for processor cores and the memory that needs to snuggle up next to it. And a high-bandwidth, low-latency connection is only achievable if data never has to leave the short, dense interconnects on a chip. Thus one big chip.   3 | What’s in those 400,000 cores? According to the company, the WSE’s cores are specialized to do AI, but still programmable enough that they’re not locked into only one flavor of it. They call them Sparse Linear Algebra (SLA) cores. These processing units are specialized to “tensor” operations key to AI work, but they also include a feature that reduces the work, particularly for deep-learning networks. According to the company, 50 to 98 percent of all the data in a deep learning training set are zeros. The nonzero data is therefore “sparse.” The SLA cores cut down on the work by simply not multiplying anything by zero. The cores have built in data-flow elements that trigger computing actions based on the data, so when it encounters a zero in the data, it doesn’t waste its time.   4 | How did they do this? The fundamental idea behind Cerebras’s massive single chip has been obvious for decades, but it has also been impractical. To quote myself: Back in the 1980s, parallel computing pioneer Gene Amdahl hatched a plan to speed mainframe computing: a silicon-wafer-sized processor. By keeping most of the data on the processor itself instead of pushing it through a circuit board to memory and other chips, computing would be faster and more energy efficient. With US $230 million from venture capitalists, the most ever at the time, Amdahl founded Trilogy Systems to make his vision a reality. This first commercial attempt at “wafer-scale integration” was such a disaster that it reportedly introduced the verb “to crater” into the financial press lexicon.   The most basic problem is that the bigger the chip, the worse the yield; that’s the fraction of working chips you get from each wafer. Logically, this should mean a wafer-scale chip would be unprofitable, because there would always be flaws in your product. Cerebras’s solution is to add a certain amount of redundancy. According to EE Times, the Swarm communications networks have redundant links to route around damaged cores, and about 1 percent of the cores are spares. Cerebras also had to work around some key manufacturing limits. For one, chip tools are designed to cast their feature-defining patterns onto relatively small rectangles and do that over and over, perfectly across the wafer. That alone would keep a lot of systems from being built on a single wafer, because of the cost and difficulty of casting different patterns in different places on the wafer. But the WSE resembles a typical wafer full of the exact same chips, just as you’d ordinarily manufacture. The big difference was a method they worked out with TSMC to make connections across the space between the chips, an area called the scribe lines. This space is typically left blank because the chips are diced up along those lines. According to Tech Crunch, Cerebras also had to invent a way to provide the chips 15 kilowatts of power and cool the system as well as create new kinds of connectors that could deal with the way it expands when it heats up.    5 | Is this the only way to make a wafer-scale computer? Of course not. For example, a team at University of California, Los Angeles, and University of Illinois Urbana-Champaign is working on a similar system that would eventually use bare processor dies that have already been built and tested and mounts them on a silicon wafer that’s already patterned with the needed dense network of interconnects. This concept, called a silicon interconnect fabric, allows these dielets to sit as close as 100 micrometers from each other, allowing for interchip communication that nears the characteristics of a single chip. “This is a huge validation of the research we’ve been doing,” says the University of Illinois’s Rakesh Kumar. “We like the fact that there is commercial interest in something like this.” Kumar believes that the silicon interconnect fabric approach has some advantages over Cerebras’s monolithic wafer-scale scheme. For one, it allows a designer to mix and match technologies, and use the best manufacturing process for each. A monolithic approach means picking the best process for the most crucial subsystem—logic, for example—and using it for memory and other components even if it’s not ideal for them. In that approach, Cerebras could be limited in the amount of memory it can put on the processor, Kumar suggests. “They have 18 gigabits of SRAM on the wafer. Maybe that’s enough for some models today, but what about models tomorrow and the day after?”  6 | When does it come out? According to Fortune, the first systems ship to customers in September, and some have already received prototypes. According to EE Times, the company plans to reveal results from complete systems at the Supercomputing Conference in November.   Receive latest technology science and technology news & analysis from IEEE Spectrum every Thursday.  IEEE Spectrum’s general technology blog, featuring news, analysis, and opinions about engineering, consumer electronics, and technology and society, from the editorial staff and freelance contributors. Featured Jobs © Copyright 2019 IEEE — All rights reserved. Use of this Web site signifies your agreement to the IEEE Terms and Conditions.  A not-for-profit organization, IEEE is the world  largest technical professional organization dedicated to advancing technology for the benefit of humanity."
IEEE,How Robotics Teams Are Solving the Biggest Problem at DARPA’s Subterranean Challenge,Robotics,2019-08-21,-,https://spectrum.ieee.org/automaton/robotics/robotics-hardware/how-teams-are-solving-the-biggest-challenge-at-darpa-subt,"      When DARPA announced its Subterranean Challenge, the agency framed things with a comprehensive list of “technical challenge elements” that it expected to be particularly, you know, challenging. One of those elements was communication constraints, which DARPA said teams should expect to be “severe.” That may have been an understatement, based on what we're seeing at the SubT Tunnel Circuit—teams have had a lot of trouble consistently talking to their robots on the course. Even though most teams are emphasizing autonomy as much as possible, they do still have to deal with communication challenges, because finding artifacts won’t earn you any points unless the robot reports its location back to base before time runs out. And if your robot has to come all the way back to base to make its report, it’s going to run out of time after finding just a few artifacts. There’s no magical solution for this, which is awesome, because teams have come up with all kinds of fantastically creative and unique strategies. We went around and asked them about it when we visited the SubT Tunnel Circuit in Pittsburgh yesterday.  Some quick context to help you understand the challenge here—robots usually do fine through the first several tens of meters just past the mine entrance. Once they turn the first corner, however, they lose their wireless connection back to the base station almost immediately, because radio waves don’t pass through solid rock. And even if the robots manage to hang on to a signal for a little bit, the twists and turns and sheer distances that the robots must travel (hundreds and hundreds of meters, ideally) means it simply isn’t possible to maintain a direct connection back to base.  Most teams are adopting a robot-to-robot mesh networking approach to help with this, meaning that the robots themselves can serve as network nodes, and if one robot can communicate back to base, any robot that it can communicate with can also communicate back to base—and so on down as long a chain of robots as you can manage. Robots need to move around to do their jobs, though, and teams only have a limited number of robots, so here are some other strategies that teams are using to keep in contact. This is about as straightforward as it gets—Team PLUTO mounted massive dipole antennas on the butts of their Ghost Robotics Vision 60 quadrupeds, which in their experience improves communication performance by an order of magnitude. The team is emphasizing autonomy, and like many teams, their robots are designed to operate for extended periods without any communications at all, but they do still need to report back on what they found from time to time. Team Explorer, currently leading (by a lot) in artifacts found, uses deployable network nodes (pulled halfway out of a protective casing in the picture above) that its robots can drop when the strength of the network starts getting low. Each robot can carry about 10 nodes in the two racks that you can see, and while the nodes are dropped at the command of the remote operator at the moment, the robots will eventually be able to decide autonomously when they need to plop one down. The team also plans to shrink the nodes down, and to improve the dropping mechanism, which can get jammed by mud. The beefy deployable network node idea was a popular one, and Team CoSTAR (tied for second place in artifacts found at the end of day three) sent in multiple robots carrying nodes in several different configurations.  DARPA not-so-subtly suggested that teams may not want to rely on a physical tether between the base station and robots (“teams should seriously consider the limitations [on tethers] imposed by large-scale, potentially dynamic, complex environments,” says the agency), but Team CERBERUS didn’t let that scare them. They’re using a fiber-optic tether and a dedicated communications robot with a massive antenna on it to essentially extend their base station deep into the mine. The tether isn’t long enough to explore the whole mine, of course, and it has to be carefully managed around corners, but even if the robot just makes it down to the end of the first passage and around the first corner, it’s a massive improvement. These are “Anchorballs” that Team NCTU’s robots can deploy as mesh network nodes, but they’re also used as active landmarks to help with SLAM localization. They’re weighted at the bottom so that, after being dropped, they stop rolling with a camera pointing at the ceiling, and the robot can then correlate the image from the Anchorball camera with its own internal map.  After a bit of communication trouble, Team NCTU decided that they needed to boost their system a bit, so they deployed their own tether of sorts yesterday. If that looks like a router wrapped in a plastic bag connected to a really long Ethernet cord, well, you nailed it. The team placed the router on a robot, let the cable out from the base station as the robot drove into the mine, and then just gave the cable a tug to pull the router off the robot and onto the ground once the robot got far enough to deploy the router where the team wanted it. These are some of the most cleverly designed droppable network nodes that we’ve seen—once dropped, the node waits for a few seconds for the robot to drive itself off, and then uses an actuator and springs to flip itself up and deploy its antennas. The reflective surfaces are a nice touch as well; presumably, they help DARPA find the dropped nodes at the end of a run, while also encouraging any following robots not to run over them quite as much. Why drop a network node that just sits there, when you could instead drop a network node that can drive itself around? Team CRETISE is dropping FirstLook robots from a beastly mothership robot to serve as cute little mobile nodes that can zip around to optimize your network. The FirstLooks are themselves descendants of LANdroids, which were developed by iRobot with DARPA funding so long ago that I wrote about them back before I was even writing about robots, in early 2007. The original idea with LANdroids was that they would self-deploy to create dynamic and resilient mesh networks in challenging environments, but eventually iRobot turned them into the FirstLook tossable surveillance robots. And now, more than a decade later, Team CRETISE is turning them back into LANdroids again, which is pretty cool.  In addition to little puck-shaped deployable mesh-network nodes, Team MARBLE has been experimenting with these robots built on top of remote-controlled off-road racing cars. They have onboard sensing and computing and communications, of course, but they’re not intended to search for artifacts. Instead, their job is to ferry information—quickly navigating between areas with base station connectivity and other (slower) robots that are exploring elsewhere. Rather than acting as mobile nodes, these little cars are more like delivery robots, picking up data and carrying it back home. Without the constraints of having to maintain a network, the idea is that the exploration robots will be able to travel much farther while spending more time exploring autonomously, relying on the information-ferrying cars for all of their communication needs. The team doesn’t have it all working yet, but it’s a super interesting idea, and we’re looking forward to seeing it in action.  Biweekly newsletter on advances and news in robotics, automation, control systems, interviews with leading roboticists, and more.  IEEE Spectrum’s award-winning robotics blog, featuring news, articles, and videos on robots, humanoids, automation, artificial intelligence, and more. Featured Jobs © Copyright 2019 IEEE — All rights reserved. Use of this Web site signifies your agreement to the IEEE Terms and Conditions.  A not-for-profit organization, IEEE is the world  largest technical professional organization dedicated to advancing technology for the benefit of humanity."
